{"meta":{"title":"LincentMa's Blog","subtitle":null,"description":null,"author":"LicentMa","url":"http://lincentma.men"},"pages":[{"title":"about","date":"2017-06-15T05:55:42.000Z","updated":"2017-06-20T03:17:17.880Z","comments":true,"path":"about/index.html","permalink":"http://lincentma.men/about/index.html","excerpt":"","text":"一名SWJTU的计算机科学与技术专业的致力于后端的程序猿1234567891011121314151617181920&#123; name: '马凌 / lincentma' age: 24, gender: '男', address: '四川省成都市郫都区犀浦镇西南交通大学', education: [ ['本科/西南交通大学'], ['硕士/西南交通大学'] ], Github: 'https://github.com/lingma1993', email: 'mlstd@163.com', skills: [ ['Java','Python', 'PHP', ], ['MySQL','Redis'], ['Hadoop', 'Hive'], ['git'], ['Linux'] ], description: 'stay hungry，stay foolish'&#125; 关于工作致力于：工作高效，简单可依赖致力于：自己成为一专多长的人才 关于生活生活不止眼前的苟且，还有诗和远方的田野，你赤手空拳来到人世间，为找到那片海不顾一切。 关于她为白首不相离而努力"},{"title":"categories","date":"2017-06-15T04:22:36.000Z","updated":"2017-06-15T07:18:28.114Z","comments":false,"path":"categories/index.html","permalink":"http://lincentma.men/categories/index.html","excerpt":"","text":""},{"title":"guestbook","date":"2017-06-28T14:22:38.000Z","updated":"2017-06-28T14:22:38.844Z","comments":true,"path":"guestbook/index.html","permalink":"http://lincentma.men/guestbook/index.html","excerpt":"","text":""},{"title":"随笔一记,生活点滴记录","date":"2017-06-28T14:32:59.000Z","updated":"2017-06-28T14:39:38.488Z","comments":true,"path":"mooddatabase/index.html","permalink":"http://lincentma.men/mooddatabase/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-06-15T04:22:27.000Z","updated":"2017-06-15T07:18:54.414Z","comments":false,"path":"tags/index.html","permalink":"http://lincentma.men/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"招银科技一面","slug":"“zhaoyinkeji_interview”","date":"2017-09-14T15:57:57.000Z","updated":"2017-09-14T16:00:06.411Z","comments":true,"path":"“zhaoyinkeji_interview”.html","link":"","permalink":"http://lincentma.men/“zhaoyinkeji_interview”.html","excerpt":"","text":"招银科技一面 主要是基础知识，有些细节自己没有掌握牢固，温故知新 基础知识1. 你了解过Java的序列化吗？ Java 对象序列化是 JDK 1.1 中引入的一组开创性特性之一，用于作为一种将 Java 对象的状态转换为字节数组，以便存储或传输的机制，以后，仍可以将字节数组转换回 Java 对象原有的状态。实际上，序列化的思想是 “冻结” 对象状态，传输对象状态（写到磁盘、通过网络传输等等），然后 “解冻” 状态，重新获得可用的 Java 对象。 2. Java序列化的用途以及使用场景？ 1.当对象需要被网络传输时2.对象状态需要被持久化时 围绕根本，就有很多实际的拓展应用，例如： tomcat服务器会在服务器关闭时把session序列化存储到tomcat目录一个名为session.ser的文件中，这个过程成为session的钝化，因为有些时候当我们要重新部署项目的时候，有的用户可能在访问，这样做的目的是服务器重启之后tomcat可以反序列化这个session.ser文件，将session对象重新生成出来，用户可以使用部署之前的session进行操作，这个反序列化的过程成为session的活化。 分布式应用。 3. 类序列化需要实现什么接口？ Serializable接口。 4. 该类实现了这个接口，那么子类可以序列化吗？ 父类实现了Serializable，子类不需要实现Serializable接口。 5. 当序列化后修改serialVersionUID，还可以反序列化回来吗? 序列化的时候系统会把当前类的serialVersionUID 写入序列化的文件中（也可能是其他中介），当反序列化的时候系统会去检测文件中的serialVersionUID，看它是否和当前类的serialVersionUID一致，如果一致就说明序列化的类的版本和当前类的版本是相同的，这个时候可以成功反序列化，否则就说明当前类和序列化的类相比发生了某些变换，比如成员变量的数量，类型可能发生了改变，这个时候就会抛异常，反序列化失败。 默认情况下，也就是不声明serialVersionUID属性情况下，系统会按当前类的成员变量计算hash值并赋值给serialVersionUID。声明serialVersionUID，可以很大程度上避免反序列化过程的失败。比如当版本升级后，我们可能删除了某个成员变量，也可能增加了一些新的成员变量，这个时候我们的反序列化依然能够成功，程序依然能够最大程度地恢复数据，相反，如果不指定serialVersionUID，程序就会挂掉。当然我们还要考虑另外一种情况，如果类结构发生了非常规性改变，比如修改了类名，类型等，这个时候尽管serialVersionUID验证通过了，但是反序列化过程还是会失败，因为类结构有了毁灭性的改变。 serialVersionUID一般默认设置为固定的 1L。 Java序列化允许java类中的一些变化，如果他们可以被忽略的话。一些不会影响到反序列化处理的变化有： 在类中添加一些新的变量。 将变量从transient转变为非tansient，对于序列化来说，就像是新加入了一个变量而已。 将变量从静态的转变为非静态的，对于序列化来说，就也像是新加入了一个变量而已。 总结，serialVersionUID不一致，反序列化报错。对象序列化后更改值同样也可以读取到，序列化并不保存静态变量，可以接受一些类变量的增加操作不影响反序列化。 6. Java序列化相对于其他数据交换的方式有哪些缺点？ Java序列化写入不仅是完整的类名，也包含整个类的定义，包含所有被引用的类。一旦类定义较多，空间占用大。同时Java序列化为二进制对文件，序列化后内容都是不可读的，这会对系统的排错造成一定的影响。优点是转换效率高。 JSON以固定的格式，稳定简单的数据结构大大简化了序列化过程。缺点是转换效率低。 7. classloader加载类的机制是什么？ 遵循委派双亲加载。通过调用loadClass方法逐级往上传递委派加载请求，当找不到父ClassLoader时调用其findClass方法尝试进行查找和加载，如果当前ClassLoader找不所需的Class,则由其孩子尝试进行查找和加载，如果当前ClassLoader找了所需的Class则将该Class按请求路径逐级返回孩子。 8. 你的意思是jar包中的类不一定会全部加载？系统提供(例如JDK、String)的类是由哪一个加载器加载的？EXT加载哪些类？如果我自定义一个类加载区，它的父加载区是哪一个？ Java动态加载。Bootstrap ClassLoader。EXT加载JRE\\lib\\ext*.jar。拥堵自定义的类加载器的父类为系统加载器。 JVM本身包含了一个ClassLoader称为Bootstrap ClassLoader，和JVM一样，BootstrapClassLoader是用本地代码实现的，它负责加载核心JavaClass(即所有java.*开头的类)。——Load JRE\\lib\\rt.jar 另外JVM还会提供两个ClassLoader，它们都是用Java语言编写的，由BootstrapClassLoader加载;其中Extension ClassLoader负责加载扩展的Javaclass(例如所有javax.*开头的类和存放在JRE的ext目录下的类) ApplicationClassLoader负责加载应用程序自身的类。 9. classLoad加载class文件一般分为哪几个阶段？ 当使用到某个类，但该类还未初始化，未加载到内存中时会经历类加载、链接、初始化三个步骤完成类的初始化。 类加载： 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器。只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。 类的链接： 当类加载完成后，系统会给为之生成一个对象；随后进入链接阶段，链接阶段负责把类的二进制数据添加到JRE中。三个阶段： 验证：检验被加载的类是否有正确的内部结构，并和其他类协调一致 准备：负责为类的类变量分配内存。并设置默认初始值 解析：将类的二进制数据中的符号引用替换成直接引用 类的初始化：JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： 声明类变量是指定初始值 使用静态代码块为类变量指定初始值 JVM初始化步骤 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 10. 数据库试图的作用？视图中的数据是存在视图中的吗？ 这个回答的不好。 视图是从一个或几个基本表（或视图）导出的表。它与基本表不同，是一个虚表。数据库只存放视图的定义，而不存放视图对应的数据，这些数据仍存放在原来的基本表中。 视图能简化用户操作 视图使用户能以多种角度看待同一数据 视图对重构数据库提供了一定程度的逻辑独立性 视图能够对机密数据提供安全保护 11. 视图的更新有没有一些限制？ 没有回答上来 利用数据库视图进行更新实质上就是对数据库的基本表进行更新。所以视图的更新update命令有很多限制。 若视图是由两个以上基本表导出的，则此视图不允许更新 若视图的字段来自字段表达式或常数，则不允许对此视图执行INSERT和UPDATE操作，但允许执行DELETE 若视图字段来自聚集函数，则此视图不允许更新 若视图定义中含有GROUP BY 子句，则此视图不允许更新 若视图中含有DISTINCT语句，则此视图不允许更新 若视图定义中含有嵌套查询，并且内层查询的FROM子句涉及的表也是导出该视图的基本表，则此视图不允许更新 一个不允许更新的视图上定义的视图也不允许更新 12. 内联结和外联结的区别？ 内连接查询操作列出与连接条件匹配的数据行，它使用比较运算符比较被连接列的列值。 外连接，返回到查询结果集合中的不仅包含符合连接条件的行，而且还包括左表(左外连接或左连接))、右表(右外连接或右连接)或两个边接表(全外连接)中的所有数据行。 left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录； right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录。 13. 索引的作用 优点： 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快 数据的检索速度，这也是创建索引的最主要的原因。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序 子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点： 创建索引和维护索引要耗费时间，这种时间随着数据 量的增加而增加。 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 14. 索引一定会加快检索速度吗？ 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因 为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那 些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比 例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索 引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因 此，当修改性能远远大于检索性能时，不应该创建索引。 15. 数据库的锁分为哪几种？ 锁的类型有三种： 共享（S)锁：多个事务可封锁一个共享页；任何事务都不能修改该页； 通常是该页被读取完毕，S锁立即被释放。 排它（X)锁：仅允许一个事务封锁此页；其他任何事务必须等到X锁被释放才能对该页进行访问；X锁一直到事务结束才能被释放。 更新（U)锁：用来预定要对此页施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的页将要被更新时，则升级为X锁；U锁一直到事务结束时才能被释放。 16. 幻读产生场景？一般出现在什么样的事务中？ 不可重复读取(Non-Repeatable Reads): A 事务两次读取同一数据，B事务也读取这同一数据，但是 A 事务在第二次读取前B事务已经更新了这一数据。所以对于A事务来说，它第一次和第二次读取到的这一数据可能就不一致了。 幻读(Phantom Reads): 与不可重复读有点类似，都是两次读取，不同的是 A 事务第一次操作的比如说是全表的数据，此时 B 事务并不是只修改某一具体数据而是插入了一条新数据，而后 A 事务第二次读取这全表的时候就发现比上一次多了一条数据，发生幻觉了。 数据库事务的隔离级别有4个，由低到高依次为Read uncommitted 读未提交 、Read committed 读提交 、Repeatable read 重复读 、Serializable 序列化 ，这四个级别可以逐个解决脏读 、不可重复读 、幻读 这几类问题。 幻读出现在前三个级别中。不可重复读出现在前两个级别中。脏读出现在第一个级别中。 17. TCP如何保证重传？ 每一次发送一个片段，就开启一个重传计时器。计时器有一个初始值并随时间递减。如果在片段接收到确认之前计时器超时，就重传片段。 放置于重传队列中，计时器开始 包含数据的片段一经发送，片段的一份复制就放在名为重传队列的数据结构中，此时启动重传计时器。因此，在某些时间点，每一个片段都会放在队列里。队列按照重传计时器的剩余时间来排列，因此TCP软件可追踪那几个计时器在最短时间内超时。 确认处理 如果在计时器超时之前收到了确认信息，则该片段从重传队列中移除。 重传超时 如果在计时器超时之前没有收到确认信息，则发生重传超时，片段自动重传。当然，相比于原片段，对于重传片段并没有更多的保障机制。因此，重传之后该片段还是保留在重传队列里。重传计时器被重启，重新开始倒计时。如果重传之后没有收到确认，则片段会再次重传并重复这一过程。在某些情况下重传也会失败。我们不想要TCP永远重传下去，因此TCP只会重传一定数量的次数，并判断出现故障终止连接。 18. 域名解析过程？ 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"zhaoyinkeji","slug":"zhaoyinkeji","permalink":"http://lincentma.men/tags/zhaoyinkeji/"}]},{"title":"猎豹移动一面","slug":"cheetah_mobile_interview","date":"2017-09-14T14:08:51.000Z","updated":"2017-09-14T14:10:15.144Z","comments":true,"path":"cheetah_mobile_interview.html","link":"","permalink":"http://lincentma.men/cheetah_mobile_interview.html","excerpt":"","text":"猎豹移动一面Python项目 详细介绍项目流程 Java项目 详细介绍后台管理系统的设计流程 MySQL数据库开放性问题 谈谈你对于MySQL设计的理解 自己主要根据项目经历和实习经历中使用MySQL的经验，从数据库表建立和索引建立这两方面来回答。 在网上找到了数据库的发展历史。 MySQL是一种关系数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。 数据库设计原则 基本表及其字段之间的关系, 应尽量满足第三范式。但是，满足第三范式的数据库设计，往往不是最好的设计。为了提高数据库的运行效率，常常需要降低范式标准：适当增加冗余，达到以空间换时间的目的。 数据库范式 第一范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解 第二范式：2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性； 第三范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。 冗余的目的是为了提高处理速度。只有低级冗余才会增加数据的不一致性，因为同一数据，可 能从不同时间、地点、角色上多次录入。因此，我们提倡高级冗余(派生性冗余)，反对低级冗余(重复性冗余)。 视图是一种虚表，它依赖数据源的实表而存在。视图是供程序员使用数据库的一个窗口，是基表数据综合的一种形式, 是数据处理的一种方法，是用户数据保密的一种手段。为了进行复杂处理、提高运算速度和节省存储空间, 视图的定义深度一般不得超过三层。 若三层视图仍不够用, 则应在视图上定义临时表, 在临时表上再定义视图。这样反复交迭定义, 视图的深度就不受限制了。 中间表是存放统计数据的表，它是为数据仓库、输出报表或查询结果而设计的，有时它没有主键与外键(数据仓库除外)。临时表是程序员个人设计的，存放临时记录，为个人所用。基表和中间表由DBA维护，临时表由程序员自己用程序自动维护。 数据库设计的实用原则是：在数据冗余和处理速度之间找到合适的平衡点。 提高数据库运行效率的办法。在给定的系统硬件和系统软件条件下，提高数据库系统的运行效率的办法是： 在数据库物理设计时，降低范式，增加冗余, 少用触发器, 多用存储过程。 当计算非常复杂、而且记录条数非常巨大时(例如一千万条)，复杂计算要先在数据库外面，以文件系统方式用C++语言计算处理完成之后，最后才入库追加到表中去。这是电信计费系统设计的经验。 发现某个表的记录太多，例如超过一千万条，则要对该表进行水平分割。水平分割的做法是，以该表主键PK的某个值为界线，将该表的记录水平分割为两个表。若发现某个表的字段太多，例如超过八十个，则垂直分割该表，将原来的一个表分解为两个表。 对数据库管理系统DBMS进行系统优化，即优化各种系统参数，如缓冲区个数。 在使用面向数据的SQL语言进行程序设计时，尽量采取优化算法。 参考文章：总结数据库设计的原则 MySQL如何面对高并发用户的访问 自己的回答主要是从主从分离以及Redis结果缓存这两方面回答。 查询SQL优化 使用SQL时，尽量把使用的索引放在选择的首列； 在查询时，不要过多地使用通配符; 在可能的情况下尽量限制尽量结果集行数; 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描; 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描; 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描; in 和 not in 也要慎用，因为IN会使系统无法使用索引,而只能直接搜索表中的数据; 尽量避免在索引过的字符数据中，使用非打头字母搜索。这也使得引擎无法利用索引; 必要时强制查询优化器使用某个索引; 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描; 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描; 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致; 使用视图加速查询 能用UNION ALL就不要用UNION, UNION ALL不执行SELECT DISTINCT函数，这样就会减少很多不必要的资源 参考文章：MySQL大数据高并发处理之-查询的优化 分库分表 分表：例如user表按照user_id%256的策略进行分表。分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。面对高并发的读写访问，当数据库Master服务器无法承载写操作压力 时，不管如何扩展Slave服务器，此时都没有意义了。 分库: 对数据库进行拆分，从而提高数据库写入能力，这就是所谓的分库。假设user_id字段的值为257,将原有的单库分为256个库，那么应用程序对数据库的访问请求将被路由到第1个库（257%256=1)。 有时数据库可能既面临着高并发访问的压力，又需要面对海量数据的存储问题，这时需要对数据库即采用分库策略，又采用分表策略，以便同时扩展系统的并发处理能力，以及提升单 表的查询性能，这就是所谓的分库分表。 中间变量=user_id% (库数量X每个库的表数量） 库=取整（中间变量/每个库的表数量） 表=中间变量％每个库的表数量。 假设将原来的单库单表order拆分成256个库，每个库包含1024个表，那么按照前面所提到的路由策略，对于user_id=262145的访问，路由的计算过程如下：中间变量=262145% (256X1024) =1;库=取整（1/1024) =0;表=1%1024=1。这意味着，对于user_id=262145的订单记录的查询和修改，将被路由到第0个库的第1个表中执行。 参考文章：大型网站架构设计-mysql分表与分库 使用队列：使用队列写入等方法来降低并发读写:Redis队列 缓存设计 采用redis数据库，前置到mysql。 例如秒杀场景：必须使用缓存，将需要秒杀的商品放入缓存中，并使用锁来处理其并发情况。当接到用户秒杀提交订单的情况下，先将商品数量递减（加锁/解锁）后再进行其他方面的处理，处理失败在将数据递增1（加锁/解锁），否则表示交易成功。当商品数量递减到0时，表示商品秒杀完毕，拒绝其他用户的请求。 多用户并发修改同一条记录。 乐观锁，就是在数据库设计一个版本号的字段，每次修改都使其+1，这样在提交时比对提交前的版本号就知道是不是并发提交了，但是有个缺点就是只能是应用中控制，如果有跨应用修改同一条数据乐观锁就没办法了，这个时候可以考虑悲观锁。 悲观锁，就是直接在数据库层面将数据锁死，类似于oralce中使用select xxxxx from xxxx where xx=xx for update，这样其他线程将无法提交数据。 除了加锁的方式也可以使用接收锁定的方式，思路是在数据库中设计一个状态标识位，用户在对数据进行修改前，将状态标识位标识为正在编辑的状态，这样其他用户要编辑此条记录时系统将发现有其他用户正在编辑，则拒绝其编辑的请求，类似于你在操作系统中某文件正在执行，然后你要修改该文件时，系统会提醒你该文件不可编辑或删除。 参考文章：mysql处理高并发，防止库存超卖","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"Cheetah Mobile","slug":"Cheetah-Mobile","permalink":"http://lincentma.men/tags/Cheetah-Mobile/"}]},{"title":"OJ基本技巧记录","slug":"OJ_skill","date":"2017-09-12T07:58:15.000Z","updated":"2017-09-12T08:00:19.958Z","comments":true,"path":"OJ_skill.html","link":"","permalink":"http://lincentma.men/OJ_skill.html","excerpt":"","text":"OJ基本技巧记录OJ平台代码基本格式123456789101112131415161718import java.util.Scanner;/** * Created by ml on 2017/9/11. */public class Main &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); while (in.hasNext()) &#123; String n = in.nextLine();//读一个字符串 int m = in.nextInt();//读一个整数 long l = in.nextLong();//读一个长整数 double t = in.nextDouble();//读一个浮点数 System.out.println(cal(n));//具体处理逻辑 &#125; in.close(); &#125;&#125; OJ输入输出技巧 输入数据有多行，第一行是一个整数n，表示测试实例的个数，后面跟着n行，每行包括一个由字母和数字组成的字符串。 123456789Scanner in = new Scanner(System.in);int n = in.nextInt();//可以创建数组int[] n = new int[n];String[] str = new String[n];for(int i=0;i&lt;n;i++) &#123; n[i] = in.nextInt(); String str = in.nextLine();&#125; 读入字符串的分割 例如：Input输入数据有多组，每组占一行，数据格式为YYYY/MM/DD组成 123456789Scanner in = new Scanner(System.in);while (in.hasNext()) &#123; String str =in.nextLine(); String[] date = str.split(&quot;/&quot;); int y = Integer.parseInt(date[0]); int m = Integer.parseInt(date[1]); int d = Integer.parseInt(date[2]);&#125;in.close(); 不同类型相互转换 int转为String： String s = Integer.toString(i); String s = String.valueOf(i); String s = “” + i; 三种效率排序：Integer.toString(int i) &gt; String.valueOf(int i) &gt; i+””; String转为int int i = Integer.parseInt(s); int i = Integer.valueOf(s).intValue() 这两种都会抛出异常（NumberFormatException） Java输出 System.out.print(); //输出不换行 System.out.println(); //输出换行 System.out.format(); double d = 345.678; System.out.printf(“%9.2f”, d);// “9.2”中的9表示输出的长度，2表示小数点后的位数。 System.out.printf(“%+-9.3f”, d);// “+-“表示输出的数带正负号且左对齐。 System.out.printf(); //与上相同 DecimalFormat。DecimalFormat 类主要靠 # 和 0 两种占位符号来指定数字长度。0 表示如果位数不足则以 0 填充，# 表示只要有可能就把数字拉上这个位置。 NumberFormat formatter = new DecimalFormat( “0.00”); String s = formatter.format(-.567); // -0.57 System.out.println(s); 矩阵如何按行输出 123456789//输出int[n][m]，判断是否是每一行的最后一个，输出换行。for(int i = 0; i &lt; n ; i++) &#123; for(int j = 0; j &lt; m; j++&gt;) &#123; if(j == m - 1)&#123; system.out.println(i); &#125; else &#123; system.out.print(i + &quot; &quot;); &#125;&#125; 不定长度类型 对于整形等数据在处理中不能确定长度的情况，使用ArrayList等形式来存储数据。 对于char或者String类型可以使用StingBuffer等形式来存储。 集合遍历 数组以及List：遍历 1234List&lt;String&gt; list = new ArrayList&lt;String&gt;();for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i));&#125; Map类 12345678910111213141516Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();//1Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = map.entrySet().iterator();while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = it.next(); System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue());&#125;//2for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; entry.getKey();&#125;//3for (String key : map.keySet()) &#123; String value = (String) map.get(key);&#125; 传统的for循环遍历，基于计数器。遍历整个集合的平均时间复杂度为O(n^2)。 迭代器遍历，Iterator。 foreach循环遍历。实现原理同Iterator。 排序 如果要对数组排序，请使用java.util.Arrays.sort()方法。 如果对list排序，请使用java.util.Collections.sort()方法。 自定义排序：对于要排序的类实现Comparable接口。 123456789101112131415161718192021class S1 implements Comparable&#123; int x; int y; S1(int x, int y)&#123; this.x = x; this.y = y; &#125; //实现排序方法。先比较x，如果相同比较y @Override public int compareTo(Object o) &#123; S1 obj = (S1) o; if(x != obj.x) &#123; return x - obj.x; &#125; return y - obj.y; &#125; //重写toStirng方法，改变println时的显示效果 public String toString()&#123; return &quot;(&quot;+x+&quot;, &quot;+y+&quot;)&quot;; &#125; OJ常用函数 不同类型长度： 数组：int len = n.length;//int[] n = new int[10]; 字符串：int len = s.length();//String s = “hello”; List：int len = list.size();//List list = new ArrayList(); String类： 字符串某一位置字符,charAt。 12String str = new String(&quot;asdfzxc&quot;);char ch = str.charAt(4);//ch = z 转化为char数组。toCharArray方法。 12String str1 = new String(&quot;abc&quot;);char[] c = str1.toCharArray(); 判断相等。equals方法。 123String str1 = new String(&quot;abc&quot;);String str2 = new String(&quot;ABC&quot;);boolean c = str1.equals(str2);//c=false 提取子串。substring方法：一个参数：该方法从beginIndex位置起，出剩余的字符作为一个新的字符串返回。两个参数：左闭右开原则[beginIndex,endIndex)，即[beginIndex,endIndex - 1] 123String str1 = new String(&quot;asdfzxc&quot;);String str2 = str1.substring(2);//str2 = &quot;dfzxc&quot;String str3 = str1.substring(2,5);//str3 = &quot;dfz&quot; 字符串比较。compareTo方法是对字符串内容按字典顺序进行大小比较，通过返回的整数值指明当前字符串与参数字符串的大小关系。若当前对象比参数大则返回正整数，反之返回负整数，相等返回0。 1234String str1 = new String(&quot;abc&quot;);String str2 = new String(&quot;ABC&quot;);int a = str1.compareTo(str2);//a&gt;0int b = str1.compareTo(str2);//b=0 是否包含字符。contains方法判断参数s是否被包含在字符串中，并返回一个布尔类型的值. 123String str = &quot;student&quot;;str.contains(&quot;stu&quot;);//truestr.contains(&quot;ok&quot;);//false 字符串字符替换。replace、replaceFirst、replaceAll方法。 12345String str = &quot;asdzxcasd&quot;;String str1 = str.replace(&apos;a&apos;,&apos;g&apos;);//str1 = &quot;gsdzxcgsd&quot;String str2 = str.replace(&quot;asd&quot;,&quot;fgh&quot;);//str2 = &quot;fghzxcfgh&quot;String str3 = str.replaceFirst(&quot;asd&quot;,&quot;fgh&quot;);//str3 = &quot;fghzxcasd&quot;String str4 = str.replaceAll(&quot;asd&quot;,&quot;fgh&quot;);//str4 = &quot;fghzxcfgh&quot; 字符查找。indexOf、lastIndexOf方法。 123456String str = &quot;I am a good student&quot;;int a = str.indexOf(&apos;a&apos;);//a = 2int b = str.indexOf(&quot;good&quot;);//b = 7int c = str.indexOf(&quot;w&quot;,2);//c = -1int d = str.lastIndexOf(&quot;a&quot;);//d = 5int e = str.lastIndexOf(&quot;a&quot;,3);//e = 2 StringBuffer类 添加。append方法。 12StringBuffer sb = new StringBuffer(“abc”);sb.append(true);//&quot;abctrue&quot; 插入。insert方法。 12StringBuffer sb = new StringBuffer(“TestString”);sb.insert(4,false);//&quot;TestfalseString&quot; 删除。deleteCharAt方法。 12StringBuffer sb = new StringBuffer(“Test”);sb. deleteCharAt(1);//&quot;Tst&quot; 转换为字符串 12StringBuffer sb = new StringBuffer(“Test”);String s1 = sb.toString(); //StringBuffer转换为String ArrayList类 添加：add方法 插入：insert方法 删除：remove方法 清空：clear方法 包含：contains方法 OJ常用算法 自己的初步阶段：理清思路，暴力求解，再逐步改进！","categories":[{"name":"面试","slug":"面试","permalink":"http://lincentma.men/categories/面试/"}],"tags":[{"name":"OJ","slug":"OJ","permalink":"http://lincentma.men/tags/OJ/"},{"name":"skill","slug":"skill","permalink":"http://lincentma.men/tags/skill/"}]},{"title":"美团二面记录","slug":"meituan_interview_2","date":"2017-09-07T09:13:37.000Z","updated":"2017-09-07T09:15:37.195Z","comments":true,"path":"meituan_interview_2.html","link":"","permalink":"http://lincentma.men/meituan_interview_2.html","excerpt":"","text":"美团二面记录 第一次遇见女面试官进行面试。自己学到更多的东西。 项目相关 面试官听了我的项目，差异公司没有这样的解决方案，需要自己再去造轮子吗？这也是自己的当时最晚的感受，也就是自己理解的常说的CRUD接口操作，但是这个项目给自己最大的感受是在于自己熟悉了整套开发上线流程，明白各个部门之间的分工协作过程。 自己的目标就是希望可以自己在后端写出属于自己的通用轮子。 如何考虑故障？单台提供数据查询有没有更好的方案？ 基础知识 Redis的基本数据结构 String类型：将String类型作为元素值； Lists类型：根据插入顺序的String类型为元素的集合，基于LinkedList实现，非Array型； Sets类型：无重复且无序的String类型为元素的集合； Sorted Set类型：无重复且有序的String类型为元素的集合； Hashes类型：映射域到值类型的数据结构，其中域和值都是String类型； Redis使用场景？ 会话缓存（Session Cache）:用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。用户的购物车信息。 全页缓存（FPC）:Redis有磁盘的持久化，用户也不会看到页面加载速度的下降。 队列：Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 排行榜/计数器。Redis在内存中对数字进行递增或递减的操作实现的非常好。“ZRANGE user_scores 0 10 WITHSCORES” 发布/订阅。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统。 参考文章：Redis 的 5 个常见使用场景 如何设计多级缓存结构？考虑哪些方面？ 多级缓存，即在整个系统架构的不同系统层级进行数据缓存，以提升访问效率，这也是应用最广的方案之一。 整体流程如上图所示： 首先接入Nginx将请求负载均衡到应用Nginx，此处常用的负载均衡算法是轮询或者一致性哈希，轮询可以使服务器的请求更加均衡，而一致性哈希可以提升应用Nginx的缓存命中率；后续负载均衡和缓存算法部分我们再细聊； 接着应用Nginx读取本地缓存（本地缓存可以使用Lua Shared Dict、Nginx Proxy Cache（磁盘/内存）、Local Redis实现），如果本地缓存命中则直接返回，使用应用Nginx本地缓存可以提升整体的吞吐量，降低后端的压力，尤其应对热点问题非常有效；为什么要使用应用Nginx本地缓存我们将在热点数据与缓存失效部分细聊； 如果Nginx本地缓存没命中，则会读取相应的分布式缓存（如Redis缓存，另外可以考虑使用主从架构来提升性能和吞吐量），如果分布式缓存命中则直接返回相应数据（并回写到Nginx本地缓存）； 如果分布式缓存也没有命中，则会回源到Tomcat集群，在回源到Tomcat集群时也可以使用轮询和一致性哈希作为负载均衡算法； 在Tomcat应用中，首先读取本地堆缓存，如果有则直接返回（并会写到主Redis集群），为什么要加一层本地堆缓存将在缓存崩溃与快速修复部分细聊； 作为可选部分，如果步骤4没有命中可以再尝试一次读主Redis集群操作，目的是防止当从有问题时的流量冲击； 如果所有缓存都没有命中只能查询DB或相关服务获取相关数据并返回； 步骤7返回的数据异步写到主Redis集群，此处可能多个Tomcat实例同时写主Redis集群，可能造成数据错乱，如何解决该问题将在更新缓存与原子性部分细聊。 整体分了三部分缓存：应用Nginx本地缓存、分布式缓存、Tomcat堆缓存，每一层缓存都用来解决相关的问题，如应用Nginx本地缓存用来解决热点缓存问题，分布式缓存用来减少访问回源率、Tomcat堆缓存用于防止相关缓存失效/崩溃之后的冲击。 使用消息机制同步缓存 把写缓存改成写消息，通过消息通知数据变更； 同步缓存系统会订阅消息，并根据消息进行更新缓存； 数据一致性可以采用：消息体只包括ID、然后查库获取最新版本数据；通过时间戳和内容摘要机制(MD5)进行缓存更新； 如上方法也不能保证消息不丢失，可以采用：应用在本地记录更新日志，当消息丢失了回放更新日志；或者采用数据库binlog，采用如canal订阅binlog进行缓存更新。 对于长尾访问的数据、大多数数据访问频率都很高的场景、缓存空间足够都可以考虑不过期缓存，比如用户、分类、商品、价格、订单等，当缓存满了可以考虑LRU机制驱逐老的缓存数据。 维度化缓存与增量缓存 将数据进行维度化并增量更新（只更新变的部分）。尤其如上下架这种只是一个状态变更，但是每天频繁调用的，维度化后能减少服务很大的压力。 轮询的优点：到应用Nginx的请求更加均匀，使得每个服务器的负载基本均衡；轮询的缺点：随着应用Nginx服务器的增加，缓存的命中率会下降，比如原来10台服务器命中率为90%，再加10台服务器将可能降低到45%；而这种方式不会因为热点问题导致其中某一台服务器负载过重。 一致性哈希的优点：相同请求都会转发到同一台服务器，命中率不会因为增加服务器而降低；一致性哈希的缺点：因为相同的请求会转发到同一台服务器，因此可能造成某台服务器负载过重，甚至因为请求太多导致服务出现问题。 正常情况采用一致性哈希，如果某个请求类型访问量突破了一定的阀值，则自动降级为轮询机制。另外对于一些秒杀活动之类的热点我们是可以提前知道的，可以把相关数据预先推送到应用Nginx并将负载均衡机制降级为轮询。 参考文章：应用多级缓存模式支撑海量读服务 这是一篇非常好的文章！ 主键和唯一键的区别？ 索引是存储在数据库中的一个物理结构，键纯粹是一个逻辑概念。键代表创建来实施业务规则的完整性约束。索引和键的混淆通常是由于数据库使用索引来实施完整性约束。 （1）主键约束和唯一键约束均会隐式创建同名的唯一索引，当主键约束或者唯一键约束失效时，隐式创建的唯一索引会被删除； （2）主键约束要求列值非空，而唯一键约束和唯一索引不要求列值非空； （3）相同字段序列不允许重复创建索引。 生产者消费者实现需要考虑哪几方面？如何考虑存储？ 生产者仅仅在仓储未满时候生产，仓满则停止生产。 消费者仅仅在仓储有产品时候才能消费，仓空则等待。 当消费者发现仓库没产品可消费时候会通知生产者生产。 生产者在生产出可消费产品时候，应该通知等待的消费者去消费。 对于存储中介，它肯定是一块具有额定大小的存储空间，而这个存储空间一般来说具有FIFO的数据结构，比如JDK内置了具有阻塞作用的有界队列：ArrayBlockingQueue、LinkedBlockingQueue。 参考文章：生产者/消费者模式 如何实现O(1)时间复杂度求栈的最小值？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com;import java.util.Stack;/** * Created by ml on 2017/9/7. * 原栈中，每次添加一个新元素时，就和辅助栈的栈顶元素相比较，如果新元素小，就把新元素的值放到辅助栈和原栈中，如果新元素大，就把元素放到原栈中；出栈时，如果原栈跟辅助栈元素相同，都弹出，否则只弹出原栈栈顶元素. */public class Stackmin &#123; public static void main(String[] args) &#123; AdvancedStack&lt;Integer&gt; stack = new AdvancedStack&lt;Integer&gt;(); stack.push(5); System.out.println(stack.getMin()); stack.push(7); System.out.println(stack.getMin()); stack.push(3); System.out.println(stack.getMin()); stack.push(9); System.out.println(stack.getMin()); stack.push(3); System.out.println(stack.getMin()); stack.pop(); System.out.println(stack.getMin()); &#125; static class AdvancedStack&lt;T extends Comparable&gt; &#123; Stack&lt;T&gt; stackNormal = new Stack&lt;T&gt;(); Stack&lt;T&gt; stackMin = new Stack&lt;T&gt;(); Stack&lt;T&gt; stackMax = new Stack&lt;T&gt;(); public void push(T e) &#123; stackNormal.push(e); //最小栈为空或者push的值小于最小栈的栈顶元素 if (stackMin.isEmpty() || e.compareTo(stackMin.peek()) &lt; 0) &#123; stackMin.push(e); &#125; else if (e.compareTo(stackMin.peek()) &gt; 0) &#123; stackMin.push(stackMin.peek()); &#125; if (stackMax.isEmpty() || e.compareTo(stackMin.peek()) &gt; 0) &#123; stackMax.push(e); &#125; else if (e.compareTo(stackMax.peek()) &lt; 0) &#123; stackMax.push(stackMax.peek()); &#125; &#125; public T pop() &#123; if (!stackNormal.isEmpty() &amp;&amp; !stackMin.isEmpty() &amp;&amp; !stackMax.isEmpty()) &#123; T e = stackNormal.pop(); stackMin.pop(); stackMax.pop(); return e; &#125; else &#123; return null; &#125; &#125; public T getMin() &#123; return stackMin.peek(); &#125; public T getMax() &#123; return stackMax.peek(); &#125; &#125;&#125; 如何设计即时通信系统，采用TCP还是UDP？ 现在的移动端IM、推送系统，既面对移动互联网的不确定性，又面对智能终端频繁的系统休眠、网络切换，还要考虑服务端的承载成本，对于在线服务而言UDP是比TCP更适合的方式。但是由于数据完整性、安全性的需要，又不应完全放弃TCP的可靠与安全。 两种通信协议同时使用，各有侧重。UDP用于保持大量终端的在线与控制，应用与业务则通过TCP去实现。这个和FTP服务控制与数据分离，采取不同的连接，有异曲同工之处。 参考文章:移动端IM/推送系统的协议选型：UDP还是TCP？ 抽象类的作用？ 通过继承它实现多态。设计抽象类是为了继承它，实现代码的重用性，可以使得由它所派生的所有类具有相同的接口，使用更加灵活抽象，可以使多态的作用发挥的更好，还有一点就是程序的结构更易于更改和扩充。 接口就是更纯粹的抽象类。 kafka有了解过吗？ kafka学习笔记：知识点整理 开放问题 对你最大作用的项目？ OK 学校期间最有挑战性的项目？ 应该侧重于技术方面的挑战 除了项目和实习，你是如何学习新的技术？ OK 除了以上技术，你最喜欢的技术是什么？ 前沿技术？？","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"meituan","slug":"meituan","permalink":"http://lincentma.men/tags/meituan/"}]},{"title":"美团点评一面","slug":"meituan_interview","date":"2017-09-01T14:19:46.000Z","updated":"2017-09-01T14:21:31.584Z","comments":true,"path":"meituan_interview.html","link":"","permalink":"http://lincentma.men/meituan_interview.html","excerpt":"","text":"美团点评一面 强大的基础面试让我亚历山大半个小时多的面试，很多问题自己没有扎实的理解没有深入，导致问的越多自己越慌张基础是深度的基础，深度是基础的升华 1. 介绍Sug项目1.1 项目之间的关联？ 项目背景需求讲述。 1.2 项目中最有挑战性？ 项目难点说明。 1.3 数据量是多少？ 感觉考察对于项目细节的总结。 1.4 map reduce配置多少？ Map的数量经常是由输入数据中的DFS块的数量来决定的。正确的reduce任务的个数应该是0.95或者1.75 ×（节点数 ×mapred.tasktracker.tasks.maximum参数值）。 1.5 调整的container数量是多少？ 步骤1：用户将应用程序提交到ResourceManager上； 步骤2：ResourceManager为应用程序ApplicationMaster申请资源，并与某个NodeManager通信，以启动ApplicationMaster； 步骤3：ApplicationMaster与ResourceManager通信，为内部要执行的任务申请资源，一旦得到资源后，将于NodeManager通信，以启动对应的任务。 步骤4：所有任务运行完成后，ApplicationMaster向ResourceManager注销，整个应用程序运行结束。上述步骤中，步骤2~3涉及到资源申请与使用，而这正是Container出现的地方。 （1） Container是YARN中资源的抽象，它封装了某个节点上一定量的资源（CPU和内存两类资源）。它跟Linux Container没有任何关系，仅仅是YARN提出的一个概念（从实现上看，可看做一个可序列化/反序列化的Java类）。（2） Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster；（3） Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令（可以使任何命令，比如java、Python、C++进程启动命令均可）以及该命令执行所需的环境变量和外部资源（比如词典文件、可执行文件、jar包等）。 Container数量=min (2CORES, 1.8DISKS, (可用内存)/最低Container的大小) 每个Container的内存大小 = max(最小Container内存大小, (总可用内存) /Container数)) 例如：集群的节点有 12 CPU cores, 48 GB RAM, and 12 磁盘.预留内存= 6 GB 系统预留 + 8 GB HBase预留最小Container内存大小 = 2 GB Container数 = min (212, 1.8 12, (48-6)/2) = min (24, 21.6, 21) = 21 每个Container的内存大小 = max (2, (48-6)/21) = max (2, 2) = 2 1.6 定时crontab挂掉有其他方式保证吗？ 百度了下，有crontab误删的解决方案：获取完整日志和cmd日志，获取所有crontab指令，从crontab.txt 中找出每一条指令，然后在cmd_temp 中匹配运行次数，重新编辑crontab添加恢复。 123456#!/bin/bash# 每天对crontab 进行备份 ，同时删除最近15天的数据DATE=$(date +%Y%m%d)crontab -l &gt; /home/work/bak/crontab_$DATE.bakfind /home/work/bak/ -mtime +15 -name &apos;*.bak&apos; -exec rm -rf &#123;&#125; \\; 自己第二个理解是，crontab在单台布置任务，如果该台机器发生故障的解决方案？ 多台备份，一主多从，故障切换。多台机器上的定时任务——cronsun。cronsun 支持：多机单任务(防止单机挂掉任务不按时执行)。 1.7 Hadoop Streaming相对于传统的优点？ Hadoop Streaming是Hadoop提供的一个编程工具，它允许用户使用任何可执行文件或者脚本文件作为Mapper和Reducer。 mapper和reducer会从标准输入中读取用户数据，一行一行处理后发送给标准输出。Streaming工具会创建MapReduce作业，发送给各个tasktracker，同时监控整个作业的执行过程。如果一个文件（可执行或者脚本）作为mapper，mapper初始化时，每一个mapper任务会把该文件作为一个单独进程启动，mapper任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。 同时，mapper收集可执行文件进程标准输出的内容，并把收到的每一行内容转化成key/value对，作为mapper的输出。 默认情况下，一行中第一个tab之前的部分作为key，之后的（不包括tab）作为value。如果没有tab，整行作为key值，value值为null。对于reducer，类似。以上是Map/Reduce框架和streaming mapper/reducer之间的基本通信协议。 优点：只要是支持stdin stdout的语言都可以用来实现MapReduce算法，这对于非Java程序员来编写MapReduce程序非常友好。 缺点：慢；无法避免的数据类型转换；archive，file分发对于I/O的压力。 1.8 关于Hadoop本身的架构你有哪些了解？Yarn？（这个地方反复听还是没有听清）? 自己了解的不多，需要积累。 推荐董的博客。 1.9 MapReduce执行过程？ 1.预先加载本地的输入文件2.经过MAP处理产生中间结果3.经过shuffle将key相同的中间结果分配到同一个节点去处理4.Reduce处理产生结果输出5.将结果保存在hdfs上 1.10 你了解多少MapRedce？ 自己了解的不多，需要积累。 推荐董的博客。 2. 智能快递箱项目——Java的SSH框架 本科项目，细节遗忘比较多，但是写在简历上，就必须完全掌握。面试官很好，他采用一站到底的形式，让我明白技术深度的重要性。 2.1 SSH框架对于传统的JSP、Servlet这些的优势？ 传统J2EE开发模式：Jsp+Servlet+Javabean 其实传统J2EE的缺点就是SSH框架中的优点，框架是为了解决一个又一个在Web开发中所遇到的问题而诞生的。不同的框架，都是为了解决不同的问题。 从最开始的JSP，在Html中嵌入Java逻辑，但是功能复杂后，Html混乱的结构，数据库事务以及日志，功能逻辑固化，遇到需求更改，往往需要重写一个JSP文件。 所以有了使用servlet来处理那些业务逻辑，把JSP中的Java业务逻辑剥离抽象出来。这样的好处在于流程更加清晰，虽然只是代码从JSP移动到了Servlet。。然而，为了这么点干净，付出的是为每个servlet都在web.xml里面去做一个url的请求配置。 最终，我们需要的是：1. 数据 2. 页面展示 3. 处理具体业务的场所，任何形式实现的功能内部的核心元素都是这三种。 那么这就是MVC的概念：数据 ———— Model 页面展示 ———— View 处理具体业务的场所 ———— Control 框架的典型的三层构架体现MVC（模型Model,视图View和控制）思想、良好的可扩展性、良好的可维护性和优秀的解耦性。 框架将实现功能的流程清晰化、分离化、独立化之后，各个模块之间的通信、异常等问题就是新的问题，就是SSH框架需要解决的问题。 Struts的优点： Struts2 Action对象为每一个请求产生一个实例，因此没有线程安全问题。 Struts2强大的标签库提高开发效率。 页面脉络清晰，通过查看配置文件把握整个系统的关系，方便开发人员岗位流动时的维护。 Spring的优点： spring提高了一种对象管理方法，有效的组织系统中间层对象。是框架的完美“粘合剂”。 IOC和AOP Hibernate的优点： hibernate是JDBC轻量级的封装，占用内存较少，性能比较高。 优秀的ORM框架。 Hibernate兼容JDBC。 参考文章：深入浅出的理解框架（Struts2、Hibernate、Spring）与 MVC 设计模式 2.2 你的意思是Strtus框架是在JSP上做了一层封装？ Struts是对Servlet控制页面跳转、类型转换等做了进一步封装，解决了Servlet开发带来的诸多问题，有利于维护。 2.3 JSP中有一些内置的对象？ NO. 内置对象 类型 作用 1 pageContext javax.servlet.jsp.PageContext 使用它可以访问到本页面中所有其他对象，例如前面已经描述的request、response以及application对象等。 2 request javax.servlet.http.HttpServletRequest request内置对象中包含了有关浏览器请求的信息，并提供了多个用于获取cookie、header以及session内数据的方法。 3 response javax.servlet.http.HttpServletResponse response对象与request对象相对应，它是用于响应客户请求，向客户端输出信息。response对象提供了多个方法用来处理HTTP响应。 4 session javax.servlet.http.HttpSession session是与请求有关的会话期，用来表示和存储当前页面的请求信息。 5 application javax.servlet.ServletContext 用于实现用户之间的数据共享（多使用于网络聊天系统）。一般来说，一个用户对应着一个session，并且随着用户的离开session中的信息也会消失，所以不同客户之间的会话必须要确保某一时刻至少有一个客户没有终止会话；而applicat则不同，它会一直存在，类似于系统的“全局变量”，而且只有一个实例。 6 config javax.servlet.ServletConfig 在Servlet初始化的时候，JSP引擎通过config向它传递信息。这种信息可以是属性名/值匹配的参数，也可以是通过ServletContext对象传递的服务器的有关信息。 7 out javax.servlet.jsp.JspWriter out对象用于向客户端发送文本数据。 8 page java.lang.Object page对象有点类似于Java编程中的this指针，就是指当前JSP页面本身。 9 exception java.lang.Throwable exception内置对象是用来处理页面出现的异常错误。 2.4 JSP是如何在web容器中跑起来的？经历那几个阶段？如何传输？ 当客户端第一次请求一个jsp资源的时候，jsp引擎会查找这个jsp文件并且将它转换成为一个java文件，然后编译成为一个servlet类。 Web容器实例化这个servlet。 Web容器调用init()方法。在这个init方法中，调用针对jsp的JspInit()方法。 Web容器调用service()方法。在service()方法中，调用_jspService()方法。 JSP和Servlet的本质是一样的，因为JSP最终需要编译成Servlet才能运行，换句话说JSP是生成Servler的草稿文件。 参考文章:jsp是如何被容器调用和执行的？ 2.5 Servlet的生命周期？ 初始化阶段：调用init()方法 响应客户请求阶段：调用service()方法 终止阶段：调用destroy()方法 JSP的优点是擅长于网页制作，生成动态页面比较直观，缺点是不容易跟踪与排错。Servlet是纯Java语言，擅长于处理流程和业务逻辑，缺点是生成动态网页不直观。 2.7 SSH中Spring、Hibernate各自负责的角色？ Spring充当了管理容器的角色，起到的主要作用是解耦，创建对象处理对象的依赖关系以及框架整合。IOC、AOP。 Struts主要控制逻辑关系的处理。 hibernate 是数据持久化层。 2.8 SSH中的ORM？ ORM框架可作为面向对象程序语言和数据库之间的桥梁。ORM框架是面向对象程序设计语言与关系数据库发展不同步时的中间解决方案。 ORM的基本映射方式： 数据类型映射模式 类映射模型 关联映射模式 引用映射模式 Employee.hbm.xml 对象的映射 (映射文件)hibernate.cfg.xml 数据库连接配置、加载所用的映射(*.hbm.xml) 123456789101112131415161718192021222324252627282930313233343536package sram.hello;import java.util.Date;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.Transaction;import org.hibernate.cfg.Configuration;import org.junit.Test;public class App &#123; @Test public void testHello() throws Exception&#123; //对象 Employee emp = new Employee(); emp.setEmpName(&quot;Alice&quot;); emp.setWorkDate(new Date()); //获取加载配置文件的管理类对象 Configuration config = new Configuration(); config.configure();//默认加载src/hibernate.cfg.xml文件 //创建session工厂 SessionFactory sf = config.buildSessionFactory(); //创建session(代表一个会话，与数据库连接的会话) Session session = sf.openSession(); //开启事务 Transaction tx = session.beginTransaction(); //保存-数据库 session.save(emp); //提交事务 tx.commit(); //关闭 session.close(); sf.close(); &#125;&#125; 2.9 通常把什么样的功能放在Spring中？ 核心容器(Spring core) 核心容器提供Spring框架的基本功能。Spring以bean的方式组织和管理Java应用中的各个组件及其关系。Spring使用BeanFactory来产生和管理Bean，它是工厂模式的实现。BeanFactory使用控制反转(IoC)模式将应用的配置和依赖性规范与实际的应用程序代码分开。BeanFactory使用依赖注入的方式提供给组件依赖。 Spring上下文(Spring context) Spring上下文是一个配置文件，向Spring框架提供上下文信息。Spring上下文包括企业服务，如JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring面向切面编程(Spring AOP) 通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring框架中。所以，可以很容易地使 Spring框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO模块 DAO模式主要目的是将持久层相关问题与一般的的业务规则和工作流隔离开来。Spring 中的DAO提供一致的方式访问数据库，不管采用何种持久化技术，Spring都提供一直的编程模型。Spring还对不同的持久层技术提供一致的DAO方式的异常层次结构。 Spring ORM模块 Spring 与所有的主要的ORM映射框架都集成的很好，包括Hibernate、JDO实现、TopLink和IBatis SQL Map等。Spring为所有的这些框架提供了模板之类的辅助类，达成了一致的编程风格。 Spring Web模块 Web上下文模块建立在应用程序上下文模块之上，为基于Web的应用程序提供了上下文。Web层使用Web层框架，可选的，可以是Spring自己的MVC框架，或者提供的Web框架，如Struts、Webwork、tapestry和jsf。 Spring MVC框架(Spring WebMVC) MVC框架是一个全功能的构建Web应用程序的MVC实现。通过策略接口，MVC框架变成为高度可配置的。Spring的MVC框架提供清晰的角色划分：控制器、验证器、命令对象、表单对象和模型对象、分发器、处理器映射和视图解析器。Spring支持多种视图技术。 2.10 Hibernate内对象session的生命周期？ Hibernate 三种状态 临时状态（Transient）：在通过new关键字，实例化一个对象开始，该对象就进入了临时状态，但它还没有被持久化，没有保存在Session当中。 持久化状态（Persistent）：对象被加入到Session缓存当中，如通过session.save(entity)，Hibernate把实体保存到seesion当中，entity就处在持久化状态中。 游离状态（Detached）：对象脱离了session缓存，如通过session清理，将对象保存到数据库中，原来在session中的对象仍然与内存中，该对象就处于游离状态。 hibernate Session的生命周期受到其自身属性和方法的影响，简单的说： SessionFactory的openSession() 方法会开启一个session。 Session的flushMode会决定session何时进行flush。 Session的flush()方法会对session进行强制flush。 Session的close()方法会关闭session。 读取并解析配置文件 读取并解析映射信息，创建SessionFactory 打开Sesssion 创建事务Transation 持久化操作 提交事务 关闭Session 关闭SesstionFactory 当一个对象被实例化出来以后，该对象是临时状态，当调用方法session.save(entity)，后该对象被加入到session缓存中，进入持久化状态，这时数据库中还不存在相关的记录，当session提交数据库事务时，这里隐含做了两件事，一件事是隐式调用session.flush()，其作用先是清理缓存（相当于调用了session.clear()），再生成一条对应的insert语句，但该语句还没有提交，第二件事是对刚才生成的语句进行提交，从而在数据库中生成了对应的记录。至此原entity对象就在数据库中生成了一条对应的记录，而它本身也脱离了session缓存，处于游离状态，该对象经过垃圾回收机制处理被回收。一个hibernate的保存对象过程就此结束。 Hibernate一级缓存又称为“Session的缓存”。Session的缓存是事务范围的缓存（Session对象的生命周期通常对应一个数据库事务或者一个应用事务）。 Hibernate二级缓存又称为“SessionFactory的缓存”。由于SessionFactory对象的生命周期和应用程序的整个过程对应，因此Hibernate二级缓存是进程范围或者集群范围的缓存。适合1) 很少被修改的数据 2) 不是很重要的数据，允许出现偶尔并发的数据 3) 不会被并发访问的数据 4) 常量数据 。 当Hibernate根据ID访问数据对象的时候，首先从Session一级缓存中查；查不到，如果配置了二级缓存，那么从二级缓存中查；如果都查不到，再查询数据库，把结果按照ID放入到缓存删除、更新、增加数据的时候，同时更新缓存。 Session的延迟加载实现要解决两个问题：正常关闭连接和确保请求中访问的是同一个session。Hibernate session就是java.sql.Connection的一层高级封装，一个session对应了一个Connection。http请求结束后正确的关闭session（过滤器实现了session的正常关闭）；延迟加载必须保证是同一个session（session绑定在ThreadLocal）。 2.11 SSH，SSM请求过程？ SSH jsp页面，提交表单或者点击链接会触发一个action。 action交给struts2处理，读取struts.xml文件，在配置中找到对应的action。 根据struts.xml文件中找到的class=”XXXAction”交给spring，读取Spring容器的配置文件/WebRoot/WEB-INF/applicationContext.xml文件。根据applicationContext.xml配置文件找到xxx.xxx.action.xxxAction类，其中有一个属性xxxService,并提供setxxxService()方法，由applicationContext.xml文件得知该xxxService对象由Spring容器依赖注入，set注入。 取得xxxService对象(接口对接口实现类的一个引用)后，调用它的方法。后面的就是访问DAO了。 执行的结果会在action的对应的方法中以字符串的形式给出。然后根据配置文件中的result.找到下一步要执行的动作，是跳转到页面显示还是继续交给其他的action处理。 SSM 2.12 Spring如何实现AOP，那几种方式实现，内部如何实现？ Spring提供了4种实现AOP的方式： 经典的基于代理的AOP @AspectJ注解驱动的切面 纯POJO切面 注入式AspectJ切面 内部实现：动态代理就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 2.13 Struts2中的拦截器的实现运用哪一种设计模式？ 拦截器用到了代理模式，过滤器用到了责任链的设计模式。拦截器栈（Interceptor Stack）：将拦截器按一定的顺序联结成一条链，在访问被拦截的方法时，Struts2拦截器链中的拦截器就会按其之前定义的顺序依次调用。类似于FilterChain，但又有很大的不同，比如FilterChain需要在编写doFilter方法时自行实现返回时的过滤以及链的向下执行，并且是在Servlet容器执行的这些操作。相反Intercetor是通过反射，通过XWork容器调用，自动返回拦截。 3. 基础知识3.1 TCP如何保证消息传递的顺序？ 主机每次发送数据时，TCP就给每个数据包分配一个序列号并且在一个特定的时间内等待接收主机对分配的这个序列号进行确认， 如果发送主机在一个特定时间内没有收到接收主机的确认，则发送主机会重传此数据包。 接收主机利用序列号对接收的数据进行确认，以便检测对方发送的数据是否有丢失或者乱序等， 接收主机一旦收到已经顺序化的数据，它就将这些数据按正确的顺序重组成数据流并传递到高层进行处理。 3.2 出现拥塞如何解决？如何进行流量控制？ TCP的流量控制是利用滑动窗口机制实现的，流量的端到端控制的实现是接收方在返回的ACK中会包含自己的接收窗口的大小，以控制发送方的数据发送。TCP的窗口单位是字节，不是报文段，发送方的发送窗口不能超过接收方给出的接收窗口的数值。 网络中的链路容量和交换结点中的缓存和处理机都有着工作的极限，当网络的需求超过它们的工作极限时，就出现了拥塞。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。 慢开始（Slow-Start）和拥塞避免（Congestion Avoidance）结合 （1）当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。（2）当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。（3）当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 快重传（Fast Retransmit）和快恢复（Fast Recovery）结合 （1）当发送方在cwnd=24时连续收到三个重复确认，就把慢开始门限ssthresh减半，就是上图中的24修改为12。这是为了预防网络发生拥塞。（2）与慢开始不同之处是现在不执行慢开始算法，而是把cwnd值设置为慢开始门限ssthresh减半后的数值，即cwnd不是设置为1而是设置为12，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。这里为什么替换掉了慢开始算法呢，这是因为收到重复的ACK不仅仅告诉我们一个分组丢失了，由于接收方只有在收到另一个报文段时才会产生重复的ACK，所以还告诉我们该报文段已经离开了网络并进入了接收方的缓存。也就是说，在收发两端之间仍然有流动的数据，而我们不想执行慢启动来突然减少数据流。无论在慢开始阶段还是在拥塞避免阶段，只要发送方没有收到确认通知判断网络出现拥塞，就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半，上例中是把发送方窗口值24修改为12。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 参考文章：NetWork——TCP的流量控制和拥塞控制 3.3 HTTP状态码以3开头的含义？ 重定向。基本上会配合Location首部字段来使用。301、302、304是HTTP1.0定义的，303、307是HTTP1.1定义的。 301：永久性重定向，该状态码表示请求的资源已被分配了新的URI，以后应使用Location指定的URI。 302：表示资源是临时性移动，已移动资源对应的URI将来还可能发生改变。301和302标准是禁止将post请求改变为get请求的，即原先使用post的请求，收到301和302的响应时，不能使用get请求Location指定的URI，而是应该得到用户的确认，然后使用post请求Location指定的URI。但是很多浏览器为了方便，直接略过用户确认，并使用get请求Location指定的URI。 303：与302类似。标准明确规定客户端应使用get请求Location指定的URI。 304：304其实和重定向没有任何关系。当客户端缓存了目标资源但不确定该缓存资源是否是最新版本的时候,就会发送一个条件请求.在Fiddler中,你可以在Headers Inspector查找相关请求头,这样就可以辨别出一个请求是否是条件请求。服务器会读取到这两个请求头中的值,判断出客户端缓存的资源是否是最新的,如果是的话,服务器就会返回HTTP/304 Not Modified响应。 307：相当于302，由于浏览器对于302标准并不遵守，因此定义307来代替302。post请求不会改变为get请求。 3.3 进程之间的通信方式？ 无名管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 高级管道(popen)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。 有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字( socket ) ： 套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"meituan","slug":"meituan","permalink":"http://lincentma.men/tags/meituan/"}]},{"title":"百度运维一面","slug":"baidu_interview","date":"2017-09-01T14:16:55.000Z","updated":"2017-09-01T14:19:30.235Z","comments":true,"path":"baidu_interview.html","link":"","permalink":"http://lincentma.men/baidu_interview.html","excerpt":"","text":"百度运维一面 问的最多的问题就是你为什么不在原来的部门留下来。这个问题回答的不是很自信。 面对自己的过去，明白自己想要的。 1. 实习经历梳理以及Sug项目介绍 还不错。 2. 关于正则表达式2.1 项目中正则表达式匹配效率 自己当时说自己主要是匹配一些策略类型，然后聊到匹配的效率，同阿伦如何一次匹配所有。因为自己之前是写了几个正则表达式去匹配各自的信息。 2.2 写出提取一行中所有满足格式的数据的正则表达式：例如提取a:3, b:2, c:1,… 如何提取？类似于匹配多个结果 1234567891011121314151617181920public void testRegex() &#123; String msg = &quot;Rect(x1=\\&quot;0\\&quot; y1=\\&quot;0\\&quot; x2=\\&quot;416\\&quot; y2=\\&quot;416\\&quot;)Rect(x1=\\&quot;1\\&quot; y1=\\&quot;2\\&quot; x2=\\&quot;413\\&quot; y2=\\&quot;414\\&quot;)&quot;; List&lt;String&gt; textList = new ArrayList&lt;String&gt;(); Pattern pattern = Pattern.compile(&quot;(x1=\\&quot;[^\\&quot;]*\\&quot;\\\\s*y1=\\&quot;[^\\&quot;]*\\&quot;\\\\s*x2=\\&quot;[^\\&quot;]*\\&quot;\\\\s*y2=\\&quot;[^\\&quot;]*\\&quot;)&quot;); Matcher matcher = pattern.matcher(msg); while (matcher.find()) &#123; textList.add(matcher.group(1)); &#125; for (String text : textList) &#123; try &#123; System.out.println(text); System.out.println(getValue(text, &quot;x1&quot;)); System.out.println(getValue(text, &quot;y1&quot;)); System.out.println(getValue(text, &quot;x2&quot;)); System.out.println(getValue(text, &quot;y2&quot;)); &#125; catch (Exception ex) &#123;&#125; &#125; &#125; 3. crontab实现原理以及使用格式 周期执行的任务一般由cron这个守护进程来处理。cron读取一个或多个配置文件，这些配置文件中包含了命令行及其调用时间。cron的配置文件称为“crontab”，是“cron table”的简写。 一旦cron进程启动，它就会读取配置文件，并将其保存在内存中，接着自己转入到休眠状态。以后每分钟会醒来一次检查配置文件，读取修改过的，并执行为这一刻安排的任务，然后再转入休眠。 实例5：每个星期一的上午8点到11点的第3和第15分钟执行命令： 3,15 8-11 1 command 4. 如何在日志中找到ip最大的10个，Linux命令以及设计算法实现 自己回答桶排序是错的，IP32位无法映射完所有的IP IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理。 按照IP地址的Hash(IP) % 1024的值，把海量IP日志分别存储到1024个小文件中，这样，每个小文件最多包含4MB个IP地址； 每一个文件中建立Top10的堆, 比较IP地址大小，遍历维护堆 12345678910111213141516171819202122232425262728293031 /** * 比较两个ip地址，如果两个都是合法地址，则1代表ip1大于ip2，-1代表ip1小于ip2,0代表相等； * 如果有其一不是合法地址，如ip2不是合法地址，则ip1大于ip2，返回1，反之返回-1；两个都是非法地址时，则返回0； * 注意此处的ip地址指的是如“192.168.1.1”地址，并不包括mask * @return */ public static int compareIpV4s(String ip1,String ip2) &#123; int result = 0; int ipValue1 = getIpV4Value(ip1); // 获取ip1的32bit值 int ipValue2 = getIpV4Value(ip2); // 获取ip2的32bit值 if(ipValue1 &gt; ipValue2) &#123; result = -1; &#125; else if(ipValue1 &lt;= ipValue2) &#123; result = 1; &#125; return result; &#125; public static int getIpV4Value(String ipOrMask) &#123; byte[] addr = getIpV4Bytes(ipOrMask); int address1 = addr[3] &amp; 0xFF; address1 |= ((addr[2] &lt;&lt; 8) &amp; 0xFF00); address1 |= ((addr[1] &lt;&lt; 16) &amp; 0xFF0000); address1 |= ((addr[0] &lt;&lt; 24) &amp; 0xFF000000); return address1; &#125; 最后遍历所有的堆取所有的Top10。 5. MySQL中联合索引（A，B，C）单独使用B会使用联合索引吗？联合索引为什么比单独的索引快？ SELECT * FROM TABLE_NAME WHERE COL1=’ABC’ AND COL2=123; 在2个列上单独创建索引，如果查询语句使用到，叫合并索引；如果是在2个列上创建组合索引，就叫组合索引。 单独的2个索引进行查找——索引合并，需要反复在2个索引表间进行跳转，这是造成速度慢的第一个影响。第2个影响是，假设满足COL1=’ABC’的数据有5行，满足COL2=123的数据有1000行。最坏的情况下（那5行在COL2的1000行最后面）需要扫描完COL2的1000行才能找到需要的数据，并不能达到快速查找的目的。 由于组合索引综合保存了COL1和COL2的数据，它不需要在2个索引表之间跳转，所以速度会更快。组合索引不需要像索引合并那样对索引的ROWID进行比较合并。 复合索引的优势只有查询复合索引的全部列，并且按索引的设置顺序查询，最重要的是一定要有首列的查询条件。 6. 手写堆排序维护最大的10个数 Key[i]&lt;=key[2i+1]&amp;&amp;Key[i]&lt;=key[2i+2]或者Key[i]&gt;=Key[2i+1]&amp;&amp;key[i]&gt;=key[2i+2]即任何一非叶节点的关键字不大于或者不小于其左右孩子节点的关键字。 step 1. 随意选出K个数，挑出这K个数的最小的数。这个过程可以用最小堆完成。 step 2. 在剩下的n – K个数中，挑出任意一个数m，和最小堆的堆顶进行比较，如果比最小堆的堆顶大，那么说明此数可以入围前K的队伍，于是将最小堆的堆顶置为当前的数m。 step 3. 调整最小堆。时间复杂度为Olg(K)，由于K是constant(常数级别)，所以时间复杂度可以认为是常数级别。 step 4. 重复进行step 2 ~ step 3，直到剩下的n – K个数完成。进行了n –constant次，时间复杂度为O(n lgK)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/** * Created by jeff on 16/5/11. */public class MinHeap &#123; // 堆的存储结构 - 数组 private int[] data; /** * 初始化堆中的数据,以int的最小值作为初始值 * * @param k */ public MinHeap(int k) &#123; this.data = new int[k]; for(int i=0;i&lt;k;i++)&#123; data[i]=Integer.MIN_VALUE; &#125; &#125; private void adjustHeap(int i) &#123; //获取左右结点的数组下标 int l = left(i); int r = right(i); // 这是一个临时变量，表示 跟结点、左结点、右结点中最小的值的结点的下标 int min = i; // 存在左结点，且左结点的值小于根结点的值 if (l &lt; data.length &amp;&amp; data[l]&lt;data[i])&#123; min = l; &#125; // 存在右结点，且右结点的值小于以上比较的较小值 if (r &lt; data.length &amp;&amp; data[r]&lt;data[min])&#123; min = r; &#125; // 左右结点的值都大于根节点，直接return，不做任何操作 if (i == min) return; // 交换根节点和左右结点中最小的那个值，把根节点的值替换下去 swap(i, min); // 由于替换后左右子树会被影响，所以要对受影响的子树再进行adjustHeap adjustHeap(min); &#125; /** * 获取右结点的数组下标 * @param i * @return */ private int right(int i) &#123; return (i + 1) &lt;&lt; 1; &#125; /** * 获取左结点的数组下标 * @param i * @return */ private int left(int i) &#123; return ((i + 1) &lt;&lt; 1) - 1; &#125; /** * 交换元素位置 * * @param i * @param j */ private void swap(int i, int j) &#123; int tmp = data[i]; data[i] = data[j]; data[j] = tmp; &#125; /** * 将数值加入到堆中 * * @param element */ public void add(int element) &#123; if(element&gt;data[0]) &#123; data[0] = element; adjustHeap(0); &#125; &#125; public int[] getData()&#123; return data; &#125; @Override public String toString()&#123; StringBuilder builder = new StringBuilder(); builder.append(&quot;&#123;&quot;); for (int i=0;i&lt;data.length;i++)&#123; builder.append(data[i]); if(i!=data.length-1)&#123; builder.append(&quot;,&quot;); &#125; &#125; builder.append(&quot;&#125;&quot;); return builder.toString(); &#125;&#125; 参考文章：算法——TOP K问题最小堆实现","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"baidu","slug":"baidu","permalink":"http://lincentma.men/tags/baidu/"}]},{"title":"蘑菇街二面记录","slug":"mogujie_interview_2","date":"2017-08-31T04:04:03.000Z","updated":"2017-08-31T04:05:36.334Z","comments":true,"path":"mogujie_interview_2.html","link":"","permalink":"http://lincentma.men/mogujie_interview_2.html","excerpt":"","text":"蘑菇街二面 全是项目对于活动类问题问的非常详细 项目中面试询问计数点1. 项目流程图- 略。 2. 订单中心接口的时延是多少？- 接口文档说明。 - 自己的理解应该是如何降低接口的响应时间？ - 从接口垂直与水平拆分（MapReduce）：项目没用到。。。 - 接口缓存与本地缓存 ：对于订单的实时获取，将用户的最新订单缓存到本地，然后计算结果放入缓存？随之带来存储问题？感觉可以把用户信息缓存，省去一部分查询用户的时间比较实际？ - 非核心流程异步化：类似于发消息，写日志，更新缓存等不会影响接口准确性的非核心流程，可以采用异步方式进行处理，不阻塞主计算逻辑处理。 - 内部并发：项目没有考虑。 - 参考文章：[如何减少接口响应时间](http://blog.csdn.net/xiaoxuan2015/article/details/51240872) 3. 高QPS下如何保证接口访问的稳定性？除了加服务器之外？- QPS（TPS）：每秒钟request/事务 数量 - 并发数： 系统同时处理的request/事务数 - 响应时间： 一般取平均响应时间 - 自己的理解应该是业务的解耦分拆，提高并发量。具体没有实践所以需要好好学习。 - 服务做到多少QPS，多长的耗时，应结合手头有限的资源、业务需求来制定。 - 参考文章：[美团团购订单系统优化记](https://tech.meituan.com/meituan_tuangou_order.html) - 非常有价值的文章。 4. 高QPS下哪一个模块的压力最大？如何解决？- 数据库访问。引入连接池。 - 如果在代码中显式为每次操作分别建立并释放资源，无疑增大了业务代码的复杂度，并且建立和释放连接的开销变得不可忽略。 5. 对于超时如何处理？- 尝试多调用一次 - 使用待处理队列 - 回滚数据 - 使用异步机制 - 参考文章：[【干货篇】调用其他系统http接口超时了，如何处理，方案汇总](http://blog.csdn.net/linsongbin1/article/details/50393383) - 自己的理解：对于活动类需要实时返回查询结果的，增加尝试调用次数是最合适的选择，要有错误策略来包容所有的错误类别。 - 实际项目中对于API接口调用是通过RAL调用，通过配置RAL的相关超时信息设置。具体设置搞忘了。 6. 如何确定每一次接口数据查询范围？极端数据情况占比多少？如何考虑这部分的数据的处理？- 针对于活动类接口，数据查询范围是根据活动规则制定，那么如何制定活动规则保证尽可能所有多的用户满足活动？ - 另一方面，调用其他接口获取数据量也需要根据实际需求去保证接口响应时间的可控性。 - API接口设计的考虑因素：是否需要为一小部分数据的需求去增加所有的适配工作？还是为了保证大部分的使用体验，对于小部分进行抛出错误的设计？ - 如何根据现有资源和条件进行权衡? 7. 活动中有用到消息队列吗？- 消息队列解决的是将突发大量请求转换为后端能承受的队列请求。 - NMQ。 - 参考文章：[nmq消息队列解析](http://www.cnblogs.com/lushilin/p/6209976.html) 8. 自己的学习目标和计划？","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"mogujie","slug":"mogujie","permalink":"http://lincentma.men/tags/mogujie/"}]},{"title":"蘑菇街一面记录","slug":"mogujie_interview","date":"2017-08-28T14:11:49.000Z","updated":"2017-08-28T14:13:31.385Z","comments":true,"path":"mogujie_interview.html","link":"","permalink":"http://lincentma.men/mogujie_interview.html","excerpt":"","text":"蘑菇街应用平台开发工程师一面 面试官给自己的建议是，按部就班，面试偶然性很多，没有办法一应俱全，打好自己的基础才是最好的办法。 Java基础知识 Java集合中哪些是线程安全的？ vector：就比arraylist多了个同步化机制（线程安全），因为效率较低，现在已经不太建议使用。在web应用中，特别是前台页面，往往效率（页面响应速度）是优先考虑的。 statck：堆栈类，先进后出。 hashtable：内部的方法基本都是synchronized。 enumeration：枚举，相当于迭代器。 Java集合其他的呢？ 1234567891011121314151617java.util.Collection [I]+--java.util.List [I] +--java.util.ArrayList [C] +--java.util.LinkedList [C] +--java.util.Vector [C] +--java.util.Stack [C]+--java.util.Set [I] +--java.util.HashSet [C] +--java.util.SortedSet [I] +--java.util.TreeSet [C]java.util.Map [I]+--java.util.SortedMap [I] +--java.util.TreeMap [C]+--java.util.Hashtable [C]+--java.util.HashMap [C]+--java.util.LinkedHashMap [C]+--java.util.WeakHashMap [C] ArrayList与LinkedList区别，增删改查时间复杂度区别？ ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 当操作是在一列数据的后面添加数据而不是在前面或中间,并且需要随机地访问其中的元素时,使用ArrayList会提供比较好的性能；当你的操作是在一列数据的前面或中间添加或删除数据,并且按照顺序访问其中的元素时,就应该使用LinkedList. ArrayList 是线性表（数组） get() 直接读取第几个下标，复杂度 O(1) add(E) 添加元素，直接在后面添加，复杂度O(1) add(index, E) 添加元素，在第几个元素后面插入，后面的元素需要向后移动，复杂度O(n) remove() 删除元素，后面的元素需要逐个移动，复杂度O(n) LinkedList 是链表的操作 get() 获取第几个元素，依次遍历，复杂度O(n) add(E) 添加到末尾，复杂度O(1) add(index, E) 添加第几个元素后，需要先查找到第几个元素，直接指针指向操作，复杂度O(n) remove() 删除元素，直接指针指向操作，复杂度O(1) 如何描述链表的数据结构 链表种类：单向链表、双向链表、单向循环链表和双向循环链表 单向链表：每个元素包含两部分：数据域和一个称为next的指针域。通过采用这种结构，next的指针域将按某一个方向指向其下一个元素。最后一个元素的next指针域指向NULL，即为空，它表示链表的末尾元素，链表的第一个元素称为“头”元素。 项目详细状况 报表日志项目流程 遇到哪些问题，如何解决？ MySQL手写语句1.三个表（school、class、student）连接查询，查找制定学校、学院、姓名的学号 1234SELECT 学生.id,学生.name FROM 学校,院系,学生WHERE 学校.id=院系.sid AND 学生.cid=院系.idAND 学校.name = &quot;大学&quot; and 院系.name = &quot;信息&quot; and 学生.name = &quot;小王&quot; 12345select 学生.id,学生.name from 学校 inner join 院系 on 学校.id=院系.sid inner join 学生 on 学生.cid=院系.id where 学校.name = &quot;大学&quot; and 院系.name = &quot;信息&quot; and 学生.name = &quot;小王&quot; 1子查询嵌套 from多表加上where和多个inner join表加上on条件查询结果一样的，都是做完笛卡尔积在从里面根据条件筛选数据。 优化核心在索引。 Linux手写语句 看过不如写过的感受 在123.txt中找到abc所在的行 grep –i “被查找的字符串” 文件名 cat 123.txt | grep -n ‘wang’ 输出所有找到的行数 grep -c “被查找的字符串” 文件名 cat 123.txt | grep -c ‘wang’ 输出所有匹配的行号 cat 123.txt | grep -n ‘wang’ | awk -F: ‘{print $1}’ grep命令原理 find命令是根据文件的属性进行查找。 grep是根据文件的内容进行查找，会对文件的每一行按照给定的模式(patter)进行匹配查找。 －c：只输出匹配行的计数。 －i：不区分大小写 －h：查询多文件时不显示文件名。 －l：查询多文件时只输出包含匹配字符的文件名。 －n：显示匹配行及行号。 －s：不显示不存在或无匹配文本的错误信息。 －v：显示不包含匹配文本的所有行。 grep是基于行的文本搜索 工具， 按匹配模式打印出符合条件的所有行。sed是流式文本编辑器，每次读入一行，处理一行； 开放性试题 如何设计斗地主的发牌过程 int CardValueArray[54]。我们将54个元素用来代表不同的牌。 CardValueArray[0——–12]: 方块A———方块K CardValueArray[13——-25]: 梅花A———梅花K CardValueArray[26——-38]: 红心A———红心K CardValueArray[39——-51]: 黑桃A———黑桃K CardValueArray[52] 小鬼 CardValueArray[53] 大鬼 规则：将数组分为4份。3份17张，1份3张（抢地主牌）。将3份17张牌，依次分发给3个不同的玩家。 方法一：Collections.shuffle(CardValueArray); 该方法方法用于随机排列随机使用一个默认的源指定的列表。然后依次取出17张牌即可。 方法二：顺序写入，随机生成0-53随机数，依次遍历交换，达到洗牌的目的。最后依次取出17张牌。 顺序遍历，每次生成一个随机位置，和当前位置的元素互换。运行时间是线性的。 面试官问的思路应该是如何把一个数组随机排列，并且减少交换次数？ 未来待续 参考文章：QQ 斗地主发牌是完全随机吗？","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"},{"name":"mogujie","slug":"mogujie","permalink":"http://lincentma.men/tags/mogujie/"}]},{"title":"华为成渝地区面试","slug":"huawei_interview","date":"2017-08-26T14:00:47.000Z","updated":"2017-08-26T14:02:09.363Z","comments":true,"path":"huawei_interview.html","link":"","permalink":"http://lincentma.men/huawei_interview.html","excerpt":"","text":"华为成渝地区面试 每一家公司的特点的不同就会决定了不同的面试风格以及不同的侧重点记录每一个不同，完善自己 一面业务面 重点在于项目细节 手绘项目流程图 项目实现细节 自己负责的部分详细说明 Java基础知识 try-catch-finally 执行顺序 不管有木有出现异常，finally块中代码都会执行； 当try和catch中有return时，finally仍然会执行； finally是在return后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在finally执行前确定的； finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值。 任何执行try 或者catch中的return语句之前，都会先执行finally语句，如果finally存在的话。如果finally中有return语句，那么程序就return了，所以finally中的return是一定会被return的，编译器把finally中的return实现为一个warning。 参考文章：有return的情况下try catch finally的执行顺序（最有说服力的总结）http://blog.csdn.net/kavensu/article/details/8067850 描述线程安全： 线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。 Java中对于线程安全的机制。 加锁。(1) 锁能使其保护的代码以串行的形式来访问，当给一个复合操作加锁后，能使其成为原子操作。一种错误的思想是只要对写数据的方法加锁，其实这是错的，对数据进行操作的所有方法都需加锁，不管是读还是写。(2) 加锁时需要考虑性能问题，不能总是一味地给整个方法加锁synchronized就了事了，应该将方法中不影响共享状态且执行时间比较长的代码分离出去。(3) 加锁的含义不仅仅局限于互斥，还包括可见性。为了确保所有线程都能看见最新值，读操作和写操作必须使用同样的锁对象。 不共享状态。(1) 无状态对象： 无状态对象一定是线程安全的，因为不会影响到其他线程。(2) 线程关闭： 仅在单线程环境下使用。 不可变对象。可以使用final修饰的对象保证线程安全，由于final修饰的引用型变量(除String外)不可变是指引用不可变，但其指向的对象是可变的，所以此类必须安全发布，也即不能对外提供可以修改final对象的接口。 参考文章：Java并发编程——线程安全及解决机制简介 二面综合面 综合面最大的感觉是类似压力面的形式，多个综合性问题，反应时间短. 自我介绍 自己的优缺点。紧接着用实例描述自己的缺点。 你认为自己的编程水平在你的专业是什么样的水平？ 自己认为目前行业前沿的变成设计趋势是哪些？如何理解微服务？ 你认为优秀的编程人员和普通的编程人员的区别在哪里？ 你认为代码能力的提高你会从哪些方面着手？ 在你的眼中华为是一个什么样的公司，为什么选择来到华为？ 你认为你来到华为自己具备什么样的实力？ 如果在华为你的付出与你的回报不成正比，或者说不公平的现象在你身上发生，你该怎么办？ 你在成都学习生活，你对于成都的印象，你的第一意向城市是哪里？ 未完待续 等待结果","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"}]},{"title":"好未来面试记录","slug":"haoweilai_interview","date":"2017-08-23T08:52:01.000Z","updated":"2017-08-23T08:53:25.876Z","comments":true,"path":"haoweilai_interview.html","link":"","permalink":"http://lincentma.men/haoweilai_interview.html","excerpt":"","text":"好未来面试记录 通过提前批筛选之后就是二次现场面试。 相对于机器学习的面试来说，自己的难度确实简单，需要查漏补缺的地方还是很多。 一面1.如何处理hadoop的数据倾斜问题针对问题是，请描述一个自己印象最深刻的项目 数据倾斜表现：ruduce阶段卡在99.99%，一直99.99%不能结束。 数据分布不均匀，导致大量的数据分配到了一个节点。 解决思路： 业务逻辑：我们从业务逻辑的层面上来优化数据倾斜。对于数据同一类型数量巨大，单独来做count，最后和其他数据做整合。这也是面试官想要引导我说出的方案 调参方面，Hadoop和Spark都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。 mapjoin方式 count distinct的操作，先转成group，再count 万能膏药：hive.groupby.skewindata=true left semi jioin的使用 设置map端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了IO读写和网络传输，能提高很多效率） 通过randint等函数把倾斜的数据分到不同的reduce上 ,解决数据倾斜问题。这是自己的回答。 参考文章： 漫谈千亿级数据优化实践：数据倾斜（纯干货） [Hive数据倾斜]http://www.cnblogs.com/skyl/p/4855099.html() 2.Java多线程线程池的参数意义- 线程池解决的两个问题： - 1）线程池通过减少每次做任务的时候产生的性能消耗来优化执行大量的异步任务的时候的系统性能。 - 2）线程池还提供了限制和管理批量任务被执行的时候消耗的资源、线程的方法。 Executors提供的一些工厂方法来快速创建ThreadPoolExecutor实例: 1.newCachedThreadPool创建一个可缓存线程池，如果线程池长度超处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 2.newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 3.newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 4.newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 5.newWorkStealingPool JDK8引入。返回一个ForkJoinPool类型的 executor，它的工作方法与其他常见的execuotr稍有不同。与使用一个固定大小的线程池不同，ForkJoinPools使用一个并行因子数来创建，默认值为主机CPU的可用核心数。 - 线程池构造器参数： - corePoolSize：核心池的大小，这个参数与后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； - maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程； - keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize：即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize；但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； - unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性 - 参考文章： - [Java线程池（ThreadPool）详解](http://www.cnblogs.com/kuoAT/p/6714762.html) 3.如何设置Java多线程个数最合理- 对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N+1时，通常能实现最优的效率。(即使当计算密集型的线程偶尔由于缺失故障或者其他原因而暂停时，这个额外的线程也能确保CPU的时钟周期不会被浪费。) - 如果是IO密集型应用，则线程池大小设置为2N+1 - 参考文章： - [java线程池大小为何会大多被设置成CPU核心数+1？](https://www.zhihu.com/question/38128980) 4.用尽可能多的方法去实现判断数组回文1. 处理小数字。使用数学方法。取每一位数字然后从后往前计算值，与原来数进行比较是否相等。 2. 处理大数字。使用字符串处理方式。因为回文数关于中心对称，只要比较对称的数即可。 3. 使用栈的思想。入栈一半元素，比较出栈元素与串中字符。 4. 回文判断不能使用正则表达式。正则表达式对应的是有限状态自动机，要达到你所说的需求，至少要图灵机。[正则表达式能否解决所有的字符串的模式匹配问题?](https://www.zhihu.com/question/32327623) - 参考文章： - [回文数的判断(三种方法)](http://blog.csdn.net/deaidai/article/details/71820164) 5.reverse函数源码实现- StringBuffer和StringBuilder常用到的方法，而String并没有这个牛逼的功能~~ 12345678910111213141516171819202122 public AbstractStringBuilder reverse() &#123; boolean hasSurrogates = false; int n = count - 1; //j初始化，长度-2再算术右移一位 j = (count-2)/2 //偶数长度，遍历一半次数，对调替换 //奇数长度，遍历一半-1次数，对调替换，中间值不用替换 for (int j = (n-1) &gt;&gt; 1; j &gt;= 0; j--) &#123; int k = n - j; char cj = value[j]; char ck = value[k]; value[j] = ck; value[k] = cj; if (Character.isSurrogate(cj) || Character.isSurrogate(ck)) &#123; hasSurrogates = true; &#125; &#125; if (hasSurrogates) &#123; reverseAllValidSurrogatePairs(); &#125; return this;&#125; 二面1.如何让接口发生改变时，使得调用方调用无感变化情况- 百度了下：采用调用中间代理方法 - 设计模式：Adpater。接口调用者不变。协议改变时由Adapter做转换。 1.session和cookie- Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中； - Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。","categories":[{"name":"面试记录","slug":"面试记录","permalink":"http://lincentma.men/categories/面试记录/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"}]},{"title":"百度运维部交流会学习笔记","slug":"baiduOPCoumminate","date":"2017-08-20T14:15:47.000Z","updated":"2017-08-20T14:17:07.727Z","comments":true,"path":"baiduOPCoumminate.html","link":"","permalink":"http://lincentma.men/baiduOPCoumminate.html","excerpt":"","text":"百度运维部交流会学习笔记地点：电子科技大学时间：2017.08.20 最大的感受：随着AI的不断发展，自己未来工作中会遇到越来越多AI场景，要去拥抱这样的变化。自己希望工作之后也可以回到母校为学弟学妹们带来这样一场业界前沿、职场相关的交流会。 1. AIOps AIOps 定义：按照 Gartner 的定义，AIOps 是 Algorithmic IT Operations，但是在人工智能时代，可能很多的人会把 AI 理解成 Artificial Intelligence，不去纠结定义，我觉得本质上，想要表达的意思是一样的，就是让运维具备机器学习和算法的能力。 特征： 高质量 可靠用户访问体验 低成本 高效率 发展过程：最开始的人工填单、到Web自动化。由于计算成本的下降，导致机器的数量快速增长，这就加剧了运维成本上升，智能运维代替人工，降低成本就应运而生。 讲解单机房故障的止损以及排查方案 BGW与BFE之间的故障 后端服务故障 自己的感受：运维中的海量日志信息蕴含的故障问题原因以及其他相关信息都是可以数据挖掘机器学习去实现。所有的大数据行业都存在这样的过程。关键在与运维知识库：将传统运维基于人的经验，操作行为、规则固化至知识库中。如何将问题的特征提取出来，标签尽可能细化，比如地点标签精确到大学，那么检测到该地点流量下降就可以推测该地点存在故障，此外还有日期特征，等等，如何将尽可能多地相关特征提取出来，匹配最佳的知识库中的运维方案，这也是机器学习的重点吧，自己在这方面的技术知识太少，需要制定学习计划完善自己。 2. BFE BFE: 百度统一前端，Baidu Front End 对标Google的GFE 它相对于整个应用是处于最前面直接处理用户的http请求。 采用Go语言编写 基于机器学习的动态优化，识别机器访问与真实访问 全站HTTPS，有效避免网络信息劫持 3. 职场建议 小事做好，自然轮到做大事 自我驱动去完成项目比分配任务去完成更加提升自己 运维是架构的学堂。听完了分享，我是认可这句话。单纯的从业务方面是专注于业务一点，运维是需要掌握上下游所有的流程，从这点来看，运维入门难，最后深度与广度是更优的。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lincentma.men/categories/学习笔记/"}],"tags":[{"name":"AIOps","slug":"AIOps","permalink":"http://lincentma.men/tags/AIOps/"},{"name":"BFE","slug":"BFE","permalink":"http://lincentma.men/tags/BFE/"},{"name":"Baidu","slug":"Baidu","permalink":"http://lincentma.men/tags/Baidu/"}]},{"title":"菜鸟物流简历评估面试","slug":"alibaba_interview_0820","date":"2017-08-20T12:50:55.000Z","updated":"2017-08-20T12:52:30.308Z","comments":true,"path":"alibaba_interview_0820.html","link":"","permalink":"http://lincentma.men/alibaba_interview_0820.html","excerpt":"","text":"菜鸟物流简历评估面试记录 刚睡醒的面试一塌糊涂，不打没有准备的仗。总结经验，扎实基础 问题记录1. 自我介绍两方面简单自我介绍：公司实习经历和学校项目。最后总结与申请职位的契合程度以及表明下自己的意愿。PS：感觉并没有什么用。。。 2. 你的简历中关于Java的很少，为什么还要选择投递研发工程师Java呢？ 当自己听到这个问题的时候，自己就懵了，和自己之前复习准备，参考其他菜鸟网络面经有很大的不一样。 每一位面试官都有自己的风格。 自己还是主动把学校项目中的Java部分阐述，以及在公司实习中采用PHP以及Python同时可以表现出自己的自学能力。 但是面试官的反馈是，从你的简历上无法看到Java相关的内容，无法谈论Java技术方面的问题。自己在项目中的SSH框架以及Java与Hadoop的项目经历放在实习经历后面，对于Java的具体实现功能自己之前因为一页简历的限制并没有详细叙述，这是自己的一个缺点。 自己面试完成后总结自己应该向面试官表达自己对于Java研发工程师岗位的浓厚兴趣以及自己在项目实践，博客记录等自己所做的工作。 自己对于压力面试的准备不是很充分，在面对压力以及工作之后的困难应该表现出进取向上的态度吧。 3. 那么你用过Java、PHP、Python这些不同的编程语言，你认为它们最大的区别在哪里？ 听到这个问题，我又懵了。自己的横向广度可以，但是纵向深度缺乏。 百度整理答案以及自己实践理解如下： Java：Java 编程语言是个简单、面向对象、分布式、解释性、健壮、安全与系统无关、可移植、高性能、多线程和动态的语言。 PHP：Hypertext Preprocessor的缩写，中文名：“PHP：超文本预处理器”）是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，入门门槛较低，易于学习，使用广泛，主要适用于Web开发领域。 Python：是一种面向对象、直译式计算机程序设计语言，Python语法简洁而清晰，具有丰富和强大的类库。它常被昵称为胶水语言，它能够很轻松的把用其他语言制作的各种模块（尤其是C/C++）轻松地联结在一起。 参考文章：C、C++、C#、Java、php、python语言的内在特性及区别 通过不同语言与MySQL数据库连接过程，发现不同语言之间的特点差异：六种流行的语言—C、C++、python、Java、php、C#比较 总结：自己在使用编程语言的时候，会用是基础，为什么这么用，这么用的好处，设计的原则这些都要好好理解。 4. Java基础知识 Object对象的方法有哪些？记得但是没有答全。重新阅读Java.lang.Object.java文件源码，温故知新。 Java中，用native关键字修饰的函数表明该方法的实现并不是在Java中去完成，而是由C/C++去完成，并被编译成了.dll，由Java去调用。 private static native void registerNatives();//返回此Object运行时类型 public final native Class&lt;?&gt; getClass();//返回对象的哈希值 public native int hashCode();//判断其他对象是否与此对象”相等” public boolean equals(Object obj);//创建并返回此对象的一个副本 protected native Object clone() throws CloneNotSupportedException;//返回此对象的字符串表示 public String toString();//唤醒在此对象监视器上等待的单个线程 public final native void notify();//唤醒在此对象监视器等待的所有线程 public final native void notifyAll();//在其他线程调用此对象的notify()方法或notifyAll()方法前，或者超过指定的时间量前，让当前线程等待 public final void wait() throws InterruptedException; public final native void wait(long timeout) throws InterruptedException; public final void wait(long timeout, int nanos) throws InterruptedException//当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法 protected void finalize() throws Throwable; 参考文章：Java源码解读：顶级父类Object hashCode()方法重写与equals()方法的关系。这个答上来了。 equals方法和hashCode方法的关系 如果重写了equals方法，则必须重写hashCode防止两个等价的对象的hashCode值不同，这在集合中将造成严重后果。 如果equals成立，则hashCode必须相同，如果hashCode不同，则equals则一定不成立。 如果两个对象各自调用hashCode方法产生的不同结果，对这两个对象进行equals方法的比较一定要返回false。 如果根据equals方法比较。两个对象时等价的，那么在两个对象中各自调用hashCode方法必须产生相同的整数结果。 如果根据equals方法比较，两个对象不等价，那么在两个对象中各自调用hashCode方法不一定会产生不同的整数结果。 final，finally，finalize区别。这个答上来了。现在回想自己回答的不够简练。 final: 常量声明。 finally: 处理异常。 finalize: 帮助进行垃圾回收。 接口里声明的变量默认是final的。final类无法继承，也就是没有子类。这么做是出于基础类型的安全考虑，比如String和Integer。这样也使得编译器进行一些优化，更容易保证线程的安全性。final方法无法重写。final变量的值不能改变。finalize()方法在一个对象被销毁和回收前会被调用。finally,通常用于异常处理，不管有没有异常被抛出都会执行到。比如，关闭连接通常放到finally块中完成。 参考文章：Java面试题与解答(一)——基础部分 介绍序列化。并提出当一个对象序列化之后又添加一个字段，当其被反序列化时会发生什么？这个问题后半部分答得不好，说在类加载的验证过程中不通过报错。感觉不对。 序列化的思想是 “冻结” 对象状态，传输对象状态（写到磁盘、通过网络传输等等），然后 “解冻” 状态，重新获得可用的 Java 对象。 序列化允许重构：序列化允许一定数量的类变种，甚至重构之后也是如此，ObjectInputStream 仍可以很好地将其读出来。 Java Object Serialization 规范可以自动管理的关键任务是：将新字段添加到类中；将字段从 static 改为非 static；将字段从 transient 改为非 transient。 序列化新加字段，前一个类与后一个类必须有有相同的序列化版本 hash（存储为 private static final serialVersionUID 字段）。 一旦有了serialVersionUID，不仅可以从原始对象的序列化数据创建新加字段对象（当出现新字段时，新字段被设为缺省值，最常见的是“null”），还可以反过来做：即从新加字段对象的数据通过反序列化得到原始对象。 序列化文件格式为二进制文件流： 0xACED:根据协议文档的约定,由于所有二进制流(文件)都需要在流的头部约定魔数(magic number=STREAM_MAGIC),既java object 序列化后的流的魔数约定为ACED; 0x0005:然后是流协议版本是short类型(2字节)并且值为5,则十六进制值为0005; 0x7372:java byte型长度为1字节,所以0x73 0x72直接对应到字节流上,0x73(TC_OBJECT)代表这是一个对象,0x72(TC_CLASSDESC)代表这个之后开始是对类的描述. 0x0003:类名的长度,这个类名是Pet,是三个字符,所以长度是3,对应16进制中就是0x0003. 0x506574:这三个字节转为ASCII码就是类名Pet。 序列化存在安全风险，信任，但要验证。可以实现 ObjectInputValidation接口，并覆盖 validateObject() 方法。如果调用该方法时发现某处有错误，则抛出一个 InvalidObjectException。 参考文章： 关于 Java 对象序列化您不知道的 5 件事 Java序列化格式详解 接下来转为数据结构，问的基础问题。但是越是基础，越容易犯眼高手低的毛病。什么是二叉树？什么是平衡二叉树？ 自己从数据结构的实现方面阐述被打断。要求用自己的理解来阐述二叉树的结构。 二叉树是每个节点最多有两个子树的树结构。 二叉树的每个结点至多只有二棵子树(不存在度大于2的结点)，二叉树的子树有左右之分，次序不能颠倒。二叉树的第i层至多有2^{i-1}个结点；深度为k的二叉树至多有2^k-1个结点；对任何一棵二叉树T，如果其终端结点数为n_0，度为2的结点数为n_2，则n_0=n_2+1。 平衡二叉树（Self-balancing binary search tree）又被称为AVL树（有别于AVL算法），且具有以下性质：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。常用算法有红黑树、AVL、Treap、伸展树等。在平衡二叉搜索树中，我们可以看到，其高度一般都良好地维持在O（log（n）），大大降低了操作的时间复杂度。 自己把平衡二叉树和二叉查找树弄反了，汗颜。 二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： 若左子树不空，则左子树上所有结点的值均小于或等于它的根结点的值； 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 左、右子树也分别为二叉排序树； 参考文章：平衡二叉树 算法题：给定一个数组A，一个数组B，两个数组元素均是数字，只允许分别循环遍历每个数组1次，求出： 1. A中有B中没有的元素集合； 2. A中没有B中有的元素集合； 3. A中有B中也有的元素集合。 思路：桶排序（位图）来解决，但是还是要多一次桶的循环。HashMap也是一样的思路。 升级版思路：TreeSet来解决,遍历A构建TreeSet，遍历B通过add返回值来判断，同时再remove该元素。 桶排序思路改进：遍历A数组，添加时+1；遍历B数组，添加时+2；对应三种情况值分别为1,2,3。最后遍历输出即可。设置不同的权值来进行区分，重复元素不再重复相加即可。 当数组数据有序和无序两种情况下，算法有哪些不同？ 无序最终也要归结为有序来处理吧。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148package com.alibaba.interview;import java.util.*;/** * Created by ml on 2017/8/20. * 给定一个数组A，一个数组B，两个数组元素均是数字，只允许分别循环遍历每个数组1次，求出： 1. A中有B中没有的元素集合； 2. A中没有B中有的元素集合； 3. A中有B中也有的元素集合。 */public class findNumber &#123; public static void main(String[] args) &#123; int[] testA = &#123; 5, 9, -4, 10, 21, 16&#125;; int[] testB = &#123; 10, 8, 4, 5, -3 &#125;; int[] test2A = &#123;&#125;; int[] test2B = &#123;&#125;; calSorted(testA, testB); calSorted2(testA, testB); calRandom(test2A,test2B); &#125; //自己当时的思路，桶排序但是只能实现两种 private static void calSorted(int[] testA, int[] testB) &#123; //数组有序 Arrays.sort(testA); Arrays.sort(testB); //确定最大值和最小值 int len = testA.length &lt;= testB.length ? testB.length : testA.length; int min = testA[0] &lt;= testB[0] ? testA[0] : testB[0]; int max = testA[testA.length - 1] &lt;= testB[testB.length - 1] ? testB[testB.length - 1] : testA[testA.length - 1]; int[] tong = new int[max - min + 1]; for(int i = 0; i &lt; testA.length;i++) &#123; tong[testA[i] - min]++; &#125; //A中有B中没有的元素集合 List&lt;Integer&gt; A1B0 = new ArrayList&lt;&gt;(); //A中没有B中有的元素集合 List&lt;Integer&gt; A0B1 = new ArrayList&lt;&gt;(); //A中有B中也有的元素集合 List&lt;Integer&gt; A1B1 = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; testB.length;i++) &#123; //A中没有B中有的元素 if(tong[testB[i] - min] == 0) &#123; A0B1.add(testB[i]); &#125; //A中有B中也有的元素 if(tong[testB[i] - min] &gt; 0) &#123; A1B1.add(testB[i]); tong[testB[i] - min]--; &#125; //A中有B中没有的元素无法搞定 &#125; //必须要添加一层循环 for(int i = 0; i &lt; tong.length;i++) &#123; if(tong[i] &gt; 0) &#123; A1B0.add(i + min); &#125; &#125; System.out.println(\"A中没有B中有的元素:\"); printList(A0B1); System.out.println(\"A中有B中没有的元素:\"); printList(A1B0); System.out.println(\"A中有B中也有的元素:\"); printList(A1B1); &#125; //改进版 private static void calSorted2(int[] testA, int[] testB) &#123; TreeSet&lt;Integer&gt; treeA = new TreeSet&lt;&gt;(); for(int i = 0; i &lt; testA.length; i++) &#123; treeA.add(testA[i]); &#125; //A中有B中没有的元素集合 List&lt;Integer&gt; A1B0 = new ArrayList&lt;&gt;(); //A中没有B中有的元素集合 List&lt;Integer&gt; A0B1 = new ArrayList&lt;&gt;(); //A中有B中也有的元素集合 List&lt;Integer&gt; A1B1 = new ArrayList&lt;&gt;(); for(int j = 0; j &lt; testB.length; j++) &#123; //A中没有B中有的元素 if(treeA.add(testB[j])) &#123; A0B1.add(testB[j]); treeA.remove(testB[j]); &#125; else &#123; A1B1.add(testB[j]); treeA.remove(testB[j]); &#125; &#125; System.out.println(\"A中没有B中有的元素:\"); printList(A0B1); System.out.println(\"A中有B中没有的元素:\"); printSet(treeA); System.out.println(\"A中有B中也有的元素:\"); printList(A1B1); &#125; private static void calRandom(int[] test2A, int[] test2B) &#123; &#125; private static void printArr(int[] arr) &#123; for(int i = 0; i &lt; arr.length - 1; i++) &#123; System.out.print(arr[i] + \" \"); &#125; System.out.print(arr[arr.length - 1]); System.out.println(); &#125; private static void printList(List&lt;Integer&gt; list) &#123; for(int i = 0; i &lt; list.size() - 1; i++) &#123; System.out.print(list.get(i) + \" \"); &#125; System.out.print(list.get(list.size() - 1)); System.out.println(); &#125; private static void printSet(TreeSet&lt;Integer&gt; tree) &#123; Iterator&lt;Integer&gt; it=tree.iterator(); int i=0; while(it.hasNext())&#123; i++; if(i&lt;tree.size())&#123; System.out.print(it.next()+\" \"); &#125;else&#123; System.out.print(it.next()); &#125; &#125; System.out.println(); &#125;&#125; 验证结果：123456789101112A中没有B中有的元素:-3 4 8A中有B中没有的元素:-4 9 16 21A中有B中也有的元素:5 10A中没有B中有的元素:-3 4 8A中有B中没有的元素:-4 9 16 21A中有B中也有的元素:5 10","categories":[{"name":"alibaba","slug":"alibaba","permalink":"http://lincentma.men/categories/alibaba/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"}]},{"title":"学习《阿里巴巴Java开发手册》","slug":"learn_alibaba_java","date":"2017-07-23T08:24:02.000Z","updated":"2017-07-26T11:03:57.412Z","comments":true,"path":"learn_alibaba_java.html","link":"","permalink":"http://lincentma.men/learn_alibaba_java.html","excerpt":"","text":"经验，是提高自己的重要途径之一。 学习笔记：编程规约命名风格 “骆驼拼写法”分为两种。第一个词的首字母小写，后面每个词的首字母大写，叫做“小骆驼拼写法”（lowerCamelCase）；第一个词的首字母，以及后面每个词的首字母都大写，叫做“大骆驼拼写法”（UpperCamelCase），又称“帕斯卡拼写法”。类名大骆驼，方法名、参数名、成员变量、局部变量都是小骆驼。 POJO类（只有getter和setter方法的简单类）：布尔类型变量不要加is，否则会引起部分框架解析引起序列化错误。 接口类的方法和属性不要加任何修饰符号，包括public。JDK8允许接口有默认实现，default方法。 基于SOA理念，暴露出来的一定是接口，内部实现类加Impl后缀。 常量定义 常量的复用层次： 跨应用共享常量 应用内共享常量 子工程内共享常量 包内共享常量 类内共享常量： private static final 变量值在范围内变化，设置为枚举类。成员名称全部大写。 OOP规约 直接通过类名访问类的静态变量和静态方法，而不是通过类的对象，增加编译器的解析成本。 所有覆写方法都必须加上@override注解。 所有相同类型的包装对象之间的值的比较，通过equals方法。 原因：Integer在128 127 分为内的复制，Integer对象是在IntegerCache.cache产生，会复用已有的对象，区间之外的所有数据都在堆上产生，并不会复用已有对象。 == 不仅比较值的大小，还比较对象的地址。 POJO类属性必须使用包装类型，返回值和参数也必须使用包装数据类型。预防NPE现象。 基本类型 包装器类型 boolean Boolean char Character int Integer byte Byte short Short long Long float Float double Double 使用索引访问String的split方法，需要对最后一个分隔符后面有无内容进行检查，否则会报IndexOutOfBoundsException。 public String[] split(String regex,int limit)方法：split(String regex) 方法，其实也就等同于split(String regex，0)方法，把结尾的空字符串丢弃！ 可以使用split(“分隔符”,1)或者是org.apache.commons.lang.StringUtils提供的split 参考文章：java 字符串split有很多坑，使用时请小心！！ 循环体内字符串的链接方式： 用String和“+”：因为“+”拼接字符串，每拼接一次都是再内存重新开辟一个新的内存区域（堆里边）,然后把得到的新的字符串存在这块内存，很容易引起内存溢出。 使用StringBuilder的append方法进行扩展。是在已有的内存空间追加的字符串。 commonlang工具包的StringUtils.join(list,”,”);来一步实现这个拼接而且还能指定分隔的符号。 对象的clone方法默认是前拷贝，实现深拷贝需要重写clone方法。 基本数据类型的拷贝是没有意义的，String类型这样的引用的拷贝才是有意义的。 需要注意的是，如果在拷贝一个对象时，要想让这个拷贝的对象和源对象完全彼此独立，那么在引用链上的每一级对象都要被显式的拷贝。所以创建彻底的深拷贝是非常麻烦的，尤其是在引用关系非常复杂的情况下， 或者在引用链的某一级上引用了一个第三方的对象， 而这个对象没有实现clone方法， 那么在它之后的所有引用的对象都是被共享的。 参考文章：详解Java中的clone方法 — 原型模式 集合处理 只要重写equals方法，就必须重写hashCode。 为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的（因为equal都是根据对象的特征进行重写的），但hashcode确实不相同的。 Set存放不重复队形，先比较hashCode，再用equals比较，提高效率。 String两个方法都重写了，放心使用。 参考文章：为什么重写equals时必须重写hashCode方法？ ArrayList之subList： Java.util.List中有一个subList方法，用来返回一个list的一部分的视图。 1List&lt;E&gt; subList(int fromIndex, int toIndex); 它返回原来list的从[fromIndex, toIndex)之间这一部分的List(下面称之为sublist)，但是这个sublist是依赖于原来的List集合。 在subList中进行了结构性修改（list大小修改），原来的list的大小也会发生变化，抛出一个ConcurrentModificationException。 集合转为数组的方法，必须使用集合的toArray(T[] array)，类型与大小完全一致。 不带参数的toArray方法，是构造的一个Object数组，然后进行数据拷贝，此时进行转型就会产生ClassCastException。 Arrays.asList()数组转为集合方法，不能使用挂起修改集合相关的方法，如add、remove、clear等，会抛出UnsupportedOperationException异常。 设计模式：适配器模式。只是转换接口，后台的数据仍是数组。 Arrays.asList方法返回的ArrayList是继承自AbstractList同时实现了RandomAccess和Serializable接口，AbstractList定义add等方法抛出异常。 解决方法： 12345//1List&lt;Integer&gt; list = new ArrayList&lt;&gt;(Arrays.asList(1,2,3));//2int i[]=&#123;11,22,33&#125;; Arrays.asList(ArrayUtils.toObject(i)); Java泛型通配符PECS原则： 如果要从集合中读取类型T的数据，并且不能写入，可以使用 ? extends 通配符；(Producer Extends) 如果要从集合中写入类型T的数据，并且不需要读取，可以使用 ? super 通配符；(Consumer Super) 如果既要存又要取，那么就不要使用任何通配符。 不要在foreach循环中进行元素的remove/add操作。如果要remove，需在Iterator中。如果并发，需给Iterator加锁。 List类会在内部维护一个modCount的变量，用来记录修改次数。 每生成一个Iterator，Iterator就会记录该modCount，每次调用next()方法就会将该记录与外部类List的modCount进行对比，发现不相等就会抛出多线程编辑异常。 1234//foreach和迭代器的hasNext()方法，foreach这个语法糖，实际上就是while(itr.hasNext())&#123; itr.next()&#125; 123public boolean hasNext() &#123; return cursor != size;&#125; cursor是用于标记迭代器位置的变量，该变量由0开始，每次调用next执行+1操作。 你的代码在执行删除“1”后，size=1，cursor=1，此时hasNext()返回false，结束循环，因此你的迭代器并没有调用next查找第二个元素，也就无从检测modCount了，因此也不会出现多线程修改异常但当你删除“2”时，迭代器调用了两次next，此时size=1，cursor=2，hasNext()返回true，于是迭代器傻乎乎的就又去调用了一次next()，因此也引发了modCount不相等，抛出多线程修改的异常。 当你的集合有三个元素的时候，你就会神奇的发现，删除“1”是会抛出异常的，但删除“2”就没有问题了，究其原因，和上面的程序执行顺序是一致的。 参考文章：为什么java不要在foreach循环里进行元素的remove/add操作 在 JDK 7 版本以上， Comparator 要满足自反性，传递性，对称性，不然 Arrays.sort ，Collections.sort 会报 IllegalArgumentException 异常。 保证等于和大小与分开，要严格有序。 Comparable 是排序接口。若一个类实现了Comparable接口，就意味着“该类支持排序”。 Comparable 接口仅仅只包括一个函数： Comparator 是比较器接口。我们若需要控制某个类的次序，而该类本身不支持排序(即没有实现Comparable接口)，可以通过“实现Comparator类来新建一个比较器”，然后通过该比较器对类进行排序。 Comparable相当于“内部比较器”，而Comparator相当于“外部比较器”。 1234567891011package java.lang;import java.util.*;public interface Comparable&lt;T&gt; &#123; public int compareTo(T o);&#125;public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2); boolean equals(Object obj);&#125; 集合初始化，指定集合的初始值大小。 Collection的初始容量也显得异常重要。所以：对于已知的情景，请为集合指定初始容量。 HashMap初始化容量计算 = （需要存储元素的个数 / 负载因子） + 1 12345678910111213141516171819202122// ArrayList新容量扩大到原容量的1.5倍，右移一位相关于原数值除以2。int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//Vector线程安全，速度慢。默认初始容量为10，加载因子为1：即当 元素个数 超过 容量长度 时，进行扩容扩容增量：原容量的1倍int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity);//HashMapstatic final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;static final float DEFAULT_LOAD_FACTOR = 0.75f;if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1;//HashTableint newCapacity = oldCapacity * 2 + 1;//StringBuildervoid expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) // overflow throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity); &#125; 集合名称 默认容量 加载因子 扩容容量(扩大到原来的) ArrayList 10 1 1.5 Vector 10 1 2 HashSet 16 0.75 2 HashMap 16 0.75 2 HashTable 11 0.75 *2 +1 StringBuilder（StringBuffer） 16 条件判断 *2+2 遍历Map类，使用entrySet。 同时遍历key和value时，keySet与entrySet方法的性能差异取决于key的具体情况，如复杂度（复杂对象）、离散度、冲突率等。换言之，取决于HashMap查找value的开销。entrySet一次性取出所有key和value的操作是有性能开销的，当这个损失小于HashMap查找value的开销时，entrySet的性能优势就会体现出来。 同时遍历key和value时，与HashMap不同，entrySet的性能远远高于keySet。这是由TreeMap的查询效率决定的，也就是说，TreeMap查找value的开销较大，明显高于entrySet一次性取出所有key和value的开销。因此，遍历TreeMap时强烈推荐使用entrySet方法。 123456789101112131415//keySet遍历2次，一次转为Iterator对象，一次从HashMap中取出对应的valuefor (String key : map.keySet()) &#123; value = map.get(key);&#125;//entrySetfor (Entry&lt;String, String&gt; entry: map.entrySet()) &#123; key = entry.getKey(); value = entry.getValue();&#125;//for循环for (String value : map.values()) &#123;&#125;//JDK8 增强for循环Map&lt;String, Integer&gt; items = new HashMap&lt;&gt;();items.forEach((k,v)&gt;System.out.println(\"key : \" + k + \"; value : \" + v)); 参考文章：Java Map遍历方式的选择 Map类集合K/V为null需要注意的地方： 集合类 Key Value Super 说明 Hashtable 不允许为 null 不允许为 null Dictionary 线程安全 ConcurrentHashMap 不允许为 null 不允许为 null AbstractMap 分段所锁技术 TreeMap 不允许为 null 允许为 null AbstractMap 线程不安全 HashMap 允许为 null 允许为 null AbstractMap 线程不安全 由于 HashMap的干扰，很多人认为 ConcurrentHashMap是可以置入 null值，注意存储null值时会抛出 NPE异常。 集合的有序性和稳定性：ArrayList是order/unsort，HashMap是unorder/unsort，TreeSet是order/sort 利用Set唯一性去重，避免使用List的contains方法遍历去重。Collection的contains()和remove()操作都是线性时间复杂度，用set也会隐式的调用contains()方法，不过你用的是HashSet,这个contains()应该只会用常数时间，所以如果考虑平均时间复杂度，用set可能会占优；最坏情况下，两者可能差不多 。 并发处理 获取单例对象，保证线程安全，以及方法的线程安全。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//立即加载（饿汉模式），在调用getInstance()方法前，实例就被创建了，getInstance()方法没有同步，所以可能出现非线程安全问题。public class Singleton &#123; private final static Singleton INSTANCE = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return INSTANCE; &#125;&#125;//延迟加载（懒汉模式），延迟加载就是在getInstance()方法中创建实例。在多线程的环境中，延迟加载中使用同步代码块，对类加锁。虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125;//DCL双检查锁机制。 DCL双检查锁机制即使用volatile关键字（使变量在多个线程中可见）修改对象和synchronized代码块//两次检查 instance == null，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。//instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。//给 instance 分配内存//调用 Singleton 的构造函数来初始化成员变量//将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）//JVM 的即时编译器中存在指令重排序的优化，只需要将 instance 变量声明成 volatile 来避免指令重排序。public class Singleton &#123; private static volatile Singleton singleton = null; private Singleton()&#123;&#125; public static Singleton getSingleton()&#123; if(singleton == null)&#123; synchronized (Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125;//【推荐】静态内部类//使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。//但是如果对象是序列化的就无法达到效果了。public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125;//枚举//枚举的缺点是它无法从另一个基类继承，因为它已经继承自java.lang.Enum。public enum FooEnumSingleton &#123; INSTANCE; public static FooEnumSingleton getInstance() &#123; return INSTANCE; &#125; public void bar() &#123; &#125;&#125; 线程资源通过线城池提供，通过ThreadPoolExecutor方式创建。 ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务 Executors方法提供的线程服务，都是通过参数设置来实现不同的线程池机制。 关系：Executors可以认为是封装好的线城池服务，ThreadPoolExecutor更加明确线程池的运行机制。 Executors.newCachedThreadPool(); ``//创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE，允许创建线程为Integer.MAX_VALUE,容易OOM Executors.newSingleThreadExecutor(); ``//创建容量为1的缓冲池，请求队列为长度为Integer.MAX_VALUE,容易OOM， Executors.newFixedThreadPool(``int``); ``//创建固定容量大小的缓冲池请，求队列为长度为Integer.MAX_VALUE,容易OOM 123456789101112131415161718192021222324252627282930public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; /*corePoolSize 核心线程池大小maximumPoolSize 线程池最大容量大小keepAliveTime 线程池空闲时，线程存活的时间TimeUnit 时间单位ThreadFactory 线程工厂BlockingQueue任务队列RejectedExecutionHandler 线程拒绝策略*/ 123456789101112131415161718192021222324252627282930313233public class Test &#123; public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); for(int i=0;i&lt;15;i++)&#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println(\"线程池中线程数目：\"+executor.getPoolSize()+\"，队列中等待执行的任务数目：\"+ executor.getQueue().size()+\"，已执行玩别的任务数目：\"+executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125; class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println(\"正在执行task \"+taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"task \"+taskNum+\"执行完毕\"); &#125;&#125; 参考文章：[深入理解Java之线程池](http://www.importnew.com/19011.html) SimpleDateFormat类线程不安全 线程不安全原因： SimpleDateFormat(下面简称sdf)类内部有一个Calendar对象引用,它用来储存和这个sdf相关的日期信息,例如sdf.parse(dateStr), sdf.format(date) 。 calendar这个共享变量的访问没有做到线程安全 解决方法： 将SimpleDateFormat定义成局部变量： 加一把线程同步锁：synchronized(lock)； 【推荐】使用ThreadLocal: 每个线程都将拥有自己的SimpleDateFormat对象副本。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.HashMap;import java.util.Map;public class DateUtil &#123; /** 锁对象 */ private static final Object lockObj = new Object(); /** 存放不同的日期模板格式的sdf的Map */ private static Map&lt;String, ThreadLocal&lt;SimpleDateFormat&gt;&gt; sdfMap = new HashMap&lt;String, ThreadLocal&lt;SimpleDateFormat&gt;&gt;(); /** * 返回一个ThreadLocal的sdf,每个线程只会new一次sdf * * @param pattern * @return */ private static SimpleDateFormat getSdf(final String pattern) &#123; ThreadLocal&lt;SimpleDateFormat&gt; tl = sdfMap.get(pattern); // 此处的双重判断和同步是为了防止sdfMap这个单例被多次put重复的sdf if (tl == null) &#123; synchronized (lockObj) &#123; tl = sdfMap.get(pattern); if (tl == null) &#123; // 只有Map中还没有这个pattern的sdf才会生成新的sdf并放入map System.out.println(\"put new sdf of pattern \" + pattern + \" to map\"); // 这里是关键,使用ThreadLocal&lt;SimpleDateFormat&gt;替代原来直接new SimpleDateFormat tl = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123; @Override protected SimpleDateFormat initialValue() &#123; System.out.println(\"thread: \" + Thread.currentThread() + \" init pattern: \" + pattern); return new SimpleDateFormat(pattern); &#125; &#125;; sdfMap.put(pattern, tl); &#125; &#125; &#125; return tl.get(); &#125; /** * 是用ThreadLocal&lt;SimpleDateFormat&gt;来获取SimpleDateFormat,这样每个线程只会有一个SimpleDateFormat * * @param date * @param pattern * @return */ public static String format(Date date, String pattern) &#123; return getSdf(pattern).format(date); &#125; public static Date parse(String dateStr, String pattern) throws ParseException &#123; return getSdf(pattern).parse(dateStr); &#125;&#125; 高并发的同步调用考虑锁的性能消耗，锁的粒度尽可能小。 在获得锁之前做完所有需要做的事，只把锁用在需要同步的资源上，用完之后立即释放它。减少锁持有时间。 减小锁粒度：ConcurrentHashMap。 锁粗化：如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。 锁消除：即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。 分别用不同的锁来保护同一个类中多个独立的状态变量，而不是对整个类域只使用一个锁。锁分离。ReadWriteLock。 参考文章：Java 高并发九：锁的优化和注意事项详解 对多个资源、库表、对象加锁，需要保持一致的加锁顺序。 当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。 此外还有加锁时限、死锁检测等方法预防死锁。 并发修改同一记录必须加锁。 乐观锁，大多是基于数据版本(Version)记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 提交版本必须大于记录当前版本才能执行更新。 悲观锁（Pessimistic Lock），正如其名，具有强烈的独占和排他特性。它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 多线程并行之Timer 定时任务用Timer实现有可能出现异常，因为它是基于绝对时间而不是相对时间进行调度的。当环境的系统时间被修改后，原来的定时任务可能就不跑了。另外需要注意一点，捕获并处理定时任务的异常。如果在TimerTask里抛出了异常，那么Timer认为定时任务被取消并终止执行线程。 异步转同步操作CountDownLatch CountDownLatch这个类能够使一个线程等待其他线程完成各自的工作后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。 构造器中的**计数值（count）实际上就是闭锁需要等待的线程数量**。这个值只能被设置一次，而且CountDownLatch**没有提供任何机制去重新设置这个计数值**。这种通知机制是通过 **CountDownLatch.countDown()**方法来完成的；每调用一次这个方法，在构造函数中初始化的count值就减1。所以当N个线程都调 用了这个方法，count的值等于0，然后主线程就能通过await()方法，恢复执行自己的任务。 参考文章：[什么时候使用CountDownLatch](http://www.importnew.com/15731.html) 多线程之Random 任何情况下都不要在多个线程间共享一个java.util.Random实例，而该把它放入ThreadLocal之中。 Java7在所有情形下都更推荐使用java.util.concurrent.ThreadLocalRandom——它向下兼容已有的代码且运营成本更低。 1234567891011121314151617181920private static void testTL_Random( final int threads, final long cnt )&#123; final CountDownLatch latch = new CountDownLatch( threads ); final ThreadLocal&lt;Random&gt; rnd = new ThreadLocal&lt;Random&gt;() &#123; @Override protected Random initialValue() &#123; return new Random( 100 ); &#125; &#125;; for ( int i = 0; i &lt; threads; ++i ) &#123; final Thread thread = new Thread( new RandomTask( null, i, cnt, latch ) &#123; @Override protected Random getRandom() &#123; return rnd.get(); &#125; &#125; ); thread.start(); &#125;&#125; 参考文章：多线程环境下生成随机数 volatile 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 volatile不能确保原子性 可以通过synchronized或lock，进行加锁，来保证操作的原子性。也可以通过AtomicInteger。 java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 好的一面是它通过一个直接机器码指令设置值时，能够最小程度地影响其他线程的执行。坏的一面是如果它在与其他线程竞争设置值时失败了，它不得不再次尝试。在高竞争下，这将转化为一个自旋锁，线程不得不持续尝试设置值，无限循环直到成功。 JDK8中LongAdder实例，并使用intValue()和add()来获取和设置值。神奇的地方发生在幕后。这个类所做的事情是当一个直接CAS由于竞争失败时，它将delta保存在为该线程分配的一个内部单元对象中，然后当intValue()被调用时，它会将这些临时单元的值再相加到结果和中。这就减少了返回重新CAS或者阻塞其他线程的必要。 参考文章： 你真的了解volatile关键字吗？ Java 8 LongAdders：管理并发计数器的正确方式 HashMap在resize可能发生死链，加锁解决。 当多个线程同时检测到总数量超过门限值的时候就会同时调用resize操作，各自生成新的数组并rehash后赋给该map底层的数组table，结果最终只有最后一个线程生成的新数组被赋给table变量，其他线程的均会丢失。而且当某些线程已经完成赋值而其他线程刚开始的时候，就会用已经被赋值的table作为原始数组，这样也会有问题。 首先如果多个线程同时使用put方法添加元素，而且假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖。 线程安全： Hashtable ConcurrentHashMap(性能优势) Synchronized Map 参考文章：如何线程安全的使用HashMap ThreadLocal 参考文章：彻底理解ThreadLocal 参考文章： 【Java编码规范】《阿里巴巴Java开发手册（正式版）》更新（v1.2.0版）——迄今最完善版本 白话阿里巴巴Java开发手册(编程规约) 白话阿里巴巴Java开发手册（异常日志） 白话阿里巴巴Java开发手册（安全规约）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lincentma.men/categories/学习笔记/"}],"tags":[{"name":"java","slug":"java","permalink":"http://lincentma.men/tags/java/"},{"name":"alibaba","slug":"alibaba","permalink":"http://lincentma.men/tags/alibaba/"}]},{"title":"SSM框架整合理解","slug":"frame_ssm","date":"2017-07-17T16:32:21.000Z","updated":"2017-07-17T16:34:41.340Z","comments":true,"path":"frame_ssm.html","link":"","permalink":"http://lincentma.men/frame_ssm.html","excerpt":"","text":"SSM框架整合理解 把IntelliJ IDEA+Maven+Spring + SpringMVC + MyBatis项目部署，框架流程梳理调试了一遍，加深自己的理解。 回顾SSM框架SpringSpring就像是整个项目中装配bean的大工厂，在配置文件中可以指定使用特定的参数去调用实体类的构造方法来实例化对象。Spring的核心思想是IoC（控制反转），即不再需要程序员去显式地new一个对象，而是让Spring框架帮你来完成这一切。 SpringMVCSpringMVC在项目中拦截用户请求，它的核心Servlet即DispatcherServlet承担中介或是前台这样的职责，将用户请求通过HandlerMapping去匹配Controller，Controller就是具体对应请求所执行的操作。SpringMVC相当于SSH框架中struts。 mybatismybatis是对jdbc的封装，它让数据库底层操作变的透明。mybatis的操作都是围绕一个sqlSessionFactory实例展开的。mybatis通过配置文件关联到各实体类的Mapper文件，Mapper文件中配置了每个类对数据库所需进行的sql语句映射。在每次与数据库交互时，通过sqlSessionFactory拿到一个sqlSession，再执行sql命令。 SSM框架流程 SSM框架搭建创建Maven的Web项目 通过IntelliJ IDEA创建maven项目： 选中Createfrom archetype，选择maven-archetype-webapp 在Properties中添加一个参数 archetypeCatalog=internal，提高maven项目构建速度 SSH框架Web项目框架 main： 创建java文件夹：项目代码 resources文件夹： mapping文件夹：数据库表xml xml配置文件 webapp： WEB-INF： 创建jsp文件夹：不同显示页面 web.xml:配置文件 Tomcat启动项目 为项目配置Tomcat 配置各种XML pom.xml——引入项目所需要的jar包 spring核心依赖 mybatis依赖 mybatis-spring整合包依赖 mysql驱动依赖 其他依赖： 日志相关：log4j、slf4j 连接池相关：commons-dbcp、c3p0、Druid Json相关：fastjson 其他：jstl PS：此外还有SpringBoot可以简化xml中的配置项数量。SpringBoot完全抛弃了繁琐的XML文件配置方式，而是替代性地用注解方式来实现。 参考文章：IDEA下从零开始搭建SpringBoot工程 调试过程中的错误有很大一部分是所引的jar没有在pom.xml配置，这部分需要仔细细致。 关于jar包的版本号的修改，可以在标签中用变量保存版本号，中具体的jar包的版本用变量代替，方便后续修改。 web.xml 这是整个web项目的配置文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" version=\"3.0\"&gt; &lt;display-name&gt;cloudmusic_ssm_demo&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mybatis.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 编码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- spring监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 防止spring内存溢出监听器，比如quartz --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- spring mvc servlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;!-- 此处也可以配置成 *.do 形式 --&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;/index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- session配置 --&gt; &lt;session-config&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt; &lt;/session-config&gt;&lt;/web-app&gt; 中的配置，加载SpringMVC的配置文件。 SpringMVC具有统一的入口DispatcherServlet，所有的请求都通过DispatcherServlet。DispatcherServlet是前置控制器，配置在web.xml文件中的。拦截匹配的请求，Servlet拦截匹配规则要自已定义，把拦截下来的请求，依据某某规则分发到目标Controller来处理。 拦截所有的请求，并加载所有的ssm配置文件（路径为classpath:spring-mvc.xml） 在web.xml中使用contextConfigLocation参数定义要装入的Spring配置文件。 加载路径为classpath:spring-mybatis.xml文件 参考文章： SSM:spring+springmvc+mybatis框架中的XML配置文件功能详细解释 spring-mvc.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd\"&gt; &lt;!-- 自动扫描 @Controller--&gt; &lt;context:component-scan base-package=\"com.ssm.demo.controller\"/&gt; &lt;!--避免IE执行AJAX时，返回JSON出现下载文件 --&gt; &lt;bean id=\"mappingJacksonHttpMessageConverter\" class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"supportedMediaTypes\"&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 启动SpringMVC的注解功能，完成请求和注解POJO的映射 --&gt; &lt;bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\"&gt; &lt;property name=\"messageConverters\"&gt; &lt;list&gt; &lt;ref bean=\"mappingJacksonHttpMessageConverter\"/&gt; &lt;!-- JSON转换器 --&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 定义跳转的文件的前后缀 ，视图模式配置 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\" /&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!-- 文件上传配置 --&gt; &lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt; &lt;!-- 默认编码 --&gt; &lt;property name=\"defaultEncoding\" value=\"UTF-8\"/&gt; &lt;!-- 上传文件大小限制为31M，31*1024*1024 --&gt; &lt;property name=\"maxUploadSize\" value=\"32505856\"/&gt; &lt;!-- 内存中的最大值 --&gt; &lt;property name=\"maxInMemorySize\" value=\"4096\"/&gt; &lt;/bean&gt;&lt;/beans&gt; controller注入：使用组件扫描方式，扫描包下面所有的Controller，可以使用注解来指定访问路径。 Spring 所有功能都在 Bean 的基础上演化而来，所以必须事先将 Controller 变成 Bean。配置了一个 AnnotationMethodHandlerAdapter，它负责根据 Bean 中的 Spring MVC 注解对 Bean 进行加工处理，使这些 Bean 变成控制器并映射特定的 URL 请求。 视图解析：在Controller中设置视图名的时候会自动加上前缀和后缀。 spring-mybatis.xml：Spring与MyBatis的整合配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package=\"com.ssm.demo\"/&gt; &lt;!-- 第一种方式：加载一个properties文件 --&gt; &lt;bean id=\"propertyConfigurer\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"location\" value=\"classpath:jdbc.properties\"/&gt; &lt;/bean&gt; &lt;!-- 第二种方式：加载多个properties文件 &lt;bean id=\"configProperties\" class=\"org.springframework.beans.factory.config.PropertiesFactoryBean\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath:jdbc.properties&lt;/value&gt; &lt;value&gt;classpath:common.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"fileEncoding\" value=\"UTF-8\"/&gt; &lt;/bean&gt; &lt;bean id=\"propertyConfigurer\" class=\"org.springframework.beans.factory.config.PreferencesPlaceholderConfigurer\"&gt; &lt;property name=\"properties\" ref=\"configProperties\"/&gt; &lt;/bean&gt; --&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driverClass&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbcUrl&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name=\"initialSize\" value=\"$&#123;initialSize&#125;\"&gt;&lt;/property&gt; &lt;!-- 连接池最大数量 --&gt; &lt;property name=\"maxActive\" value=\"$&#123;maxActive&#125;\"&gt;&lt;/property&gt; &lt;!-- 连接池最大空闲 --&gt; &lt;property name=\"maxIdle\" value=\"$&#123;maxIdle&#125;\"&gt;&lt;/property&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name=\"minIdle\" value=\"$&#123;minIdle&#125;\"&gt;&lt;/property&gt; &lt;!-- 获取连接最大等待时间 --&gt; &lt;property name=\"maxWait\" value=\"$&#123;maxWait&#125;\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- mybatis和spring完美整合，不需要mybatis的配置映射文件 --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapping/*.xml\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.ssm.demo.dao\"/&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt;&lt;/beans&gt; 自动扫描，自动注入，配置数据库 自动扫描,将标注Spring注解的类自动转化Bean，同时完成Bean的注入 加载数据资源属性文件 配置数据源（三种方式，采用DBCP） 配置sessionfactory 装配Dao接口 声明式事务管理 注解事务切面 Mapper.xml映射文件中定义了操作数据库的sql，每一个sql是一个statement，映射文件是myBatis的核心。 jdbc.properties：JDBC属性文件 123456789101112131415driverClass=com.mysql.jdbc.DriverjdbcUrl=jdbc:mysql://localhost:3306/db_ssm?useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNullusername=rootpassword=147789#定义初始连接数initialSize=0#定义最大连接数maxActive=20#定义最大空闲maxIdle=20#定义最小空闲minIdle=1#定义最长等待时间maxWait=60000 创建业务流程 以数据库查询表内容为例 持久层：DAO层（mapper）做数据持久层的工作，负责与数据库进行联络的一些任务都封装在此， DAO层的设计首先是设计DAO的接口， 然后在Spring的配置文件中定义此接口的实现类， 然后就可在模块中调用此接口来进行数据业务的处理，而不用关心此接口的具体实现类是哪个类，显得结构非常清晰， DAO层的数据源配置，以及有关数据库连接的参数都在Spring的配置文件中进行配置。 业务层：Service层 主要负责业务模块的逻辑应用设计。 首先设计接口，再设计其实现的类 接着再在Spring的配置文件中配置其实现的关联。这样我们就可以在应用中调用Service接口来进行业务处理。 Service层的业务实现，具体要调用到已定义的DAO层的接口， 封装Service层的业务逻辑有利于通用的业务逻辑的独立性和重复利用性，程序显得非常简洁。 表现层：Controller层（Handler层）负责具体的业务模块流程的控制 在此层里面要调用Service层的接口来控制业务流程， 控制的配置也同样是在Spring的配置文件里面进行，针对具体的业务流程，会有不同的控制器，我们具体的设计过程中可以将流程进行抽象归纳，设计出可以重复利用的子单元流程模块，这样不仅使程序结构变得清晰，也大大减少了代码量。 模型层：Model层 主要存放实体类 项目代码结构： controller： “@RequestMapping”请求路径映射，如果标注在某个controller的类级别上，则表明访问此类路径下的方法都要加上其配置的路径；最常用是标注在方法上，表明哪个具体的方法来接受处理某次请求。 调用service层方法 spring mvc 支持如下的返回方式：ModelAndView, Model, ModelMap, Map,View, String, void。本文返回的是String，通过model进行使用。 参考文章：SpringMVC返回（return）方式详解 service：建立service接口和实现类 impl:接口对应实现类： 调用Dao层的数据库操作以及model层的实体类 dao 定义接口中的方法 一个Dao对应一个对应的mapper文件，实现Dao对应的定义的接口方法 mapping： mapper.xml：实现dao中接口定义的方法 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.ssm.demo.dao.UserDao\"&gt; &lt;resultMap id=\"UserBaseMap\" type=\"com.ssm.demo.model.User\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_name\" property=\"userName\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"user_phone\" property=\"userPhone\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"user_email\" property=\"userEmail\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"user_pwd\" property=\"userPwd\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"pwd_salt\" property=\"pwdSalt\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"create_time\" property=\"createTime\" jdbcType=\"DATE\"/&gt; &lt;result column=\"modify_time\" property=\"modifyTime\" jdbcType=\"DATE\"/&gt; &lt;result column=\"is_delete\" property=\"isDelete\" jdbcType=\"SMALLINT\"&gt;&lt;/result&gt; &lt;/resultMap&gt; &lt;select id=\"selectUserById\" parameterType=\"java.lang.Long\" resultMap=\"UserBaseMap\"&gt; SELECT * FROM t_user WHERE id = #&#123;userId&#125; &lt;/select&gt; &lt;select id=\"selectUserByPhoneOrEmail\" resultMap=\"UserBaseMap\"&gt; SELECT * FROM t_user WHERE user_email = #&#123;emailOrPhone&#125; OR user_phone = #&#123;emailOrPhone&#125; AND user_state = #&#123;state&#125; &lt;/select&gt; &lt;select id=\"selectAllUser\" resultMap=\"UserBaseMap\"&gt; SELECT * FROM t_user &lt;/select&gt;&lt;/mapper&gt; namespace:当前库表映射文件的命名空间，唯一的不能重复 映射实体类的数据类型 id：resultMap的唯一标识 column:库表的字段名 property:实体类里的属性名 id：当前sql的唯一标识 parameterType：输入参数的数据类型 返回值的数据类型：resultMap适合使用返回值是自定义实体类的情况 ； resultType适合使用返回值的数据类型是非自定义的，即jdk的提供的类型。 {}:用来接受参数的，如果是传递一个参数#{id}内容任意，如果是多个参数就有一定的规则,采用的是预编译的形式select model 实体属性——对应表中的元组的属性 getter和setter方法 DataBase ===&gt; Entity ===&gt; Mapper.xml ===&gt; Mapper.Java ===&gt; Service.java ===&gt; Controller.java ===&gt; Jsp. 参考文章SSM框架整合（IntelliJ IDEA + maven + Spring + SpringMVC + MyBatis） SSM框架感受 本质上的MVC，xml配置、注解，以及mapper的映射，让开发更加简洁和思路清晰 ##","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"http://lincentma.men/tags/SSM/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lincentma.men/tags/SpringMVC/"},{"name":"Spring","slug":"Spring","permalink":"http://lincentma.men/tags/Spring/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://lincentma.men/tags/Mybatis/"}]},{"title":"【面试持续更新】2018校招记录","slug":"interview_record","date":"2017-07-14T16:10:57.000Z","updated":"2017-07-27T13:02:26.374Z","comments":true,"path":"interview_record.html","link":"","permalink":"http://lincentma.men/interview_record.html","excerpt":"","text":"【面试持续更新】2018校招记录工商银行一句话，谈人生谈理想，不谈技术 中兴提前批一面 简单自我介绍 实习经历详细介绍 前端请求与后端处理的异常情况如何处理 SQL模糊查询语句，如何提高查询效率 实习所用PHP框架是如何与数据库相连接的 常用Shell命令 Git开发流程 二面 再次自我介绍 工作地点意向询问 网络请求如何加速（不理解是询问那一方面的加速，自己回答分机房说不对） 实习相关问题 然后就陷入了尴尬的安静 海康威视提前批一面 简单自我介绍 Spark特性有哪些？ 除了Hadoop之外有哪些其他的大数据处理框架？ MapReduce处理过程 Hadoop部署节点？如何部署？ Java与python的交互了解多少？如何进行交互？ Java内存模型介绍？ Java多线程介绍？ JVM调优经验 使用过Redis等NoSQL数据库吗，Redis如何部署？Redis中的数据最终存储在哪里？ 自己询问的问题： 部门业务应用场景：大数据构建多特征模型进行行为安全预测判断 技术能力要求：部门有不同方向，不必太在意招聘中的所有要求都需要符合 什么时候有下一步的结果：他也不知道。。。。","categories":[{"name":"面试","slug":"面试","permalink":"http://lincentma.men/categories/面试/"}],"tags":[{"name":"interview","slug":"interview","permalink":"http://lincentma.men/tags/interview/"}]},{"title":"自己用过的框架","slug":"used_frames","date":"2017-07-14T15:46:16.000Z","updated":"2017-07-14T15:48:14.875Z","comments":true,"path":"used_frames.html","link":"","permalink":"http://lincentma.men/used_frames.html","excerpt":"","text":"自己用过的框架Java之SSH SSH不是一个框架，而是多个框架的集成，是目前较流行的一种Web应用程序开源集成框架，用于构建灵活、易于扩展的多层Web应用程序。 系统从职责上分为四层：表示层、业务逻辑层、数据持久层和域模块层。 Spring+Struts+Hibernate（SSH） 其中使用Struts作为系统的整体基础架构，负责MVC的分离，在Struts框架的模型部分，利用hibernate框架对持久层提供支持，业务层用spring支持。 系统的基本业务流程是： 在表示层中，首先通过JSP页面实现交互界面，负责传送请求(Request)和接收响应(Response)，然后Struts根据配置文件(struts-config.xml)将ActionServlet接收到的Request委派给相应的Action处理。 在业务层中，管理服务组件的 Spring IoC容器负责向Action提供业务模型(Model)组件和该组件的协作对象数据处理(DAO)组件完成业务逻辑，并提供事务处理、缓冲池等容器组件以提升系统性能和保证数据的完整性。 在持久层中，则依赖于Hibernate的对象化映射和数据库交互，处理DAO组件请求的数据，并返回处理结果。 SSH配置流程： 创建web项目 配置struts： 添加Struts2所需要的基本jar包到 lib目录 在web.xml 文件里添加struts的过滤器配置 在src目录下创建struts配置文件struts.xml 配置spring： 在lib目录下导入spring相关的jar包（2个spring跟struts结合的jar包） 在web.xml文件下配置监听器 配置hibernate: 在lib目录里导入hibernate相关的jar包 创建实体类 创建实体类对应的xxx..hbm.xml映射文件 应用IOC实现DAO接口 编写Action类 编写Service(接口类)和ServiceImpl(实现类) Spring是一个轻量级的控制反转（IoC）和面向切面（AOP）的容器框架。 Struts它通过采用 Java Servlet/JSP 技术，实现了基于JavaEE Web应用的MVC设计模式的应用框架，是MVC经典设计模式中的一个经典产品。 Struts 2以WebWork为核心，采用拦截器的机制来处理用户的请求，这样的设计也使得业务逻辑控制器能够与ServletAPI完全脱离开，所以Struts 2可以理解为WebWork的更新产品。 Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Spring+SpringMVC+Mybatis（SSM） SpringMVC 做控制器(controller)，Spring 管理各层的组件，MyBatis 负责持久化层。 Struts2与SpringMVC MyBatis与Hibernate MyBatis可以进行更为细致的SQL优化，可以减少查询字段。 MyBatis容易掌握，而Hibernate门槛较高。 Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。 Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。 Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。 Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳，更新操作不能指定刷新指定记录，会清空整个表，但是也可以使用第三方缓存。 Hibernate 封装性好，屏蔽了数据库差异，自动生成SQL语句，应对数据库变化能力较弱，SQL语句优化困难。 MyBatis仅实现了SQL语句和对象的映射，需要针对具体的数据库写SQL语句，应对数据库变化能力较强，SQL语句优化较为方便。 SSM配置流程： 创建web项目 在WEB-INF/lib导入jar包（亦可以根目录下用maven配置文件poom.xml进行配置管理jar包） 配置MyBatis:dao层编写dao类以及对应的mapper和xml（为dao接口方法提供sql语句配置） 配置spring：在applicationContext.xml.xml文件下配置 配置springmvc：配置springMVC.xml 编写Service以及ServiceImpl 编写Controller（相当于struts中的action） SSM和SSH不同主要在MVC实现方式，以及ORM持久化方面不同（Hiibernate与Mybatis）。SSM越来越轻量级配置，将注解开发发挥到极致，且ORM实现更加灵活，SQL优化更简便；而SSH较注重配置开发，其中的Hiibernate对JDBC的完整封装更面向对象，对增删改查的数据维护更自动化，但SQL优化方面较弱，且入门门槛稍高。 参考文章 SSH框架的底层机制及原理 SSH的框架整合 SSH框架总结（框架分析+环境搭建+实例源码下载） SSH和SSM对比总结 手把手教你整合最优雅SSM框架：SpringMVC + Spring + MyBatis SSM SPRING+SPING MVC + MYBATIS 三大框架整合详细步骤 PHP之ODP ODP是公司发布的在线业务开发平台，面向全百度的在线业务支撑平台，专注于总结大社区类业务模式，其提供了标准的webserver环境、标准php环境、AP框架、SAF社区业务框架、基础库、RAL资源访问层、KSARCH通用服务等组件，统一业务的逻辑和部署结构，为测试、运维等提供一致的视图。 这也是自己实习时候一直在用的框架。 Online Develop Platform = Linux+Lightted/nginx+mysql+PHP ODP核心包含了ODP的核心功能组件，包括运行环境、核心基础库、数据交互层、框架等。 横向看，ODP核心通过库、框架、工具等集成支持了各类规范和模式，也为全流程支持提供接口。 向上看，ODP核心直接为产品线业务提供运行环境和研发支持。 向下看，ODP核心通过数据交互层将底层的通用服务提供给业务。 AP框架目录： 1234567891011模板层： odp/template/appname/Actiono: odp/app/appname/actions/PageService: odp/app/appname/models/service/page/DataService: odp/app/appname/models/service/data/Dao: odp/app/appname/models/dao/Controller: odp/app/appname/controller/ ODP应用程序结构： 123456789101112131415161718192021222324252627282930313233343536newapp // 应用名称+--action // 动作类目录| +--api // 子系统交互api目录| | --Sample.php // 示例api服务端action| --Sample.php // 示例普通action+--api // saf api接口和服务类| --Interface.php // 接口类| --Service.php // 实现类+--conf // 配置目录| +--newapp // 配置目录，配置文件可以拆分| --global.conf // app全局配置文件| --log.conf // log示例配置文件+--controllers // 控制类目录| --Main.php // 主控制类| --Api.php // api控制类+--doc // 文档目录+--library // 本地类根目录| +--newapp // app本地类目录| --Util.php // 示例本地类+--models // 数据目录| +--dao // 数据获取目录| | --Sample.php // 示例| +--service // 页面数据服务目录| +--data // 主题数据服务目录| | --Sample.php // 示例| +--page // 页面数据服务目录| --Sample.php // 示例| --SampleApi.php // api示例+--script // 脚本目录| --sampleScript.php // 示例脚本+--test // 测试目录+--Bootstrap.php // ap框架的引导文件+--build.sh // 打包脚本+--index.php // 入口文件+--Makefile // 自动部署脚本--readme.txt // readme文件，告诉你如何部署和运行 DB，通过对应参数的不同，实现自动拼接不同的SQL语句。 1234567891011121314$tables 数据表列表，可以是数组或者字符串$fields 字段列表，可以是数组或者字符串$conds 条件列表，可以是数组或者字符串$options 选项列表，可以是数组或者字符串$appends 结尾操作列表，可以是数组或者字符串例如：$table = ‘student’;$fields = array(‘number’, ‘class’);$conds = array(‘grade =‘ =&gt;‘three’, ‘school =‘ =&gt; ‘希望小学’);调用select($table, $fields, $conds); 就会生成 select number, class from student where grade = ‘three’ and school = ‘希望小学’ 的sql语句并执行之。 逻辑分层之间的调用关系，只能向后依赖，不能向前依赖或者跨层之间依赖。此次逻辑分层从前到后，依次为：Action、PageService、DataService、Dao。具体来说便是指，Dao不能依赖于DataService,PageService,Action；DataService不能依赖于PageService和Action；PageService不能依赖于Action。Action不能直接调用DataService，也不能直接调用Dao；PageService不能直接调用Dao。 SAF是ODP环境提供的业务层框架，SAF框架建立的目的是为了把业务逻辑开发过程中一些共性的问题抽取出来，并提供统一的解决方案。SAF框架包含控制器组件，通用业务组件（参数处理，session处理，日志打印等）以及通用配置组件。可以将SAF框架理解为一个工具库，SAF为我们提供了很多的通用功能例如验证用户的登录信息，接收用户提交的数据，更改用户的信息，记录用户的操作行为等。 SAF框架提供了一个很重要的功能就是钩子（Hook）机制，通过在钩子函数中覆写对应的钩子函数,可以实现对cgi(GET POST等)数据的特殊处理，对登陆信息的校验/修改以及对输出到log日志文件的内容的修改等功能。 RAL是一个支持多种交互协议和打包格式的php扩展。RAL规定了一套高度抽象的交互过程规范，将整个后端交互过程分成了交互协议和数据打包/解包两大块，可以支持一些常用的后端交互协议，标准化协议扩充的开发过程，促进代码复用。RAL集成了负载均衡、健康检查等功能，让上游端不需要再关注这些繁琐的通用逻辑，同时实现版本可以在性能方面有更优的表现。 参考文章： ODP教程 | 百度外卖手册 Python之Tornado 自己做Sug平台展示时候选择的Python Web框架 Tornado 和现在的主流 Web 服务器框架（包括大多数 Python 的框架）有着明显的区别：它是非阻塞式服务器，而且速度相当快。得利于其 非阻塞的方式和对 epoll 的运用，Tornado 每秒可以处理数以千计的连接，这意味着对于实时 Web 服务来说，Tornado 是一个理想的 Web 框架。我们开发这个 Web 服务器的主要目的就是为了处理 FriendFeed 的实时功能 ——在 FriendFeed 的应用里每一个活动用户都会保持着一个服务器连接。 参考文章： Tornado Nginx 无论做什么框架，很多时候都离不开nginx NGINX 有一个主进程（它执行特权操作，如读取配置和绑定端口）和一些工作进程与辅助进程。 反向代理反向代理应该是Nginx做的最多的一件事了。反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 12345678910server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; &#125; &#125; 负载均衡负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。 RR每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 1234567891011121314upstream test &#123; server localhost:8080; server localhost:8081;&#125;server &#123; listen 81; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://test; proxy_set_header Host $host:$server_port; &#125;&#125; 权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream test &#123; server localhost:8080 weight=9; server localhost:8081 weight=1;&#125; ip_hashiphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream test &#123; ip_hash; server localhost:8080; server localhost:8081;&#125; fair按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; url_hash按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081;&#125; 动静分离1234567891011121314151617181920212223242526272829upstream test&#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; server_name localhost; location / &#123; root e:wwwroot; index index.html; &#125; # 所有静态请求都由nginx处理，存放目录为html location ~ .(gif|jpg|jpeg|png|bmp|swf|css|js)$ &#123; root e:wwwroot; &#125; # 所有动态请求都转发给tomcat处理 location ~ .(jsp|do)$ &#123; proxy_pass http://test; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root e:wwwroot; &#125; &#125; 参考文章： 全面了解 Nginx 主要应用场景","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"frame","slug":"frame","permalink":"http://lincentma.men/tags/frame/"}]},{"title":"尘封已久的新浪微博实习面试问题","slug":"merge_file_by_multi_threads","date":"2017-07-05T15:57:49.000Z","updated":"2017-07-05T16:48:31.318Z","comments":true,"path":"merge_file_by_multi_threads.html","link":"","permalink":"http://lincentma.men/merge_file_by_multi_threads.html","excerpt":"","text":"尘封已久的新浪微博实习面试问题 假设本地磁盘目录中有若干文本文件（每行存储一个字符串），要求实现一个多线程的应用程序，将这些文本文件合并为一个文件文件。 备注：编程语言为必须Java，考虑代码注释、日志打印及异常处理，可以忽略内存限制。 请将代码以PDF附件的形式回复，谢谢。 代码思路 最简单的想法，一个线程读一个线程写 其次的想法，多个线程读同一个文件，一个线程写（单线程消费, 这样就严格保证了顺序） 多线程分组读取，是否要考虑文件的顺序？如果考虑顺序该如何？ 线程池、生产者消费者模型 NIO 预先对目录中的文件进行分类；线程间通信，全局变量判断文件读取状态，避免重复读取 同步锁、队列 注释、日志、异常处理 思路参考 java多线程读取多个文件 导入数据库 对于处理大数据量的记录，并将处理结果写入文件中的处理方案：方案一(适合于处理和输出的数据量都很大的情况)：生产者：多个线程 读取一定量的数据并处理，然后将处理结果封装成一个队列元素，装进阻塞队列中消费者: 一个线程 取元素 追加写文件(csv) (多个线程写文件是不安全的) 方案二(目前在使用的，适用于需要处理的数据量大，但输出的数据量不大的情况)：生产者：一个线程，分页查询部分数据，将其封装成队列元素装进队列中消费者：多个线程 ，从队列中取出数据元素并处理，存储处理结果。生产者和消费者执行完毕后，再集中将消费者处理的结果一个个输出到相应文件中 java 使用线程池处理文件夹下面的文件 由于LinkedBlockingQueue实现是线程安全的，实现了先进先出等特性，是作为生产者消费者的首选。 LinkedBlockingQueue 可以指定容量，不指定的话，默认最大是Integer.MAX_VALUE，其中主要用到put和take方法，put方法在队列满的时候会阻塞直到有队列成员被消费，take方法在队列空的时候会阻塞， 直到有队列成员被放进来。 java多线程批量读取文件(一) 新浪面试题-多线程合并文件 java:NIO读写文件的示例 IntelliJ IDEA 之 jdk Language level 代码实现代码感悟 看了那么多资料，最后还是最简单的最好理解，一个线程读取然后再写，感觉向一个伪多线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133package com.sinatest;import java.io.*;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.util.ArrayList;import java.util.List;import java.util.concurrent.BlockingQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.LinkedBlockingQueue;class fileWorker implements Runnable &#123; private File inputFile; private String outputFile; //构造函数 public fileWorker(File inputFile, String outputFile) &#123; this.inputFile = inputFile; this.outputFile = outputFile; &#125; @Override public synchronized void run() &#123; File output = new File(outputFile); if (!output.exists()) &#123; try &#123; output.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; FileInputStream fin = null; FileOutputStream fout = null; FileChannel fic = null; FileChannel foc = null; try &#123; fin = new FileInputStream(inputFile); fout = new FileOutputStream(output, true); // 从FileInputStream创建用于输入的FileChannel fic = fin.getChannel(); // 从FileOutputStream 创建用于输出的FileChannel foc = fout.getChannel(); // 16KB缓冲区 ByteBuffer bb = ByteBuffer.allocate(1024 &lt;&lt; 4); // 根据 read返回实际读出的字节数 中止循环 while (fic.read(bb) &gt; 0) &#123; // 缓冲区翻转用于输出到foc bb.flip(); foc.write(bb); // 清空缓冲区用于下次读取 bb.clear(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; // 安全释放资源 if (null != fic) try &#123; fic.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (null != foc) try &#123; foc.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (null != fin) try &#123; fin.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (null != fout) try &#123; fout.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Main &#123; //线程池线程数量 public static final int THREAD_POOL_SIZE = 5; //遍历文件夹 public static List&lt;File&gt; filePathsList = new ArrayList&lt;File&gt;(); //缓存队列 private static final BlockingQueue BLOCKING_QUEUE = new LinkedBlockingQueue(); //1、遍历文件夹 //2、线程池读取 //3、线程写入 public static void main(String[] args) &#123; //读取文件类型 String fileSuffix = \".txt\"; //读取文件目录 String fileFolder = \"D://Project//Java//MergeFile//datatest\"; //合并文件夹路径 String outputFilePath = \"D://Project//Java//MergeFile//output.txt\"; //遍历文件夹 getFileList(fileFolder, fileSuffix); //创建线程池 ExecutorService es = Executors.newFixedThreadPool(THREAD_POOL_SIZE); //每一个线程读取一个文件 for (File filePath : filePathsList) &#123; es.execute(new fileWorker(filePath, outputFilePath)); &#125; &#125; public static void getFileList(String fileFolder, String fileSuffix) &#123; File f = new File(fileFolder); File[] filePaths = f.listFiles(); for (File s : filePaths) &#123; if (s.isDirectory()) &#123; getFileList(s.toString(), fileSuffix); &#125; else &#123; if (-1 != s.getName().lastIndexOf(fileSuffix)) &#123; filePathsList.add(s); &#125; &#125; &#125; &#125;&#125; TODO [ ] 解决写入顺序问题 [ ] 采用生产者消费者模式实现，究竟是多线程读取一个文件，还是多线程读取多个文件，还是多线程写一个文件，哪一个在实际生产环境中是最合适的 [ ] 日志记录以及异常处理","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"java","slug":"java","permalink":"http://lincentma.men/tags/java/"},{"name":"multi-thread","slug":"multi-thread","permalink":"http://lincentma.men/tags/multi-thread/"}]},{"title":"Python命令行查询成都铁路局12306检票口信息","slug":"find_train_check_in","date":"2017-07-04T13:16:33.000Z","updated":"2017-07-04T13:29:35.339Z","comments":true,"path":"find_train_check_in.html","link":"","permalink":"http://lincentma.men/find_train_check_in.html","excerpt":"","text":"Github地址： [Find-Train-Ticket-Check-in]: https://github.com/lingma1993/Find-Train-Ticket-Check-in 背景近日多地大雨导致铁路多趟列车停运，自己关注成都铁路12306微信公众号，发现一个新的侯乘信息查询功能。 该功能提供了动车和高铁的列车检票口的信息，正好圆了自己的之前挖的坑。 如何获取接口链接地址： chrome F12 点击查询在Network中找到相关接口的信息 http://www.cd-rail.com:9090/CTKF/GeneralProServlet?code=C50101&amp;login=[&quot;10.192.111.79&quot;,&quot;hhs&quot;,&quot;hhs&quot;]&amp;sql=[&quot;20170703&quot;,&quot;ICW&quot;]&amp;where=[]&amp;order=[] 通过Postman模拟数据请求获取数据获取信息请求的格式 接口参数 车站查询 参数名称 参数含义 参数示例 code C50101 login 登陆信息 [“10.192.111.79”,”hhs”,”hhs”] sql 查询语句 [“20170703”,”ICW”] where [] order [] 车次查询 参数名称 参数含义 参数示例 code C5010 login 登陆信息 [“10.192.111.79”,”hhs”,”hhs”] sql 查询语句 [“20170703”,”8503”,”ICW”] where [] order 车站名称查询 参数名称 参数含义 参数示例 code C50102 login 登陆信息 [“10.192.111.79”,”hhs”,”hhs”] sql 查询语句 [] where [] order [] 解析接口返回结果1[&#123;\"CHECK_STATUS\":\"停止检票\",\"CHECK_TICKET\":\"A10、A11\",\"END_CHECK_TIME\":\"2017/07/04 09:30:00\",\"END_STN\":\"重庆北\",\"END_STN_CODE\":\"CUW\",\"IN_DATE\":\"2017/07/04 18:59:52\",\"START_CHECK_TIME\":\"2017/07/04 09:14:00\",\"START_STN\":\"成都东\",\"START_STN_CODE\":\"ICW\",\"STATUS_TRAIN\":\"正点\",\"STN_CODE\":\"ICW\",\"TD_DATE_ARR\":\"00:00:00\",\"TD_DATE_DEP11\":\"09:33\",\"TRAIN_DEP\":\"G8503\",\"WAIT_ROOM\":\"2层候车区\",\"WGQBZ\":\"0\"&#125;] Python urlib、urlib2 构建Header，模拟Post请求 prettytable 处理返回数据格式化为表格 re 匹配站点名称以及检索结果 展示","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"python","slug":"python","permalink":"http://lincentma.men/tags/python/"}]},{"title":"记如何折腾让博客加HTTPS","slug":"hexo_https","date":"2017-06-27T16:09:54.000Z","updated":"2017-06-27T16:58:24.162Z","comments":true,"path":"hexo_https.html","link":"","permalink":"http://lincentma.men/hexo_https.html","excerpt":"","text":"记如何折腾让博客加HTTPS 折腾了一晚上的博客的HTTPS问题，最后才明白一个道理，世上没有免费的午餐，如果有，那么也是你用最宝贵的时间或是其他换来的。 最终折腾完一圈，回到原点的时候，明白了需求分析而不是说走就走的重要。 背景1 - Google 抓取重定向301在Google搜索site:lincentma.men，查找自己的网站是否被Google收录。 自己的在Google Search Console 中，自己添加了sitemap之后，尝试抓取网站页面，显示： http://lincentma.men/ 请求编入索引 Googlebot类型： 桌面 已重定向 抓取时间：2017年6月26日星期一 GMT-7 下午8:25:37 此网址已重定向至：https://lincentma.men/ 1234567HTTP/1.1 301 Moved PermanentlyContent-Type: application/x-gzipLocation: https://lincentma.men/Server: Coding PagesVary: Accept-EncodingDate: Tue, 27 Jun 2017 03:25:39 GMTContent-Length: 57 导致在Google上没有自己博客更新的文章。 原因：Coding Pages 产生中间页从上面的HTTP响应头部的标志可以看出，Google重定向到了一个Coding Pages的服务商，也就是我双线同步博客的coding pages。 在其官网上我发现： 银牌会员的 Coding Pages 在访问时默认会先加载 Pages 跳转页，您可选择在网站首页任意位置放置「Hosted by Coding Pages」的文字版或图片版，然后勾选下方的「已放置 Hosted by Coding Pages」选项，通过审核后您的 Pages 将不会显示跳转页。请务必将「Hosted by Coding Pages」持续保留在网站首页，撤掉后跳转页会再次出现。 也就是没有银牌会员或者没有在博客上加载广告的时候，就会先跳转到中间页。Google在抓取页面的时候就会发现和目标地址不一致，导致抓取失败。所以没有免费的午餐。 2 - 百度 HTTPS站点认证失败失败详情：您的站点有链接未通过https检验。 知识点 抓取操作不会跟踪重定向。如果您抓取的网页存在重定向，您将需要手动前往重定向到的网址。 301转向(或叫301重定向，301跳转)是当用户或搜索引擎向网站服务器发出浏览请求时，服务器返回的HTTP数据流中头信息(header)中的状态码的一种，表示本网页永久性转移到另一个地址。 302重定向是暂时的重定向，搜索引擎会抓取新的内容而保留旧的网址。因为服务器返回302代码，搜索引擎认为新的网址只是暂时的。301重定向是永久的重定向，搜索引擎在抓取新内容的同时也将旧的网址替换为重定向之后的网址。302 重定向会造成网址URL 劫持现象。 HTTP请求格式： 请求头 说明 Host 接受请求的服务器地址，可以是IP:端口号，也可以是域名 User-Agent 发送请求的应用程序名称 Connection 指定与连接相关的属性，如Connection:Keep-Alive Accept-Charset 通知服务端可以发送的编码格式 Accept-Encoding 通知服务端可以发送的数据压缩格式 Accept-Language 通知服务端可以发送的语言 HTTP响应格式： 响应头 说明 Server 服务器应用程序软件的名称和版本 Content-Type 响应正文的类型（是图片还是二进制字符串） Content-Length 响应正文长度 Content-Charset 响应正文使用的编码 Content-Encoding 响应正文使用的数据压缩格式 Content-Language 响应正文使用的语言 HTTPS：HTTPS 协议就是 HTTP+SSL/TLS，即在 HTTP 基础上加入 SSL /TLS 层，提供了内容加密、身份认证和数据完整性3大功能，目的就是为了加密数据，用于安全的数据传输。 其中一个问题：网站改用 HTTPS 以后，由 HTTP 跳转到 HTTPS 的方式增加了用户访问耗时（多数网站采用 301、302 跳转） [推荐文章]: http://support.upyun.com/hc/kb/article/1044299/ Google宣布了，从2017年1月份正式发布的Chrome 56开始，Google将把某些包含敏感内容的https页面标记为“不安全”。 HTTPS是趋势，然而Github不支持自定义域名的强制HTTPS，Coding国内的必须加广告才能强制HTTPS且没有中间跳转页。所以自己就开始了折腾HTTPS的道路。 折腾HTTPS：折腾：配置CloudFare失败终究会有免费的午餐，那就是CloudFare。 配置教程知识点 CloudFlare作为一家CDN提供商，他为免费用户提供的服务室不完整的，根据官网SSL服务的介绍，CloudFlare仅会在浏览器与CloudFlare的通讯中加密，CloudFlare与本地服务器的通讯本身并没有加密。这也是Flexible和Full模式的区别所在。 SSL：在客户端与服务器间传输的数据是通过使用对称算法（如 DES 或 RC4）进行加密的。公用密钥算法（通常为 RSA）是用来获得加密密钥交换和数字签名的，此算法使用服务器的SSL数字证书中的公用密钥。有了服务器的SSL数字证书，客户端也可以验证服务器的身份。SSL 协议的版本 1 和 2 只提供服务器认证。版本 3 添加了客户端认证，此认证同时需要客户端和服务器的数字证书。 关于Let&#39;s Encrypt：[给站点添加 https 小绿锁]: http://www.cnblogs.com/xinpureZhu/articles/lets-encrypt-to-add-https-site-little-green-lock.html 但是，都设置好了。然后就无法访问网页的了。DNS的锅。 发现阿里云的DNS修改后仍处于未更改的状态，即使CloudFlare显示Status：Active。 自己认为可能的是国外DNS被墙，或者是强制HTTPS生效时间过长导致没有及时生效。 返回Coding Pages 加广告无奈返回去添加广告。 知识点 Hexo ，快速、简单且功能强大的 Node.js 博客框架。 页面布局 Hexo中自己感觉一个很有意思的特点是，在_config.yml以及md文件中，通过对于指定字段的true或者false的设置来实现功能，对于使用者来说是黑盒操作，降低了使用难度，提高了使用的体验。这是一种很好的方式。 阿里云更改域名配置买了一个域名：lincentma.men 参考文章：[hexo博客添加域名实现双线部署（github和coding)]: http://blog.csdn.net/qiuchengjia/article/details/52923156 知识点 域名解析就是国际域名或者国内域名以及中文域名等域名申请后做的到IP地址的转换过程。IP地址是网路上标识您站点的数字地址，为了简单好记，采用域名来代替ip地址标识站点地址。域名的解析工作由DNS服务器完成。 域名解析的A：A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的二级域名。 域名解析的CNAME：别名记录。这种记录允许您将多个名字映射到另外一个域名。通常用于同时提供WWW和MAIL服务的计算机。 A记录就是把一个域名解析到一个IP地址（Address，特制数字IP地址），而CNAME记录就是把域名解析到另外一个域名。 还有MX记录（邮件记录）和NS记录（解析服务器记录，NS记录只对子域名生效） TODO [ ] 站点地图的HTTPS是安全的，其他页面是信息不安全的，why？ [ ] Ngnix与SSL [ ] 自己在Github博客申请SSL证书","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://lincentma.men/tags/hexo/"},{"name":"https","slug":"https","permalink":"http://lincentma.men/tags/https/"}]},{"title":"【解析】Java Skills For Interview","slug":"java_skills_for_interview","date":"2017-06-25T17:43:55.000Z","updated":"2017-06-26T07:25:20.279Z","comments":true,"path":"java_skills_for_interview.html","link":"","permalink":"http://lincentma.men/java_skills_for_interview.html","excerpt":"","text":"【解析】Java Skills For Interview 从网上偶得之，把每个函数弄明白，源码是怎么写的，为什么这么写。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140//import不要使用通配符，需要import哪一个就import哪一个。import java.util.*; public class JavaSkillsForInterview &#123; public static void main(String[] args) &#123; // String String s = \"abc\"; s.charAt(0);//返回指定索引处的 char 值。 s.length();//返回此字符串的长度。 s.substring(0, 1);//返回字符串的子字符串。beginIndex - 起始索引（包括），endIndex - 结束索引（不包括）。左闭右开。 s.substring(1);//返回beginIndex - 起始索引（包括）到字符串末尾的子字符串。 s.equals(\"b\");//将此字符串与指定的对象比较。 s = s.trim();//返回字符串的副本，忽略前导空白和尾部空白。用于删除字符串的头尾空白符。 s.indexOf(\"a\");//返回指定字符在此字符串中第一次出现处的索引。如果此字符串中没有这样的字符，则返回-1。 s.indexOf(\"a\", 1);//返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。 s.lastIndexOf(\"a\");//返回指定字符在此字符串中最后一次出现处的索引。 s.lastindexOf(\"a\", 1);//返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。 s.toCharArray();//【常用】将此字符串转换为一个新的字符数组。 Integer.valueOf(s); // returns an Integer object，valueOf会返回一个Integer（整型）对象 //【注意】Integer类有一个静态缓存，存储了256个特殊的Integer对象——每个对象分别对应`-128 和127之间的一个值。 // Integer.valueOf(\"127\")==Integer.valueOf(\"127\");【true】 // Integer.valueOf(\"128\")==Integer.valueOf(\"128\");【false】 Integer.parseInt(s); // returns an int primitive， 将形参s转化为整数。Interger.parseInt(\"1\")=1; String.valueOf(s); // integer to string 返回指定参数的字符串表示形式。 // StringBuilder StringBuilder sb = new StringBuilder(); sb.append(\"a\");//将指定的字符串追加到此字符序列。 sb.insert(0, \"a\"); //在index指示的字符之前插入指定的字符串。 sb.deleteCharAt(sb.length() - 1); //在这个序列中的指定位置，此方法将删除字符。 sb.reverse(); //此方法会导致此字符序列被替换为该序列的反转序列。 sb.toString(); //该方法返回一个字符串，它表示这个序列中的数据。 //String 长度大小不可变 //StringBuffer 和 StringBuilder 长度可变 //StringBuffer 线程安全 StringBuilder 线程不安全 //StringBuilder 速度快 // Array int[] a = new int[10];//初始化方式1 char[] b = &#123;'a', 'b'&#125;;//初始化方式2 int[][] c = new int[10][10];//二维数组 int m = a.length;//数组长度 int n = c[0].length;//二维数组的列数 int max = Integer.MAX_VALUE; //MAX_VALUE = 0x7fffffff （Java语言规范规定int型为4字节） int min = Integer.MIN_VALUE; //MIN_VALUE = 0x80000000 Arrays.sort(a);//数组升序排序 （import java.util.Arrays;）int[]，double[]，char[]等基数据类型的数组，只提供了默认的升序排列，没有提供相应的降序排列方法。 for (int i = 0; i &lt; c.length; i++) &#123; System.out.println(c[i]); &#125;// 遍历数组输出元素 // List //List是一个接口，而ArrayList是一个类。 ArrayList继承并实现了List。 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();//List初始化 ArrayList&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt;(); //ArrayList初始化 List&lt;List&lt;Integer&gt;&gt; list2 = new ArrayList&lt;List&lt;Integer&gt;&gt;(); //而为List list.add(0);//指定元素E追加到列表的末尾。此方法返回true。 list.add(0, 1);//方法将指定的元素E在此列表中的指定位置。此方法不返回任何值。 list.addAll(list1);//方法会将所有指定集合中的元素添加到此列表的结尾。 list.get(0);//此方法返回在此列表中的指定位置的元素。 list.size();//此方法返回此列表中的元素数。 list.remove(list.size() - 1);//此方法返回从列表中移除的元素。 //Collections是一个类而Collection是一个接口。 Collections.sort(list);//方法用于指定列表按升序进行排序，根据其元素的自然顺序。 Collections.sort(list, Collections.reverseOrder());//反序排列。 //自定义排序。根据Collections.sort重载方法来实现。 Collections.sort(list, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1 - o2;// 0-&gt;1 // return o2 - o1; 1-&gt;0 &#125; &#125;); // Stack // import java.util.Stack; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); stack.push(0);//把项item压入栈顶，返回item参数。 stack.pop();//返回位于堆栈顶部的元素，在这个过程中除去它。 stack.peek();//返回到堆栈顶部的元素，但不会将其删除。 stack.isEmpty();//栈是否为空。空返回true，否则false。 // isEmpty() 和 empty()的区别：命名区别。 // For example, it was named empty() in original class but was named isEmpty() of Collection interface. stack.size(); //栈中元素的个数。 stack.search(\"code\"); //此方法返回从1开始的位置，一个对象在栈中。栈顶位置为1。 // Queue add ‐‐‐‐‐‐&gt; remove, peek // import java.util.Queue; import java.util.LinkedList; Queue&lt;Integer&gt; q = new LinkedList&lt;Integer&gt;(); q.add(0);//增加一个元索。 q.remove();//移除并返回队列头部的元素。 q.peek();//返回队列头部的元素。 //Queue使用也可以offer()来加入元素，使用poll()来获取并移出元素。 q.isEmpty();//返回队列是否为空。 q.size();//返回队列中元素的个数。 // HashMap // import java.util.HashMap; HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;();//初始化。 map.put('c', 1);//关联与此映射中的指定键指定的值。添加映射。 map.get('c');//返回指定键映射在此标识哈希映射，或者null，如果映射不包含此键的值。 if (map.containsKey('c')) &#123;//如果此映射包含指定键的映射关系返回true。 &#125; if (map.containsValue(1)) &#123;//如果此映射一个或多个键映射到指定值返回true。 &#125; for (Character d : map.keySet()) &#123;//遍历Hashmap的键集合。Set keySet()返回此映射中包含的键的set视图。 &#125; for (Integer i : map.values()) &#123;//遍历Hashmap的值集合。Collection values()返回此映射中包含的值的collection视图。 &#125; map.isEmpty();//如果此映射不包含键 - 值映射关系返回true。 map.size();//返回键 - 值映射关系在这个映射中的数量。 // HashSet // HashSet借助HashMap来实现的，利用HashMap中Key的唯一性，来保证HashSet中不出现重复值。 // HashMap中的Key是根据对象的hashCode() 和 euqals()来判断是否唯一的。 // import java.util.HashSet; HashSet&lt;Integer&gt; set = new HashSet&lt;Integer&gt;();//初始化。 set.add(0);//将指定的元素添加到此集合，如果它是不存在的。 set.remove(0);//从集合中删除指定的元素（如果存在）。 if (set.contains(0)) &#123;//如果此set包含指定的元素，则返回true。 &#125; set.isEmpty();//返回true如果此set不包含任何元素。 set.size();//返回元素的数目（它的基数）。 // mini heap // import java.util.PriorityQueue; PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;Integer&gt;();//初始化。 pq.add(0);//该方法调用返回true(所指定的Collection.add(E)) pq.offer(0);//该方法调用返回true(所指定的Queue.offer(E)) pq.remove();//该方法调用返回true，如果此队列由于调用而更改的结果。 pq.peek();//在方法调用返回此队列的头部，或null，如果此队列为空。但它不会将其删除。 pq.poll();//方法用于检索并移除此队列的头，则返回null，如果此队列为空。 pq.isEmpty();//判读是否为空。 pq.size();//在方法调用返回的元素在此集合数 while (!pq.isEmpty()) &#123; &#125; &#125;&#125; 阿里巴巴Java开发规范阿里巴巴Java开发规范","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"java","slug":"java","permalink":"http://lincentma.men/tags/java/"}]},{"title":"二叉树遍历那点事","slug":"binary_tree_traversal","date":"2017-06-24T15:34:33.000Z","updated":"2017-06-24T16:06:53.106Z","comments":true,"path":"binary_tree_traversal.html","link":"","permalink":"http://lincentma.men/binary_tree_traversal.html","excerpt":"","text":"二叉树遍历那点事 刷leetcode，碰见二叉树，看了一下午二叉树遍历，还在茫然着，写出来就明白了。好脑子不如烂笔头。 二叉树结构123456789101112131415161718192021222324252627282930313233343536373839// Definition for binary treepublic class BinaryTreeNode &#123; private int data; private BinaryTreeNode left; private BinaryTreeNode right; public BinaryTreeNode() &#123;&#125; public BinaryTreeNode(int data, BinaryTreeNode left, BinaryTreeNode right) &#123; super(); this.data = data; this.left = left; this.right = right; &#125; public int getData() &#123; return data; &#125; public void setData(int data) &#123; this.data = data; &#125; public BinaryTreeNode getLeft() &#123; return left; &#125; public void setLeft(BinaryTreeNode left) &#123; this.left = left; &#125; public BinaryTreeNode getRight() &#123; return right; &#125; public void setRight(BinaryTreeNode right) &#123; this.right = right; &#125;&#125; 数组转换为二叉树 二叉树上的元素存放位置在数组中是固定的。 如果树的i位置（从0开始按层编号）有元素，就放在数组的i号位置，没有元素，数组对应的位置就空着。i的左右子树的编号为2i+1和2i+2。 123456789101112131415161718192021222324252627282930public class BinaryTree &#123; BinaryTreeNode root; class TreeNode &#123; int value; TreeNode left; TreeNode right; public TreeNode(int paraValue) &#123; this.value = paraValue; &#125; &#125; public BinaryTree(int[] array) &#123; root = createBinaryTreeByArray(array, 0); &#125; private TreeNode createBinaryTreeByArray(int[] array, int index) &#123; TreeNode tn = null; if (index &lt; array.length) &#123; int value = array[index]; tn = new TreeNode(value); tn.left = createBinaryTreeByArray(array, 2 * index + 1); tn.right = createBinaryTreeByArray(array, 2 * index + 2); return tn; &#125; return tn; &#125;&#125; 递归与非递归一言以蔽之，非递归比递归难太多。 前序递归遍历算法：访问根结点–&gt;递归遍历根结点的左子树–&gt;递归遍历根结点的右子树中序递归遍历算法：递归遍历根结点的左子树–&gt;访问根结点–&gt;递归遍历根结点的右子树后序递归遍历算法：递归遍历根结点的左子树–&gt;递归遍历根结点的右子树–&gt;访问根结点 明白了思路，递归代码几行就能搞定了。 但是问题来了： 摘自知乎： 递归是函数自身调用自身，涉及到保护现场（变量入栈，记录地址等），时间和空间开销较大，而这操作都是在栈上，调用层级太多很容易溢出。 迭代（非递归）虽然也是用栈，可是这个栈和递归栈可不是一个概念，这个栈完全可以在堆上开辟，空间更大，不容易溢出。迭代也不涉及函数调用，效率也更高。 如何写出非递归的遍历呢？如何把手写遍历结果的过程用代码表达出来。 非递归方法需要借助栈 前序二叉树递归前序遍历的递归定义：先根节点，后左子树，再右子树。 1234567public void preOrder(BinaryTreeNode root) &#123; if (null != root) &#123; System.out.print(root.val); preOrder(root.getLeft()); preOrder(root.getRight()); &#125;&#125; 非递归在手写结果的过程中，我们可以总结出以下规律： 画出二叉树的图，输出顺序都是沿左下方向的直线，输出顺序LIFO，后进先出，满足栈的定义。 借助栈来保存节点，通过节点来打印右子树的数据。 只有入栈时才输出数据 1234567891011121314151617public void preOrderNonRecursive(BinaryTreeNode root) &#123; Stack&lt;BinaryTreeNode&gt; stack = new Stack&lt;BinaryTreeNode&gt;(); while (true) &#123; //首先从根节点开始遍历所有的左子树，并输出节点数据 while (root != null) &#123; System.out.print(root.getData() + \"\\t\"); stack.push(root); root = root.getLeft(); &#125; //循环终止条件：栈容量为0，说明右子树以及遍历完全，跳出。 if (stack.isEmpty()) break; //当上面的while循环完成后，也就是左子树输出完成，栈弹出元素，也就是离得最近的有右子树的节点。 root = stack.pop(); //返回循环，以该节点作为新的root循环输出。 root = root.getRight(); &#125;&#125; 中序二叉树递归中序遍历的递归定义：先左子树，后根节点，再右子树。 1234567public static void inorder(BinaryTreeNode root) &#123; if (root != null) &#123; inorder(root.nodeLeft); System.out.print(root.val); inorder(root.nodeRight); &#125;&#125; 非递归在手写结果的过程中，我们可以总结出以下规律： 与先序类似，只不过输出数据的时机发生了改变。 出栈的时候输出数据 123456789101112131415161718public void inOrderNonRecursive(BinaryTreeNode root) &#123; Stack&lt;BinaryTreeNode&gt; stack = new Stack&lt;BinaryTreeNode&gt;(); while (true) &#123; //遍历左子树，并保存到栈中 while (root != null) &#123; stack.push(root); root = root.getLeft(); &#125; //遍历跳出条件 if (stack.isEmpty()) break; //当上面的while循环完成后，也就是左子树输出完成，栈弹出元素，也就是离得最近的有右子树的节点。 root = stack.pop(); //根据中序遍历的输出顺序，先输出左子树的节点的值 System.out.print(root.getData() + \"\\t\"); //以最左下的节点为例，它的右节点为null，那么再次循环时，就会跳过遍历左子树的循环，栈出栈的节点为它的父节点，也就是根节点，输出其值，再转为其右子树，完成中序遍历的输出顺序。 root = root.getRight(); &#125;&#125; 后序二叉树递归后序遍历的递归定义：先左子树，后右子树，再根节点。 1234567public static void postOrder(BinaryTreeNode root)&#123; if (root != null)&#123; postOrder(root.nodeLeft); postOrder(root.nodeRight); System.out.print(root.val); &#125;&#125; 非递归在手写结果的过程中，我们可以总结出以下规律： 与前面区别在于，判读出栈时，要考虑该节点是否在之前已经访问过。 在stack中，最后添加的数据需要通过lastElement方法获取。 1234567891011121314151617181920212223242526272829303132333435363738public void postOrderNonRecursive(BinaryTreeNode root)&#123; Stack&lt;BinaryTreeNode&gt; stack=new Stack&lt;BinaryTreeNode&gt;(); while(true)&#123; //遍历左子树，并保存到栈中 if(root!=null)&#123; stack.push(root); root=root.getLeft(); &#125;else&#123;//此时，当遍历到最左下的叶节点时，它的左子树是null。 //后序遍历的顺序 if(stack.isEmpty()) return; // 遍历终止条件1：栈空 //栈中最近添加的元素的右子树为空则弹出并输出该元素 if(null==stack.lastElement().getRight())&#123; root=stack.pop(); //输出最开始左子树的叶节点，也就是遍历顺序中的左子树（以及代入的右子树值） System.out.print(root.getData()+\"\\t\"); //while循环终止条件1：出栈后的最近添加的元素则为父节点的右子树与之前出栈的元素相等 while(root==stack.lastElement().getRight())&#123; //root（右子树遍历完成）与此时栈中的最近添加的元素（父节点）的右子树相等，那么说明lastElement为根节点 //输出根节点 System.out.print(stack.lastElement().getData()+\"\\t\"); //出栈（右子树的叶节点） root=stack.pop(); // while终止条件2：栈空 if(stack.isEmpty())&#123; break; &#125; &#125; &#125; //栈不空，则root赋值为栈最近添加元素的右子树，开始从右子树继续遍历 if(!stack.isEmpty()) root=stack.lastElement().getRight(); else //栈空，赋值为null，确保进入遍历结束条件判断的地方 root=null; &#125; &#125;&#125; PS：感觉有点绕，stack.lastElement()这个也可以用pre节点来代替，这样可能更便于理解。 非递归的统一化非递归是否也可以像递归一样，只用修改语句的位置，实现不同方式的遍历呢？ 答案是肯定的，大牛就是多。 统一三种更简单的非递归遍历方法的基本思想：有重合元素的局部有序一定能导致整体有序。 三种非递归遍历唯一不同的就是局部入栈的三行代码的先后顺序。所以不管是根-&gt;左-&gt;右,左-&gt;根-&gt;右,左-&gt;右-&gt;根,甚至是根-&gt;右-&gt;左,右-&gt;根-&gt;左,右-&gt;左-&gt;根定义的新顺序，算法实现都无变化，除了改变局部入栈顺序。 123456789101112131415161718192021222324void postorderTraversalNew(TreeNode *root, vector&lt;int&gt; &amp;path)&#123; stack&lt; pair&lt;TreeNode *, bool&gt; &gt; s; s.push(make_pair(root, false)); bool visited; while(!s.empty()) &#123; root = s.top().first; visited = s.top().second; s.pop(); if(root == NULL) continue; if(visited) &#123; path.push_back(root-&gt;val); &#125; else &#123; s.push(make_pair(root, true)); s.push(make_pair(root-&gt;right, false)); s.push(make_pair(root-&gt;left, false)); &#125; &#125;&#125; PS: 有时间改写成Java版本的。 12 参考文章","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"binary tree","slug":"binary-tree","permalink":"http://lincentma.men/tags/binary-tree/"},{"name":"recursive","slug":"recursive","permalink":"http://lincentma.men/tags/recursive/"},{"name":"iterate","slug":"iterate","permalink":"http://lincentma.men/tags/iterate/"}]},{"title":"Java、Python与PHP的虚拟机异同","slug":"program_language_virtual_machine","date":"2017-06-23T15:59:24.000Z","updated":"2017-06-23T16:07:27.662Z","comments":true,"path":"program_language_virtual_machine.html","link":"","permalink":"http://lincentma.men/program_language_virtual_machine.html","excerpt":"","text":"Java-JVM定义 JDK(Java Development Kit) 是 Java 语言的软件开发工具包（SDK）。JDK 物理存在，是 programming tools、JRE 和 JVM 的一个集合 JRE（Java Runtime Environment）Java 运行时环境，JRE 物理存在，主要由Java API 和 JVM 组成，提供了用于执行 java 应用程序最低要求的环境。 JVM(Java Virtual Machine) 是一种软件实现，执行像物理机程序的机器（即电脑）。JVM 通过执行 Java bytecode 可以使 java 代码在不改变的情况下运行在各种硬件之上。JVM是基于栈的。 JVM 执行 加载代码 验证代码 执行代码 提供运行环境 JVM 生命周期 启动：任何一个拥有main函数的class都可以作为JVM实例运行的起点 运行：main函数为起点，程序中的其他线程均有它启动，包括daemon守护线程和non-daemon普通线程。daemon是JVM自己使用的线程比如GC线程，main方法的初始线程是non-daemon。 消亡：所有线程终止时，JVM实例结束生命。 JVM结构及内存模型 名词解释： Class Loader：类加载器负责加载程序中的类型（类和接口），并赋予唯一的名字。为什么使用双亲委托模型——ClassLoader 隔离问题。 Execution Engine：执行引擎。执行引擎以指令为单位读取 Java 字节码。它就像一个 CPU 一样，一条一条地执行机器指令。 Runtime Data Areas:：运行时数据区。 PS：想起面试的时候被问到过这样的问题：你在使用java过程中是否遇到过OOM的情况？当时一阵懵比。现在总结下： PC寄存器（PC Register）是唯一一个在 Java 虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM 栈（Java Virtual Machine Stack）：如果JVM Stack可以动态扩展，但是在尝试扩展时无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈时抛出。 本地方法栈(Native method stack)：如果本地方法栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的本地方法栈，那Java虚拟机将会抛出一个OutOfMemoryError异常。 方法区(Method area)：如果方法区的内存空间不能满足内存分配请求，那Java虚拟机将抛出一个OutOfMemoryError异常。 运行时常量池(Runtime constant pool)：当创建类和接口时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大内存空间后就会抛出OutOfMemoryError 堆(Heap)：如果实际所需的堆超过了自动内存管理系统能提供的最大容量时抛出。 总结一下就是无法申请到足够的内存以及超出最大容量两方面原因 垃圾回收 新生代新生代由 Eden 与 Survivor Space（S0，S1）构成，大小通过-Xmn参数指定，Eden 与 Survivor Space 的内存大小比例默认为8:1，可以通过-XX:SurvivorRatio 参数指定，比如新生代为10M 时，Eden分配8M，S0和S1各分配1M。 Eden：希腊语，意思为伊甸园，在圣经中，伊甸园含有乐园的意思，根据《旧约·创世纪》记载，上帝耶和华照自己的形像造了第一个男人亚当，再用亚当的一个肋骨创造了一个女人夏娃，并安置他们住在了伊甸园。 大多数情况下，对象在Eden中分配，当Eden没有足够空间时，会触发一次Minor GC，虚拟机提供了-XX:+PrintGCDetails参数，告诉虚拟机在发生垃圾回收时打印内存回收日志。 Survivor：意思为幸存者，是新生代和老年代的缓冲区域。当新生代发生GC（Minor GC）时，会将存活的对象移动到S0内存区域，并清空Eden区域，当再次发生Minor GC时，将Eden和S0中存活的对象移动到S1内存区域。 存活对象会反复在S0和S1之间移动，当对象从Eden移动到Survivor或者在Survivor之间移动时，对象的GC年龄自动累加，当GC年龄超过默认阈值15时，会将该对象移动到老年代，可以通过参数-XX:MaxTenuringThreshold 对GC年龄的阈值进行设置。 老年代老年代的空间大小即-Xmx 与-Xmn 两个参数之差，用于存放经过几次Minor GC之后依旧存活的对象。当老年代的空间不足时，会触发Major GC/Full GC，速度一般比Minor GC慢10倍以上。 永久代在JDK8之前的HotSpot实现中，类的元数据如方法数据、方法信息（字节码，栈和变量大小）、运行时常量池、已确定的符号引用和虚方法表等被保存在永久代中，32位默认永久代的大小为64M，64位默认为85M，可以通过参数-XX:MaxPermSize进行设置，一旦类的元数据超过了永久代大小，就会抛出OOM异常。 虚拟机团队在JDK8的HotSpot中，把永久代从Java堆中移除了，并把类的元数据直接保存在本地内存区域（堆外内存），称之为元空间。 这样做有什么好处？有经验的同学会发现，对永久代的调优过程非常困难，永久代的大小很难确定，其中涉及到太多因素，如类的总数、常量池大小和方法数量等，而且永久代的数据可能会随着每一次Full GC而发生移动。 而在JDK8中，类的元数据保存在本地内存中，元空间的最大可分配空间就是系统可用内存空间，可以避免永久代的内存溢出问题，不过需要监控内存的消耗情况，一旦发生内存泄漏，会占用大量的本地内存。 判断垃圾回收 引用计数法：在对象上添加一个引用计数器，每当有一个对象引用它时，计数器加1，当使用完该对象时，计数器减1，计数器值为0的对象表示不可能再被使用。引用计数法实现简单，判定高效，但不能解决对象之间相互引用的问题。 可达性分析法：通过一系列称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，搜索路径称为 “引用链”，以下对象可作为GC Roots： 本地变量表中引用的对象 方法区中静态变量引用的对象 方法区中常量引用的对象 Native方法引用的对象 当一个对象到 GC Roots 没有任何引用链时，意味着该对象可以被回收。 垃圾回收算法 标记-清除算法对待回收的对象进行标记。算法缺点：效率问题，标记和清除过程效率都很低；空间问题，收集之后会产生大量的内存碎片，不利于大对象的分配。 复制算法复制算法将可用内存划分成大小相等的两块A和B，每次只使用其中一块，当A的内存用完了，就把存活的对象复制到B，并清空A的内存，不仅提高了标记的效率，因为只需要标记存活的对象，同时也避免了内存碎片的问题，代价是可用内存缩小为原来的一半。 标记-整理算法在老年代中，对象存活率较高，复制算法的效率很低。在标记-整理算法中，标记出所有存活的对象，并移动到一端，然后直接清理边界以外的内存。 参考文章 [清蒸 JVM （一）]: http://www.importnew.com/23658.html [Java GC的那些事（上）]: http://www.importnew.com/23633.html [Java GC的那些事（下）]: http://www.importnew.com/23640.html PythonPVMPVM是Python的运行引擎。他通常表现为python系统的一部分。并且他是实际运行脚本的组件。 编译器：将源码编译成运行在虚拟机上执行的opcode(pyc文件)，pyc文件是在python虚拟机上执行的一种跨平台字节码。 运行时：虚拟机解释器把opcode(pyc文件)解释成具体机器的机器码，执行。 JVM与PVM Java代码从源程序到执行，要经过的过程是：编译器(javac)把源代码转化为字节码，然后解释器（Java.exe）把字节码转换为计算机理解的机器码来执行。其中编译器和解释器都是Java虚拟机（JVM）的一部分，由于针对不同的硬件与OS，Java解释器有所不同，因此可以实现“一次编译、到处执行”。所以JVM是Java跨平台特性的关键所在。 对于Python，其源代码到执行也要经过如下过程：源代码—&gt;字节码—&gt;机器码。与Java不同的是，Python使用的虚拟机是基于其他语言实现的，比如我们一般使用的Python实际为Cpython，也就是其虚拟机由C实现，这个虚拟机负责把Python源码编译为字节码，再解释执行。另外，还有Jypython、Ironpython等。 PHP-Zend&amp;HHVM Zend引擎默认做法，是先编译为opcode，然后再逐条执行，通常每条指令对应的是C语言级别的函数。如果我们产生大量重复的opcode（纯PHP写的代码和函数），对应的则是Zend多次逐条执行这些C代码。 HHVM生成和执行PHP的中间字节码（HHVM生成自己格式的中间字节码），执行时通过JIT（Just In Time，即时编译是种软件优化技术，指在运行时才会去编译字节码为机器码）转为机器码执行。JIT将大量重复执行的字节码在运行的时候编译为机器码，达到提高执行效率的目的。通常，触发JIT的条件是代码或者函数被多次重复调用。 写在最后时间匆忙，囫囵吞枣，努力完善。 后端开发离不开Java，python和php，深入学习原理，比较异同，最佳使用。 2017.06.23","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"python","slug":"python","permalink":"http://lincentma.men/tags/python/"},{"name":"java","slug":"java","permalink":"http://lincentma.men/tags/java/"},{"name":"virtual machine","slug":"virtual-machine","permalink":"http://lincentma.men/tags/virtual-machine/"},{"name":"php","slug":"php","permalink":"http://lincentma.men/tags/php/"}]},{"title":"几个小问题的解答","slug":"learn_for_some_questions","date":"2017-06-22T15:25:38.000Z","updated":"2017-06-22T15:43:43.699Z","comments":true,"path":"learn_for_some_questions.html","link":"","permalink":"http://lincentma.men/learn_for_some_questions.html","excerpt":"","text":"她给我提了一下几个问题，自己一眼看上去觉得简单，但是说不出来所以然，犯了眼高手低的毛病，记录自省。 [x] 一共10级楼梯，每次可以走一步或两步，求一共多少种走法。 [x] 一个细胞，一个小时分裂一次，生命周期是3小时，求n小时后容器内，有多少细胞。 [x] 斐波那契数列的实现。 [x] 递归算法的核心 Question1—走楼梯思路楼梯问题，一眼看上去，应该是一个递归问题跑不了了。 那么该如何递归，找到其中的规律呢？ 逆向思考。 要想走到M(M=10)级,可以分为2种情况。 从m-2级迈两步 从m-1级迈一步 那么对于m-2和m-1的情况也是各自分为两种，以此类推。 那么走法的和就是m-2的走法和m-1的走法之和。 那么递归到最基本的（当前人在第0阶台阶） 第0阶台阶：0 第1阶台阶：1 第2阶台阶：2（1+1或者2） 得到公式，也就是斐波那契数列。$$f(n)=f(n-1)+f(n-2)$$ 代码1234567891011121314151617181920212223242526272829import java.util.Scanner;/** * Created by ml on 2017/6/21. */public class taijie &#123; public static int countNumber(int stepsNum) &#123; int sum = 0; if (stepsNum == 0) &#123; return 0; &#125; if (stepsNum == 1) &#123; return 1; &#125; else if (stepsNum == 2) &#123; return 2; &#125; else if (stepsNum &gt; 2) &#123; return countNumber(stepsNum - 2) + countNumber(stepsNum - 1); &#125; return sum; &#125; public static void main(String[] args) &#123; long startMili=System.currentTimeMillis(); for (int i = 0; i &lt;= 10; i++) &#123; System.out.println(\"楼梯台阶数:\" + i + \", 走法有:\" + countNumber(i)); &#125; long endMili=System.currentTimeMillis(); System.out.println(\"耗时:\" + String.valueOf(endMili - startMili) + \"毫秒\"); &#125;&#125; 1234567891011121314楼梯台阶数:0, 走法有:0楼梯台阶数:1, 走法有:1楼梯台阶数:2, 走法有:2楼梯台阶数:3, 走法有:3楼梯台阶数:4, 走法有:5楼梯台阶数:5, 走法有:8楼梯台阶数:6, 走法有:13楼梯台阶数:7, 走法有:21楼梯台阶数:8, 走法有:34楼梯台阶数:9, 走法有:55楼梯台阶数:10, 走法有:89耗时:0毫秒Process finished with exit code 0 其他的方法该算法的运算时间是指数级增长的，还有其他方法吗？ 动态规划？ 其实动态规划（dynamicprogramming）是通过组合子问题而解决整个问题的解。乍一看和递归的写法差不多，都是相加。但是递归式是包含了许多重复计算的步骤，对应台阶就是每一个台阶计算前面都是重复的。动态规划算法对每个子问题只求解一次，将其结果保存起来，从而避免每次遇到各个子问题时重新计算答案。 代码如下： 1234567891011121314151617181920212223242526272829import java.util.Scanner;/** * Created by ml on 2017/6/21. */public class taijie &#123; public static int climbStairs(int n) &#123; if (n == 0 || n == 1 || n == 2) &#123; return n; &#125; //注意坐标起始点的区别 int[] r = new int[n+1]; r[1] = 1; r[2] = 2; for (int i = 3; i &lt;= n; i++) &#123; r[i] = r[i-1] + r[i-2]; &#125; return r[n]; &#125; public static void main(String[] args) &#123; long startMili=System.currentTimeMillis(); for (int i = 0; i &lt;= 10; i++) &#123; System.out.println(\"楼梯台阶数:\" + i + \", 走法有:\" + climbStairs(i)); &#125; long endMili=System.currentTimeMillis(); System.out.println(\"耗时:\" + String.valueOf(endMili - startMili) + \"毫秒\"); &#125;&#125; 1234567891011121314楼梯台阶数:0, 走法有:0楼梯台阶数:1, 走法有:1楼梯台阶数:2, 走法有:2楼梯台阶数:3, 走法有:3楼梯台阶数:4, 走法有:5楼梯台阶数:5, 走法有:8楼梯台阶数:6, 走法有:13楼梯台阶数:7, 走法有:21楼梯台阶数:8, 走法有:34楼梯台阶数:9, 走法有:55楼梯台阶数:10, 走法有:89耗时:0毫秒Process finished with exit code 0 之前数学课本上如何思考的？ 先求出走完台阶需要几步？ 再求出总步数中，走一个台阶是几步，走两个台阶式几步，不同种类为排列组合计算 类似问题再看一个硬币的凑法： 用1分、2分和5分的硬币凑成1元，共有多少种不同的凑法？（华为机试题） 它和走楼梯的区别在于，楼梯不同顺序是不同的走法，硬币则与顺序无关，程序可用穷举法。 123456789101112131415161718192021public class coin &#123; public static int getKinds()&#123; int num=0; for (int i = 0; i &lt; 21; i++) &#123; for (int j = 0; j &lt;= 100-5*i; j++) &#123; for (int k = 0; k &lt;= 100-5*i-2*j; k++) &#123; if(5*i+2*j+k==100)&#123; num++; &#125; &#125; &#125; &#125; return num; &#125; public static void main(String[] args) &#123; System.out.println(getKinds()); &#125;&#125; 那么这个问题可以推广为一般性问题吗？M阶，一次走a阶或者b阶或者。。。，求不同走法。 参考文章Question2—细胞分裂非递归思路乍一看，关键是如何处理生命周期是3小时。如何在分裂的同时提出死亡的细胞。 代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import java.util.ArrayList;import java.util.HashMap;import java.util.Iterator;import java.util.Map;/** * Created by ml on 2017/6/22. * 思路：每个细胞定义为一维数组的元素，元素的值为细胞的生存时间，每分裂一次，在数组末尾添加新的元素，初始值为0，同时原来的元素值加1 * 当元素的值为3时，将该元素剔除 * 最后返回该数组的大小 */public class xibao &#123; public static int cellNum2(int n) &#123; ArrayList&lt;Integer&gt; cell = new ArrayList&lt;Integer&gt;(); //定义cellnum int cellnum = 0; //加入初始细胞 cell.add(0); for (int i = 0; i &lt; n; i++) &#123; //记录当前数组大小（剔除完成后的数组） int size = cell.size(); //计算分裂后新的数组的大小 cellnum = 2 * cell.size(); //原有生存时间加1 for (int j = 0; j &lt; cell.size(); j++) &#123; cell.set(j, cell.get(j) + 1); &#125; //遍历剔除元素值为3 PS：ArrayList中遍历可以删除的只有迭代器 Iterator&lt;Integer&gt; it = cell.iterator(); while (it.hasNext()) &#123; if (it.next().equals(3)) it.remove(); &#125; //在数组末尾添加新的元素 for (int j = size; j &lt; cellnum; j++) &#123; cell.add(0); &#125; &#125; return cell.size(); &#125; public static int cellNum(int n) &#123; HashMap&lt;Integer, Integer&gt; cell = new HashMap&lt;&gt;(); int cellnum = 1; for (int i = 1; i &lt;= n; i++) &#123; cellnum *= 2; int size = cell.size(); for (int j = size; j &lt; cellnum; j++) &#123; cell.put(j, 0); &#125; Iterator&lt;HashMap.Entry&lt;Integer, Integer&gt;&gt; iter = cell.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = iter.next(); int key = (int) entry.getKey(); int val = (int) entry.getValue(); if (key &lt; size) &#123; cell.put(key, val + 1); &#125; &#125; &#125; return cell.size(); &#125; public static void main(String[] args) &#123; long startMili = System.currentTimeMillis(); int n = 6; System.out.println(n + \"小时后容器细胞:\" + cellNum2(n) + \"个\"); long endMili = System.currentTimeMillis(); System.out.println(\"耗时:\" + String.valueOf(endMili - startMili) + \"毫秒\"); &#125;&#125; 12343小时后容器细胞:7个耗时:0毫秒Process finished with exit code 0 关于ArrayList 迭代器是作为当前集合的内部类实现的，当迭代器创建的时候保持了当前集合的引用； 集合内部维护一个字段叫modiCount，用来记录集合被修改的次数，比如add，remove，set等都会使该字段递增； 迭代器内部也维护着当前集合的修改次数的字段，迭代器创建时该字段初始化为集合的modiCount值 当每一次迭代时，迭代器会比较迭代器维护的字段和modiCount的值是否相等，如果不相等就抛ConcurrentModifiedException异常； 当然，如果用迭代器调用remove方法，那么集合和迭代器维护的修改字数都会递增，以保持两个状态的一致。 这就是为什么你只可以用迭代器来删除，而不能用其他方式来修改集合。 这类问题如何递归？公式法：$$n=t/a~~~~y=2^n$$但是这个只适用于最简单的没有任何附加状态条件的情况。 递归如何来分析？ 细胞的生存周期是3个小时，那我们就可以把细胞在题目中状态分为以下几个状态： a：刚分裂态——1 b：分裂1小时态——a分裂出b和a c：分裂2小时态——b分裂出c和a d：分裂3小时态——死亡（停止分裂） 那么，我们就可以根据细胞状态设定函数。分析每一个状态的来源是哪里即可。$$a(t)=a(t-1)+b(t-1)+c(t-1)\\\\b(t)=a(t-1)\\\\c(t)=b(t-1)\\\\d(t)=d(t-1)+c(t-1)$$容器中存活的细胞数目就是a、b、c三种状态数量的总和。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.ArrayList;import java.util.HashMap;import java.util.Iterator;import java.util.Map;/** * Created by ml on 2017/6/22. */public class xibao &#123; public static int aStatus(int t) &#123; if (t == 0) &#123; return 1; &#125; return aStatus(t - 1) + bStatus(t - 1) + cStatus(t - 1); &#125; public static int bStatus(int t) &#123; if (t == 0) &#123; return 0; &#125; return aStatus(t-1); &#125; public static int cStatus(int t) &#123; if (t == 0) &#123; return 0; &#125; if (t == 1) &#123; return 0; &#125; return bStatus(t-1); &#125; public static int dStatus(int t) &#123; if (t == 0) &#123; return 0; &#125; if (t == 1) &#123; return 0; &#125; if (t == 2) &#123; return 0; &#125; return dStatus(t-1) + cStatus(t-1); &#125; public static void main(String[] args) &#123; long startMili = System.currentTimeMillis(); int n = 3; int res = aStatus(n) + bStatus(n) + cStatus(n); System.out.println(n + \"小时后容器细胞:\" + res + \"个\"); long endMili = System.currentTimeMillis(); System.out.println(\"耗时:\" + String.valueOf(endMili - startMili) + \"毫秒\"); &#125;&#125; 12343小时后容器细胞:7个耗时:0毫秒Process finished with exit code 0 参考文章Question3—Fibonacci数列经典问题：求Fibonacci数列前n项。$${an}：a1=1，a2=1，a_{n+2}=a_{n+1}+a_n（n≥1）。$$ PS: Markdown 中公式书写规则 \\\\符号后接的字符为上标 ^符号后接的字符为上标 _符号后接的字符为下标 如果同时有两个下标，则需要使用{}来将符号括起来 代码1234567891011121314151617181920212223242526272829303132333435public class fab &#123; public static void main(String[] args) &#123; for(int i = 1; i &lt; 10; i ++)&#123; System.out.print(recursion(i) + \" \"); &#125; System.out.println(); for(int i = 1; i &lt; 10; i ++)&#123; System.out.print(loop(i) + \" \"); &#125; &#125; /** * 递归 */ public static int recursion(int n)&#123; if(n &lt;= 2)&#123; return 1; &#125; return recursion(n -1) + recursion(n -2); &#125; /** * 循环 */ public static int loop(int n)&#123; if(n &lt;= 2)&#123; return 1; &#125; int s1 = 1,s2 = 1, sum = 0; for(int i = 0 ; i &lt; n - 2; i ++)&#123; sum = s1 + s2; s1 = s2; s2 = sum; &#125; return sum; &#125;&#125; 1231 1 2 3 5 8 13 21 34 1 1 2 3 5 8 13 21 34 Process finished with exit code 0 值得注意的是（递归方法有栈溢出的风险）。 参考文章Question4—递归核心那么总结一下，递归算法的核心是什么呢？ 那就是： 在有限次可预见性结果中，找到结果与上一次结果之间的关系。 f(n)与f(n-1)的关系有时候很简单，如同走楼梯，状态单一；又有时如同细胞分裂，多种状态组合影响结果。 关键在于梳理清楚本次结果和上一次结果的关系有哪些方面或是因素，刚开始看的时候可能会很乱。 在草稿纸上写出前几次的结果，或者画图，这样更容易找到规律，这种规律实际上就是递归方程。 *在算法的分析中，当一个算法中包含递归调用时，其时间复杂度的分析会转化成为一个递归方程的求解。而对递归方程的求解，方法多种多样，不一而足。 动态规划就是在递归的基础上，保存每一步的数据，避免重复计算。在递归计算调用次数过多时，可以考虑更换其他方法解答。","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://lincentma.men/categories/开发笔记/"}],"tags":[{"name":"java","slug":"java","permalink":"http://lincentma.men/tags/java/"}]},{"title":"Rank小记","slug":"learn_rank","date":"2017-06-21T04:13:27.000Z","updated":"2017-06-22T03:16:46.299Z","comments":true,"path":"learn_rank.html","link":"","permalink":"http://lincentma.men/learn_rank.html","excerpt":"","text":"搜索引擎，你每天用的，知其然，不知其所以然。 ——读《搜索引擎 : 信息检索实践》 信息检索的定义信息检索是关于信息的结构、分析、组织、存储、搜索和检索的领域——Gerard Salton 搜索引擎的指标处理数十亿网页的商业化网络搜索引擎时代的今天，搜索引擎的指标体现在以下五个方面： 全 新 准 快 稳 其中Rank的目标就是准 Rank如何所搜即所得是Rank的目的。 海量网页快速排序 相关性：搜索结果与用户需求的匹配程度 多样性（Query对应多个结果，通过用户行为数据进行选择和匹配） 权威性（被引用次数，链接分析。类似于学术文章的因子。） 时效性（Query的频次随时间的变化趋势） 个性化（构建用户个人数据，计算结果与用户喜好匹配程度） 用户成本 如何排序自己的理解，排序就是算分，按照分数来进行排序，key是算分。 经典IR模型:TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。距离特征 Boolean Model：布尔（Boolean）模型是基于集合论和布尔代数的一种简单检索模型。它的特点是查找那些于某个查询词返回为“真”的文档。在该模型中，一个查询词就是一个布尔表达式，包括关键词以及逻辑运算符。通过布尔表达式，可以表达用户希望文档所具有的特征。 Vetor-Space:VSM概念简单，把对文本内容的处理简化为向量空间中的向量运算，并且它以空间上的相似度表达语义的相似度，直观易懂。当文档被表示为文档空间的向量，就可以通过计算向量之间的相似性来度量文档间的相似性。文本处理中最常用的相似性度量方式是余弦距离 Rank关键技术倒排索引在线计算转为离线计算分布式计算系统 Cache辣鸡信息：找出特征，计算分数，剔除。 人工识别与机器学习。Learning to Rank 找了一些文档博客，慢慢学习~ Point-Wise：RankSVMPair-Wise：RankNetList-Wise：RankForest 努力学算法一定可以搞懂的！","categories":[{"name":"intern","slug":"intern","permalink":"http://lincentma.men/categories/intern/"}],"tags":[{"name":"rank","slug":"rank","permalink":"http://lincentma.men/tags/rank/"}]},{"title":"为找工作而准备着","slug":"prepare_for_work","date":"2017-06-17T08:57:30.000Z","updated":"2017-06-22T03:15:06.575Z","comments":true,"path":"prepare_for_work.html","link":"","permalink":"http://lincentma.men/prepare_for_work.html","excerpt":"","text":"为找工作而准备着行业了解互联网+行业——改变传统行业 未来的行业是属于数据驱动的行业： 物流行业（快递物流数据），物流成本仍有巨大空间优化 金融行业（金融数据），普惠金融有广阔的空间 电商行业（交易数据），定制化，差异化，个性化会随着物质条件的不断提高而不断重要 视频行业（视频数据），视频对于文件具有更有效地传播 农业（作物，天气等数据），高品质农业作物的需求不断上升，小作坊式模式对于行情波动的适应性有巨大的改善空间 云（云数据），理论上任何公司的数据都可以上云来进行弹性管理，提高效率 新兴科技（新兴技术），探索无止境，更多广阔的市场是由新兴技术所开创 公司了解 物流行业：菜鸟物流 金融行业：蚂蚁金融、支付宝、微信支付 电商行业：阿里巴巴、京东、美团点评、网易严选考拉 视频行业：今日头条、腾讯视频、B站 农业：网易未央、京东、联想农业 云：阿里云、腾讯云 新兴科技：大疆科技 部门了解 技术营销：通过基础数据分析，找到赋能新方法 基础研发：如何让数据更加适合的展现 产品研发：如何研发用用户不易察觉的方式解决用户痛点的产品 内部研发：研发如何提高开发效率的工具 技术栈了解Unix/Linux 后端必须掌握的操作系统。建议的书籍：《Linux编程》《Unix环境高级编程》 网络编程 建议书籍：《Unix网络编程》《TCP/IP协议详解》 脚本语言PHP、Python深入学习。 数据库 无论是关系型数据库还是非关系型数据库，都是必须要吃透牢牢掌握的东西 工作使命感互联网的技术日新月异的目标就是让人们更加方面的获取一切，享受科技带来的便利； 不可否认互联网技术同样是一把双刃剑，人们在低成本享受的同时，同时也会出现键盘侠、恶意抹黑、舆论控制等让社会阴暗面放大的趋势。 如同微博让人们无所不谈，同时也会有水军，造谣；大疆无人机让我们获得前所未有的影像视角，同时也被用于装备军队送上战场。 在致力于互联网技术和产品不断发展的同时，同时还需要致力于让技术和产品如何正确地服务于人，而避免用于歧途。 数据亦然，发掘数据蕴含的价值创造正能量价值，尽所能。","categories":[{"name":"job","slug":"job","permalink":"http://lincentma.men/categories/job/"}],"tags":[{"name":"job","slug":"job","permalink":"http://lincentma.men/tags/job/"}]},{"title":"在百度实习的日子","slug":"internship_in_baidu","date":"2017-06-17T08:57:10.000Z","updated":"2017-06-22T03:16:19.535Z","comments":true,"path":"internship_in_baidu.html","link":"","permalink":"http://lincentma.men/internship_in_baidu.html","excerpt":"","text":"在百度实习的日子 转眼从百度离开回到了在学校的日子。也应该记录下自己在帝都，在百度的255天。 在百度糯米在百度糯米第一次接触了规范的开发流程，公司庞大的知识储备库，让自己如同海绵一样广泛吸水般吸收知识。有非常nice团队来让我迅速适应这样的开发环境，让我熟悉开发流程，带我一起和产品交流、和运营交流、和测试交流。 在百度搜索在百度搜索我接触到了搜索是如何运转，自己尝试接触Sug的海量数据进行数据分析监控，第一次理解亲身理解大数据所蕴含的价值。一次次的技术分享，让我更加深刻理解百度搜索里面的核心技术的深度，自己仍有很长的路要走。 在百度目前为止我见过最好的办公环境，nice的伙食，健身设备，班车交通，让我每个周末也来公司给自己充电。每天的问好，晚上的坐上班车返回住所，每一天任务的完成带给自己的充实感让自己不断向前。体验过996，体验过封闭开发，体验过部门内分享，体验过酸甜苦辣。感谢百度，感谢曾经的同事，感谢让自己不断成长。","categories":[{"name":"intern","slug":"intern","permalink":"http://lincentma.men/categories/intern/"}],"tags":[{"name":"intern","slug":"intern","permalink":"http://lincentma.men/tags/intern/"}]},{"title":"Hexo之重新初始化","slug":"hexo_init","date":"2017-06-15T07:04:32.000Z","updated":"2017-06-25T18:25:43.666Z","comments":true,"path":"hexo_init.html","link":"","permalink":"http://lincentma.men/hexo_init.html","excerpt":"","text":"站在巨人的肩膀上，搭建Hexo，事半功倍。但是巨人太多，选择好的巨人很重要，不然就不得其法，回到原点。 Hexo参考文档 [NexT]: http://theme-next.iissnan.com/getting-started.html “NexT” [NexT优化]: http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html Hexo搭建问题记录 多说评论替换 背景效果 腾讯云搭建Hexo Hexo 性能优化 [hexo博客进阶－性能优化]: https://www.liuxinggang.com/2016-12-06-hexo%E5%8D%9A%E5%AE%A2%E8%BF%9B%E9%98%B6%EF%BC%8D%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/ 自己更换电脑，没有保存Hexo的源文件，借此机会重新部署学习，完善自己的博客。","categories":[{"name":"教程","slug":"教程","permalink":"http://lincentma.men/categories/教程/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://lincentma.men/tags/hexo/"}]}]}